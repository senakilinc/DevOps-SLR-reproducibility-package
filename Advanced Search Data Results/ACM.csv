@article{10.1002/smr.2323,
author = {Rafi, Saima and Yu, Wu and Akbar, Muhammad Azeem and Mahmood, Sajjad and Alsanad, Ahmed and Gumaei, Abdu},
title = {Readiness Model for DevOps Implementation in Software Organizations},
year = {2021},
issue_date = {April 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {4},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2323},
doi = {10.1002/smr.2323},
abstract = {DevOps is a new software engineering paradigm adopted by various software organizations to develop the quality software within time and budget. The implementation of DevOps practices is critical, and there are no guidelines to assess and improve the DevOps activities in software organizations. Hence, there is a need to develop a readiness model for DevOps (RMDevOps) with an aim to assist the practitioners for implementation of DevOps practices in software firms. To achieve the study objective, we conducted a systematic literature review (SLR) study to identify the critical challenges and associated best practices of DevOps. A total of 18 challenges and 73 best practices were identified from the 69 primary studies. The identified challenges and best practices were further evaluated by conducting a survey with industry practitioners. The RMDevOps was developed based on other well‐established models in software engineering domain, for example, software process improvement readiness model (SPIRM) and software outsourcing vendor readiness model (SOVRM). Finally, case studies were conducted with three different organizations with an aim to validate the developed model. The results show that the RMDevOps is effective to assess and improve the DevOps practices in software organizations.},
journal = {J. Softw. Evol. Process},
month = {apr},
numpages = {25},
keywords = {case study, guidelines, best practices, readiness model}
}
@inproceedings{10.1109/ICSE-C.2017.162,
author = {Arta\v{c}, Matej and Borov\v{s}ak, Tadej and Di Nitto, Elisabetta and Guerriero, Michele and Tamburri, Damian Andrew},
title = {DevOps: Introducing Infrastructure-as-Code},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.162},
doi = {10.1109/ICSE-C.2017.162},
abstract = {DevOps entails a series of software engineering tactics aimed at shortening the actionable operation of software design changes. One of these tactics is to harness infrastructure-as-code, that is, writing a blueprint that contains deployment specifications ready for orchestration in the cloud. This abstract briefly discusses all necessary elements and abstractions in writing and maintaining that blueprint, revolving around a key standard for its expression, namely, the OASIS "Topology and Orchestration Specification for Cloud Applications" (TOSCA) industrial standard adopted by as many as 60+ big industrial players worldwide.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {497–498},
numpages = {2},
keywords = {TOSCA, infrastructure-as-code, DevOps},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}
@article{10.1007/s00450-016-0337-0,
author = {Zimmermann, Olaf},
title = {Microservices Tenets},
year = {2017},
issue_date = {July      2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {3–4},
issn = {1865-2034},
url = {https://doi.org/10.1007/s00450-016-0337-0},
doi = {10.1007/s00450-016-0337-0},
abstract = {Some microservices proponents claim that microservices form a new architectural style; in contrast, advocates of service-oriented architecture (SOA) argue that microservices merely are an implementation approach to SOA. This overview and vision paper first reviews popular introductions to microservices to identify microservices tenets. It then compares two microservices definitions and contrasts them with SOA principles and patterns. This analysis confirms that microservices indeed can be seen as a development- and deployment-level variant of SOA; such microservices implementations have the potential to overcome the deficiencies of earlier approaches to SOA realizations by employing modern software engineering paradigms and Web technologies such as domain-driven design, RESTful HTTP, IDEAL cloud application architectures, polyglot persistence, lightweight containers, a continuous DevOps approach to service delivery, and comprehensive but lean fault management. However, these paradigms and technologies also cause a number of additional design choices to be made and create new options for many "distribution classics" type of architectural decisions. As a result, the cognitive load for (micro-)services architects increases, as well as the design, testing and maintenance efforts that are required to benefit from an adoption of microservices. To initiate and frame the buildup of architectural knowledge supporting microservices projects, this paper compiles related practitioner questions; it also derives research topics from these questions. The paper concludes with a summarizing position statement: microservices constitute one particular implementation approach to SOA (service development and deployment).},
journal = {Comput. Sci.},
month = {jul},
pages = {301–310},
numpages = {10},
keywords = {IDEAL cloud application architectures, Architectural principles, Loose coupling, Service-oriented computing, Systems management, Architectural styles, Messaging, Patterns, REST, SOA, DevOps, Domain-driven design}
}
@inproceedings{10.1109/ICGSE.2019.00-10,
author = {Gupta, Rajeev Kumar and Venkatachalapathy, Mekanathan and Jeberla, Ferose Khan},
title = {Challenges in Adopting Continuous Delivery and DevOps in a Globally Distributed Product Team: A Case Study of a Healthcare Organization},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICGSE.2019.00-10},
doi = {10.1109/ICGSE.2019.00-10},
abstract = {This paper presents our experiences in a project of a software engineering team spread across three countries that successfully established continuous delivery, DevOps and short release cycles with agile scrum. We had the challenge to find a way from established regulatory heavy-weight processes, long release strategies, legacy tools and technologies and people mindset towards adopting continuous delivery and DevOps.We are describing our experiences in the journey towards timeboxed release strategies compared to legacy fixed scope-based releases; value stream-based execution compared to traditional milestone-based execution; operation, test, and infrastructure as a code compared to executing these activities manually. This paper also describes experiences in transforming traditional scrum team into a DevOps team, technological landscape into lightweight tools. The authors bring their experiences as a Project Manager, Quality Manager, and an Architect, who has been an integral part of this journey.These practices have helped in stabilizing processes and methods to an extent where we have released several products versions within a year. The other business units are adopting our practices for continuous delivery and DevOps. This paper also summaries our lessons learned, and recommendations.},
booktitle = {Proceedings of the 14th International Conference on Global Software Engineering},
pages = {30–34},
numpages = {5},
keywords = {test as code, operation as code, DevOps, continuous delivery},
location = {Montreal, Quebec, Canada},
series = {ICGSE '19}
}
@inproceedings{10.1145/3147704.3147709,
author = {Theunissen, Theo and Van Heesch, Uwe},
title = {Specification in Continuous Software Development},
year = {2017},
isbn = {9781450348485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147704.3147709},
doi = {10.1145/3147704.3147709},
abstract = {The procession of lean, agile and DevOps development processes introduces new challenges and offers new chances regarding software specification and documentation. Challenges for instance because specifications, just like code and applications, are subject to continuous change; chances, because continuous software processes make use of a high degree of automation which also introduces efficient means for specification and documentation.In this paper, we describe the continuous software design specification pattern, which contains guidelines and principles for specification in continuous development processes. In these processes, a software system is an evolution of life cycles where each iteration has a start, continuation and end of defining specifications. Therefore, the pattern explicitly distinguishes specifications to be created at the start of an iteration, specifications during an iteration, and a specification-refactoring at the end of each iteration. Apart from the pattern description, this paper describes the principles of continuous software development derived from lean software development, agile, and DevOps.},
booktitle = {Proceedings of the 22nd European Conference on Pattern Languages of Programs},
articleno = {5},
numpages = {19},
keywords = {Agile, DevOps, Continuous Development, Lean, Software engineering},
location = {Irsee, Germany},
series = {EuroPLoP '17}
}
@article{10.1007/s00450-017-0385-0,
author = {Kehrer, Stefan and Blochinger, Wolfgang},
title = {TOSCA-Based Container Orchestration on Mesos},
year = {2018},
issue_date = {August    2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {3–4},
issn = {1865-2034},
url = {https://doi.org/10.1007/s00450-017-0385-0},
doi = {10.1007/s00450-017-0385-0},
abstract = {Container virtualization evolved into a key technology for deployment automation in line with the DevOps paradigm. Whereas container management systems facilitate the deployment of cloud applications by employing container-based artifacts, parts of the deployment logic have been applied before to build these artifacts. Current approaches do not integrate these two deployment phases in a comprehensive manner. Limited knowledge on application software and middleware encapsulated in container-based artifacts leads to maintainability and configuration issues. Besides, the deployment of cloud applications is based on custom orchestration solutions leading to lock-in problems. In this paper, we propose a two-phase deployment method based on the TOSCA standard. We present integration concepts for TOSCA-based orchestration and deployment automation using container-based artifacts. Our two-phase deployment method enables capturing and aligning all the deployment logic related to a software release leading to better maintainability. Furthermore, we build a container management system, which is composed of a TOSCA-based orchestrator on Apache Mesos, to deploy container-based cloud applications automatically.},
journal = {Comput. Sci.},
month = {aug},
pages = {305–316},
numpages = {12},
keywords = {TOSCA, Apache Mesos, DevOps, Container-based artifacts, Two-phase deployment, Container orchestration}
}
@book{10.5555/2845112,
author = {Familiar, Bob},
title = {Microservices, IoT, and Azure: Leveraging DevOps and Microservice Architecture to Deliver SaaS Solutions},
year = {2015},
isbn = {1484212762},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {This book provides practical guidance for adopting a high velocity, continuous delivery process to create reliable, scalable, Software-as-a-Service (SaaS) solutions that are designed and built using a microservice architecture, deployed to the Azure cloud, and managed through automation. Microservices, IoT, and Azure offers software developers, architects, and operations engineers step-by-step directions for building SaaS applicationsapplications that are available 24x7, work on any device, scale elastically, and are resilient to change--through code, script, exercises, and a working reference implementation. The book provides a working definition of microservices and contrasts this approach with traditional monolithic Layered Architecture. A fictitious, homebiomedical startup is used to demonstrate microservice architecture and automation capabilities for cross-cutting and business services as well as connected device scenarios for Internet of Things (IoT). Several Azure PaaS services are detailed including Storage, SQL Database, DocumentDb, Redis Cache, Cloud Services, Web API's, API Management, IoT Hub, IoT Suite, Event Hub, and Stream Analytics. Finally the book looks to the future and examines Service Fabric to see how microservices are becoming the de facto approach to building reliable software in the cloud. What youll learn What microservices are and why are theyre a compelling architecture pattern for SaaS applications How to design, develop, and deploy microservices using Visual Studio, Power Shell, and Azure Microservice patterns for cross-cutting concerns and business capabilities Microservice patterns for Internet of Things and big data analytics solutions using IoT Hub, Event Hub, and Stream AnalyticsTechniques for automating microservice provisioning, building, and deployment What Service Fabric is and how its the future direction for microservices on Microsoft Azure Who this book is for Software Application Architects, .NET Developers, Database Admins and DevOps engineers. The code samples will primarily be in C# but will also include Node.JS samples.}
}
@article{10.1002/smr.2263,
author = {Khan, Arif Ali and Shameem, Mohammad},
title = {Multicriteria Decision‐making Taxonomy for DevOps Challenging Factors Using Analytical Hierarchy Process},
year = {2020},
issue_date = {October 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {32},
number = {10},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2263},
doi = {10.1002/smr.2263},
abstract = {Development and operations (DevOps) practices significantly accelerate and automate the continuous delivery and deployment of software systems. However, adopting DevOps concepts is not a straightforward job. Most organizations are not able to keep pace with the rhythm of continuous delivery and deployment, which are key DevOps attributes. Despite the significance of DevOps programs, it is still unknown why software development firms are demotivated or unable to adopt them. We tried to fill this gap by investigating, prioritizing, and developing the taxonomy of the key factors that could impact the adaptation and implementation of DevOps practices. We extracted a total of 16 factors from the available literature and empirically assessed them using the survey approach. The identified factors are further classified into three core categories of the software process improvement (SPI) manifesto. The analytical hierarchy process (AHP) approach was used to calculate the prioritization weight for each factor and present it as a taxonomy. The developed taxonomy provides a roadmap to tackle the key challenges to implementing DevOps and offers suggestions for streamlining DevOps practices.},
journal = {J. Softw. Evol. Process},
month = {oct},
numpages = {26},
keywords = {AHP, Prioritization, DevOps, Taxonomy, Challenging Factors}
}
@book{10.5555/3164836,
author = {Ambler, Scott W. and Lines, Mark},
title = {An Executive's Guide to Disciplined Agile: Winning the Race to Business Agility (Volume 1)},
year = {2017},
isbn = {1539852962},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
abstract = {The agile community has figured out how to build and then continually improve very high-performance software development teams. This is akin to creating a race car engine and then evolving it to get more power, better fuel efficiency, and greater speed. Sadly in many cases we take these great engines, put them into an organizational tractor, and then complain that were not winning the race. What we need to do is take our great race car engines (our development teams), put them into a race car (a DevOps ecosystem), have a great pit crew and driver (an effective IT organization), and then provide somewhere to race (an organization that can leverage IT to make money). Thats what this book is all about Moving from optimizing team performance to optimizing the entire enterprise. Business agility being an adaptive, lean, responsive, and learning organization is the race that enterprises need to win today. Yet there is no quick fix, no silver bullet, to attain business agility. This is a multi-year journey requiring hard work, experimentation, and most importantly a willingness to improve. The Disciplined Agile framework lowers risks and provides a path to accelerate your journey to business agility. The framework is unique in that it is the only one that puts all the pieces together into a cohesive enterprise roadmap for business agility transformation. This book begins with an overview of the challenges and opportunities that organizations face. We then describe seven principles that provide the underpinnings of the Disciplined Agile framework. Then the book works through Disciplined Agile Delivery (how to build a world-class engine), Disciplined DevOps (the race car), Disciplined Agile IT (the race car and its team), and what it means to be a Disciplined Agile Enterprise (the racing business). The book ends with a plan for starting with an Agile transformation and then evolving into a long-term continuous improvement strategy. Do you have the discipline it takes to win the race to business agility?}
}
@proceedings{10.1145/3185768,
title = {ICPE '18: Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 9th ACM/SPEC International Conference on Performance Engineering (ICPE 2018), being held in Berlin, Germany from April 9 to 13, 2018. The goal of the ACM/SPEC International Conference on Performance Engineering (ICPE) is to integrate theory and practice in the field of performance engineering by providing a forum for sharing ideas and experiences between industry and academia.The call for contributions solicited submissions for several tracks, namely for research papers, industry/experience papers, work-in-progress/vision papers, artifacts (for accepted full papers), posters and demonstrations, tutorials, and workshops.In the research track, 14 out of 59 papers were accepted as full papers. Hence, the full paper acceptance rate is 24 %. Two full papers received an ACM artifact badge after the subsequent review process in the newly introduced artifact evaluation track. Seven submissions were accepted as short research papers. In the industry/experience track, four out of 16 papers were accepted as full papers. Six submissions were accepted as short papers. The awards chairs selected three papers from the research track and two papers from the industry/experience track as candidates for the best paper award. The winner for both tracks will be announced during the banquet, after the candidates have presented their work during the conference. In the work-in-progress/vision track, ten out of 23 papers were accepted.The technical program features the following three invited keynotes: Peter Braam: Performance Engineering for the SKA TelescopeMichael R. Lyu: AI Techniques in Software Engineering ParadigmAad van Moorsel: Benchmarks and Models for BlockchainIn addition, the technical program includes three tutorials, the presentation of the SPEC Distinguished Dissertation Award, a poster and demonstration session, as well as six workshops on Performance Analysis of Big data Systems (PABS), Hot Topics in Cloud Computing Performance (HotCloudPerf), Challenges in Performance Methods for Software Development (WOSP-C), Load Testing and Benchmarking of Software Systems (LTB), Energy-aware Simulation and Modelling (ENERGY-SIM), and Quality-Aware DevOps (QUDOS).The program covers traditional ICPE topics such as performance modeling, prediction, optimization, monitoring, profiling, load testing, benchmarking, and runtime adaptation for fields such as cloud and high performance computing, big data, energy, and enterprise applications.},
location = {Berlin, Germany}
}
@proceedings{10.1145/3053600,
title = {ICPE '17 Companion: Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 8th ACM/SPEC International Conference on Performance Engineering (ICPE), taking place in L'Aquila, Italy, in April 22-26, 2017. The goal of ICPE is to integrate theory and practice in the field of performance engineering by providing a forum for sharing ideas and experiences between industry and academia. ICPE grew out of the ACM Workshop on Software Performance (WOSP Est. 1998) and the SPEC International Performance Engineering Workshop (SIPEW Est. 2008). It is a great pleasure to introduce the exciting program for this year's conference in which researchers and practitioners present their latest research, newest innovations, and vision for the future of performance engineering.We received 83 high quality submissions across the Research, Industry/Experience and Work-Inprogress/ Vision tracks. The Research Track attracted 65 submissions with 24 papers (22 full, 2 short) accepted for presentation. In the Work-In-Progress/Vision Track 14 out of 25 contributions were selected and the Industry/Experience track attracted 18 submissions of which 5 were accepted for presentation. Each paper received at least three reviews from program committee members. Four best paper award candidates were also selected. The best paper is to be announced during the ICPE 2017 social event, after all four papers are presented at the conference.We are excited to also present three keynote talks as part of the technical program. Micro-Benchmarking Considered Harmful; When the Whole is Faster or Slower Than the Sum of its Parts, by Thomas Wuerthinger (Oracle Labs)Performance is Also a Matter of Where You Live, by Francesco Quaglia (University of Rome La Sapienza)Autonomic storage management at scale, by Arif Merchant (Google)In addition, the program includes five tutorials, a poster and demo track, the SPEC Distinguished Dissertation Award, and eight interesting workshops on Autonomous Control for Performance and Reliability Trade-offs in Internet of Services (ACPROSS), on Performance Analysis of Big Data Systems (PABS), on Challenges in Performance Methods for Software Development (WOSP-C), on Energy-aware Simulation (ENERGY-SIM), on Load Testing and Benchmarking of Software Systems (LTB), on Monitoring in Large-Scale Software Systems (MoLS), on Education and Practice of Performance Engineering (WEPPE), and on Quality-aware DevOps (QUDOS).The program covers traditional ICPE topics such as design for performance and problem diagnosis, online performance management, analytic models, empirical studies, model building, and benchmarking, as well as application of performance engineering theory and techniques to several practical fields, including distributed systems, cloud computing, storage, energy, big data, virtualized systems, and hardware.},
location = {L'Aquila, Italy}
}
@book{10.5555/3309045,
author = {Garverick, Josh},
title = {Migrating to Azure: Transforming Legacy Applications into Scalable Cloud-First Solutions},
year = {2018},
isbn = {1484235843},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Design an enterprise solution from scratch that allows the migration of a legacy application. Begin with the planning and design phase and be guided through all the stages of selecting the architecture framework that fits your enterprise. Join Microsoft MVP Josh Garverick as he addresses all major areas of design and implementation application, infrastructure, data, security, and deployment while leveraging the power and tools of Visual Studio Team Services (VSTS) to bring DevOps to the forefront. With an emphasis on principles and best practices of enterprise design, you will discover how to recognize existing patterns within the legacy platform and to identify potential risks, bottlenecks, and candidates for automation. What Youll Learn Accurately and completely capture baseline information about a legacy system Leverage enterprise patterns for constructing next-generation platforms in the cloud Design, plan, and implement deployment pipelines to enable continuous delivery Identify and implement cloud-based platform components to reduce total cost of ownership Understand testing and validation: iterative component authoring, monitoring, deployment, and performance Price and perform capacity planning for cloud-based infrastructure and workloads Who This Book Is For Enterprise architects and IT professionals who are required to keep legacy applications relevant in todays cloud-first world}
}
@proceedings{10.1145/3184407,
title = {ICPE '18: Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering},
year = {2018},
isbn = {9781450350952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 9th ACM/SPEC International Conference on Performance Engineering (ICPE 2018), being held in Berlin, Germany from April 9 to 13, 2018. The goal of the ACM/SPEC International Conference on Performance Engineering (ICPE) is to integrate theory and practice in the field of performance engineering by providing a forum for sharing ideas and experiences between industry and academia.The call for contributions solicited submissions for several tracks, namely for research papers, industry/experience papers, work-in-progress/vision papers, artifacts (for accepted full papers), posters and demonstrations, tutorials, and workshops.In the research track, 14 out of 59 papers were accepted as full papers. Hence, the full paper acceptance rate is 24 %. Two full papers received an ACM artifact badge after the subsequent review process in the newly introduced artifact evaluation track. Seven submissions were accepted as short research papers. In the industry/experience track, four out of 16 papers were accepted as full papers. Six submissions were accepted as short papers. The awards chairs selected three papers from the research track and two papers from the industry/experience track as candidates for the best paper award. The winner for both tracks will be announced during the banquet, after the candidates have presented their work during the conference. In the work-in-progress/vision track, ten out of 23 papers were accepted.The technical program features the following three invited keynotes: Peter Braam: Performance Engineering for the SKA TelescopeMichael R. Lyu: AI Techniques in Software Engineering ParadigmAad van Moorsel: Benchmarks and Models for BlockchainIn addition, the technical program includes three tutorials, the presentation of the SPEC Distinguished Dissertation Award, a poster and demonstration session, as well as six workshops on Performance Analysis of Big data Systems (PABS), Hot Topics in Cloud Computing Performance (HotCloudPerf), Challenges in Performance Methods for Software Development (WOSP-C), Load Testing and Benchmarking of Software Systems (LTB), Energy-aware Simulation and Modelling (ENERGY-SIM), and Quality-Aware DevOps (QUDOS).The program covers traditional ICPE topics such as performance modeling, prediction, optimization, monitoring, profiling, load testing, benchmarking, and runtime adaptation for fields such as cloud and high performance computing, big data, energy, and enterprise applications.},
location = {Berlin, Germany}
}
@inproceedings{10.5220/0007837000270039,
author = {Bolscher, Robin and Daneva, Maya},
title = {Designing Software Architecture to Support Continuous Delivery and DevOps: A Systematic Literature Review},
year = {2019},
isbn = {9789897583797},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0007837000270039},
doi = {10.5220/0007837000270039},
abstract = {This paper presents a systematic literature review of software architecture approaches that support the implementation of Continuous Delivery (CD) and DevOps. Its goal is to provide an understanding of the stateof-the-art on the topic, which is informative for both researchers and practitioners. We found 17 characteristics of a software architecture that are beneficial for CD and DevOps adoption and identified ten potential software architecture obstacles in adopting CD and DevOps in the case of an existing software system. Moreover, our review indicated that micro-services are a dominant architectural style in this context. Our literature review has some implications: for researchers, it provides a map of the recent research efforts on software architecture in the CD and DevOps domain. For practitioners, it describes a set of software architecture principles that possibly can guide the process of creating or adapting software systems to fit in the CD and DevOps context.},
booktitle = {Proceedings of the 14th International Conference on Software Technologies},
pages = {27–39},
numpages = {13},
keywords = {Micro-services., Continuous Integration, Software Architecture, Continuous Delivery, Systematic Literature Review, Deployability, DevOps},
location = {Prague, Czech Republic},
series = {ICSOFT 2019}
}
@book{10.5555/3154550,
author = {S., Senthil Kumaran},
title = {Practical LXC and LXD: Linux Containers for Virtualization and Orchestration},
year = {2017},
isbn = {148423023X},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Use Linux containers as an alternative virtualization technique to virtualize your operating system environment. This book will cover LXCs unmatched flexibility with virtualization and LXDs smooth user experience. Practical LXC and LXD begins by introducing you to Linux containers (LXC and LXD). You will then go through use cases based on LXC and LXD. Next, you will see the internal workings of LXC and LXD by considering the repositories and templates used. You will then learn how to integrate LXC and LXD with common virtualization and orchestration tools such as libvirt and SaltStack. Finally, you will dive into containerization and security. The book will explore some of the common problems in security and provide a case study on how containerization can help mitigate some of the operating system-level security issues in an IoT environment. What You Will LearnGet an introduction to Linux containers Discover the basics of LXC and LXD See use cases that can be solved with LXC and LXD for developers, devops, and system administrators Master LXC and LXD repositories Use LXC and LXD with common virtualization and orchestration tools Consider a containerization and security in IoT case study Who This Book Is ForThe audience for this book should have basic knowledge of Linux and software development in general. The intended readership is primarily software developers, operations engineers, and system administrators who are interested in devops, though managers and enthusiasts will also benefit from this book.}
}
@book{10.5555/3307241,
author = {Fawzy, Ahmed},
title = {A Beginner's Guide to DevOps &amp; Cloud: Concept &amp; Implementation},
year = {2018},
isbn = {1949814017},
abstract = {Learn How to Design Cloud Solutions and implement DevOpsWhat if you can design cloud solutions to improve your business services? What if you can utilize the DevOps methods and best practices to improve both development and operation process? Ahmed Fawzy, present an approached to improve IT Operations using DevOps and Cloud. Based on 14 years of experience building services for various organizations of different sizes across all sectors, Ahmed answer the question: How Cloud and DevOps deliver value to the Business? In this book you will learn: Understand Business Requirements How to become a DevOps Team member Create a process thats actually works How to migrate applications to Cloud How to realize the business value How to translate Goals into projects How to build a team, change the organization and overcome resistance. How to create a Business Case How to Assess the running processes and determine the GapLearn the core concepts of cloud computing What is a cloud? Private cloud, Public cloud IAAS, SAAS, PAAS Cloud benefits Advantages and disadvantages of cloud computing Learn the core concepts of DevOps Continuous delivery and continuous integration Infrastructure as code Get an overview on Microservices Containers Serverless Computing Site Reliability Engineering Learn this and more, Buy this book NOW to learn How Cloud and DevOps deliver value to the Business. Pick up your copy by clicking buy now at the top of this page!}
}
@book{10.5555/3360114,
author = {Rossberg, Joachim},
title = {Agile Project Management with Azure DevOps: Concepts, Templates, and Metrics},
year = {2019},
isbn = {1484244826},
publisher = {APress},
edition = {1st},
abstract = {Roll up your sleeves and jump into Agile project management to use and customize Microsoft Azure DevOps. Organizations adopt Agile practices because they are a key enabler to run better projects, get more successful end results, and achieve an overall higher quality output. To benefit the most from Agile, you need an Application Life Cycle Management (ALM) or DevOps toolset that supports your style and work environment. Agile Project Management with Azure DevOps teaches you how to use Azure DevOps to implement many Agile practices such as SAFe, Scrum, and Kanban, and it shows you how they fit into a well-planned Agile implementation. Agile product owners will learn how to work with Azure DevOps to set up a project from scratch, and to continue using Azure DevOps throughout. Keeping track of progress is important in any project. Author Joachim Rossberg teaches you about the tools in Azure DevOps that can help you track progress and key metrics, including those that are available right out of the box. You will learn how to create and refine the backlog, work with Kanban and Scrum task boards, and get exposed to valuable key concepts along the way. Finally, you will dive into Azure DevOps extensibility to learn about the many ways you can customize reporting to best meet your needs What You'll Learn Understand Agile product management concepts and processes for working with Azure DevOps Discover how Azure DevOps supports agile processes end-to-end Implement Agile processes in Azure DevOps Customize Azure DevOps to better support your processes Complete step-by-step setup of an Agile project from scratch and manage it through its life cycle Who This Book Is For Software product owners, Agile leaders, Scrum masters, and software engineers who use Microsoft Azure DevOps. A basic understanding of Agile is helpful.}
}
@book{10.5555/2888547,
author = {Binnie, Chris},
title = {Practical Linux Topics},
year = {2015},
isbn = {1484217713},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Teaches you how to improve your hands-on knowledge of Linux using challenging, real-world scenarios. Each chapter explores a topic that has been chosen specifically to demonstrate how to enhance your base Linux system, and resolve important issues. This book enables sysadmins, DevOps engineers, developers, and other technical professionals to make full use of Linuxs rocksteady foundation. Explore specific topics in networking, email, filesystems, encryption, system monitoring, security, servers, and more-- including systemd and GPG. Understand salient security concerns and how to mitigate them. Applicable to almost all Linux flavors--Debian, Red Hat, Ubuntu, Linux Mint, CentOS--Practical Linux Topics can be used to reference other Unix-type systems with little modification. Improve your practical know-how and background knowledge on servers and workstations alike, increase your ability to troubleshoot and ultimately solve the daily challenges encountered by all professional Linux users. Empower your Linux skills by adding PowerLinux Topicsto your library today. What You'll Learn Solve a variety of challenges faced by sysadmins and DevOps engineers Understand the security implications of the actions you takeStudy the history behind some of the packages that you are using for a greater in-depth understanding Become a professional at troubleshooting Extend your knowledge by learning about multiple OSs and third-party packages Who This Book Is For Having mastered the basics of running Linux systems this book takes you one step further to help you master the elements of Linux which you may have struggled with in the past. You have progressed past the basic stages of using Linux and want to delve into the more complex aspects. Practical Linuxinstantly offers answers to problematic scenarios and provides invaluable information for future reference. It is an invaluable addition to any Linux library.}
}
@inproceedings{10.1145/3484272.3484962,
author = {Hobeck, Richard and Weber, Ingo and Bass, Len and Yasar, Hasan},
title = {Teaching DevOps: A Tale of Two Universities},
year = {2021},
isbn = {9781450390897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3484272.3484962},
doi = {10.1145/3484272.3484962},
abstract = {DevOps is a set of practices in software engineering that is in high demand by industry. It is a dynamic field which constantly adds new methods and tools. Teaching DevOps prepares today’s computer science students for best-practices in a working environment but challenges university lecturers to provide central concepts while staying up-to-date with current trends. In this paper we report and reflect on our experiences teaching DevOps at two universities (in the USA and Germany) in an inverted classroom format. We describe how we set-up the courses, provide a brief analysis of data we collected, and share our lessons learned.},
booktitle = {Proceedings of the 2021 ACM SIGPLAN International Symposium on SPLASH-E},
pages = {26–31},
numpages = {6},
keywords = {DevOps, inverted classroom, software engineering},
location = {Chicago, IL, USA},
series = {SPLASH-E 2021}
}
@proceedings{10.1145/3030207,
title = {ICPE '17: Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 8th ACM/SPEC International Conference on Performance Engineering (ICPE), taking place in L'Aquila, Italy, in April 22-26, 2017. The goal of ICPE is to integrate theory and practice in the field of performance engineering by providing a forum for sharing ideas and experiences between industry and academia. ICPE grew out of the ACM Workshop on Software Performance (WOSP Est. 1998) and the SPEC International Performance Engineering Workshop (SIPEW Est. 2008). It is a great pleasure to introduce the exciting program for this year's conference in which researchers and practitioners present their latest research, newest innovations, and vision for the future of performance engineering.We received 83 high quality submissions across the Research, Industry/Experience and Work-Inprogress/ Vision tracks. The Research Track attracted 65 submissions with 24 papers (22 full, 2 short) accepted for presentation. In the Work-In-Progress/Vision Track 14 out of 25 contributions were selected and the Industry/Experience track attracted 18 submissions of which 5 were accepted for presentation. Each paper received at least three reviews from program committee members. Four best paper award candidates were also selected. The best paper is to be announced during the ICPE 2017 social event, after all four papers are presented at the conference.We are excited to also present three keynote talks as part of the technical program. Micro-Benchmarking Considered Harmful; When the Whole is Faster or Slower Than the Sum of its Parts, by Thomas Wuerthinger (Oracle Labs)Performance is Also a Matter of Where You Live, by Francesco Quaglia (University of Rome La Sapienza)Autonomic storage management at scale, by Arif Merchant (Google)In addition, the program includes five tutorials, a poster and demo track, the SPEC Distinguished Dissertation Award, and eight interesting workshops on Autonomous Control for Performance and Reliability Trade-offs in Internet of Services (ACPROSS), on Performance Analysis of Big Data Systems (PABS), on Challenges in Performance Methods for Software Development (WOSP-C), on Energy-aware Simulation (ENERGY-SIM), on Load Testing and Benchmarking of Software Systems (LTB), on Monitoring in Large-Scale Software Systems (MoLS), on Education and Practice of Performance Engineering (WEPPE), and on Quality-aware DevOps (QUDOS).The program covers traditional ICPE topics such as design for performance and problem diagnosis, online performance management, analytic models, empirical studies, model building, and benchmarking, as well as application of performance engineering theory and techniques to several practical fields, including distributed systems, cloud computing, storage, energy, big data, virtualized systems, and hardware.},
location = {L'Aquila, Italy}
}
@inproceedings{10.1145/2904354.2904372,
author = {Rong, Guoping and Zhang, He and Shao, Dong},
title = {CMMI Guided Process Improvement for DevOps Projects: An Exploratory Case Study},
year = {2016},
isbn = {9781450341882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2904354.2904372},
doi = {10.1145/2904354.2904372},
abstract = {Very recently, an increasing number of software companies adopted DevOps to adapt themselves to the ever-changing business environment. While it is important to mature adoption of the DevOps for these companies, no dedicated maturity models for DevOps exist. Meanwhile, maturity models such as CMMI models have demonstrated their effects in the traditional paradigm of software industry, however, it is not clear whether the CMMI models could guide the improvements with the context of DevOps. This paper reports a case study aiming at evaluating the feasibility to apply the CMMI models to guide process improvement for DevOps projects and identifying possible gaps. Using a structured method(i.e., SCAMPI C), we conducted a case study by interviewing four employees from one DevOps project. Based on evidence we collected in the case study, we managed to characterize the maturity/capability of the DevOps project, which implies the possibility to use the CMMI models to appraise the current processes in this DevOps project and guide future improvements. Meanwhile, several gaps also are identified between the CMMI models and the DevOps mode. In this sense, the CMMI models could be taken as a good foundation to design suitable maturity models so as to guide process improvement for projects adopting the DevOps.},
booktitle = {Proceedings of the International Conference on Software and Systems Process},
pages = {76–85},
numpages = {10},
keywords = {DevOps, software process improvement, CMMI},
location = {Austin, Texas},
series = {ICSSP '16}
}
@inproceedings{10.1007/978-3-030-39306-9_15,
author = {Caprarelli, Alessandro and Di Nitto, Elisabetta and Tamburri, Damian Andrew},
title = {Fallacies and Pitfalls on the Road to DevOps: A Longitudinal Industrial Study},
year = {2019},
isbn = {978-3-030-39305-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39306-9_15},
doi = {10.1007/978-3-030-39306-9_15},
abstract = {DevOps has come into play to help companies in improving their product delivery. This paper offers an overview of the fallacies and pitfalls faced in this context by engineers and operators in an industrial case-study. We reveal a total of 8 key fallacies and pitfalls that span the organisational structure, technical structures, as well as software process and delivery mechanisms in the target case-study. Practitioners can use these challenges as references for diagnosing their own scenario while planning their own potential DevOps process migration strategy.},
booktitle = {Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Ch\^{a}teau de Villebrumier, France, May 6–8, 2019, Revised Selected Papers},
pages = {200–210},
numpages = {11},
keywords = {DevOps quality, Process migration, Organizational and technical aspects},
location = {Villebrumier, France}
}
@inproceedings{10.1145/3297663.3309672,
author = {Bezemer, Cor-Paul and Eismann, Simon and Ferme, Vincenzo and Grohmann, Johannes and Heinrich, Robert and Jamshidi, Pooyan and Shang, Weiyi and van Hoorn, Andr\'{e} and Villavicencio, Monica and Walter, J\"{u}rgen and Willnecker, Felix},
title = {How is Performance Addressed in DevOps?},
year = {2019},
isbn = {9781450362399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297663.3309672},
doi = {10.1145/3297663.3309672},
abstract = {DevOps is a modern software engineering paradigm that is gaining widespread adoption in industry. The goal of DevOps is to bring software changes into production with a high frequency and fast feedback cycles. This conflicts with software quality assurance activities, particularly with respect to performance. For instance, performance evaluation activities --- such as load testing --- require a considerable amount of time to get statistically significant results.We conducted an industrial survey to get insights into how performance is addressed in industrial DevOps settings. In particular, we were interested in the frequency of executing performance evaluations, the tools being used, the granularity of the obtained performance data, and the use of model-based techniques. The survey responses, which come from a wide variety of participants from different industry sectors, indicate that the complexity of performance engineering approaches and tools is a barrier for wide-spread adoption of performance analysis in DevOps. The implication of our results is that performance analysis tools need to have a short learning curve, and should be easy to integrate into the DevOps pipeline in order to be adopted by practitioners.},
booktitle = {Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering},
pages = {45–50},
numpages = {6},
keywords = {software performance, devops, industrial practices, continuous integration},
location = {Mumbai, India},
series = {ICPE '19}
}
@inproceedings{10.1145/3391203.3391214,
author = {Maria, Tyrone Justin Sta and Dizon, Gavin Raine and Esquivel, Vince Anthony and Deja, Jordan Aiko and Chua, Unisse},
title = {Designing Grit: Discovering Features Towards Supporting Novice Programmer DevOps Integration},
year = {2020},
isbn = {9781450387682},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3391203.3391214},
doi = {10.1145/3391203.3391214},
abstract = {DevOps is usually an industry approach that is practiced by seasoned and experienced programmers and developers. In most university settings especially in the Philippine context, DevOps is not usually part of the curriculum and in some cases are only introduced to learner programmers as an elective or as bonus material. We refer to these students in computing degree programs starting out in learning programming, as novice programmers. Upon graduation, these developers transition into industry roles where they are expected to be familiar with DevOps practices [18]. In most cases, they are not prepared, and fortunately, a great number of them are given training before fully transitioning into their hired roles. In this paper, we attempt to discover and design an intervention mechanism that can assist and prepare novice programmers to easily learn DevOps at an early stage. We gathered data and insights from novice programmers and inquired into their pains and struggles in learning and practicing DevOps. To help them in this process, we propose Grit, a prototype tool to support novice programmers in integrating DevOps. Initial insights provided affordances and design elements for a version control prototype with targetted intervention features. In the long run we intend to discover more insights involving the other stages in DevOps beyond version control.},
booktitle = {Proceedings of the 2020 Symposium on Emerging Research from Asia and on Asian Contexts and Cultures},
pages = {41–44},
numpages = {4},
keywords = {DevOps, programmer support, novice programmers},
location = {Honolulu, HI, USA},
series = {AsianCHI '20}
}
@inproceedings{10.5555/3172795.3172847,
author = {Kontogiannis, Kostas and Cronin, Don and Giammaria, Alberto and Brealey, Chris and Grigoriou, Marios},
title = {DevOps Toolchains for Continuous Engineering and Improvement},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {The workshop participants focused-on, and primarily discussed, three main areas a) models to denote and reconcile software system related data, obtained from different and diverse DevOps sources such as version control systems, bug reporting systems, collaboration tools and testing frameworks; b) analytics on software artifacts stored or created by DevOps tools; these artifacts include not only source code but also deployment scripts, configuration files, build specifications, bug reports, version histories, developer's comments and notes and c) infrastructures to support continuous maintenance and deployment by providing insights on deploy or no-deploy decision making choices, and by considering and analyzing information that is collected from the overall application and its constituent components. The workshop topics are related to the IBM DevOps Analytics, IBM DevOps Insights, and IBM DevOps Continuous Delivery (Open Toolchain) frameworks.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {326},
numpages = {1},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}
@article{10.1145/3448976,
author = {Chen, Boyuan and Jiang, Zhen Ming (Jack)},
title = {A Survey of Software Log Instrumentation},
year = {2021},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3448976},
doi = {10.1145/3448976},
abstract = {Log messages have been used widely in many software systems for a variety of purposes during software development and field operation. There are two phases in software logging: log instrumentation and log management. Log instrumentation refers to the practice that developers insert logging code into source code to record runtime information. Log management refers to the practice that operators collect the generated log messages and conduct data analysis techniques to provide valuable insights of runtime behavior. There are many open source and commercial log management tools available. However, their effectiveness highly depends on the quality of the instrumented logging code, as log messages generated by high-quality logging code can greatly ease the process of various log analysis tasks (e.g., monitoring, failure diagnosis, and auditing). Hence, in this article, we conducted a systematic survey on state-of-the-art research on log instrumentation by studying 69 papers between 1997 and 2019. In particular, we have focused on the challenges and proposed solutions used in the three steps of log instrumentation: (1) logging approach; (2) logging utility integration; and (3) logging code composition. This survey will be useful to DevOps practitioners and researchers who are interested in software logging.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {90},
numpages = {34},
keywords = {instrumentation, Systematic survey, software logging}
}
@inproceedings{10.1145/2978192.2978205,
author = {Betz, Charles and Olagunju, Amos O. and Paulson, Patrick},
title = {The Impacts of Digital Transformation, Agile, and DevOps on Future IT Curricula},
year = {2016},
isbn = {9781450344524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2978192.2978205},
doi = {10.1145/2978192.2978205},
abstract = {Prior practices such as waterfall software development, project management, and IT process frameworks are being questioned, and workforce requirements changing in response. IT education must keep current with these digital trends. Present programs and curricula do not adequately meet the rapidly emerging demand for digitally-skilled professionals. To address this urgent need, the lightening talk discusses needs for digital transformation, Agile and DevOps skills. This lightening talk presents the first version of an IT curriculum reference guide recently developed for use in the Minnesota State Colleges and Universities system. The audience will be able to use this guide to embed digital and DevOps skills into new IT curriculum, modify existing IT curriculum, or develop new courses/programs for IT.},
booktitle = {Proceedings of the 17th Annual Conference on Information Technology Education},
pages = {106},
numpages = {1},
keywords = {it curriculum, agile, digital technology, devops},
location = {Boston, Massachusetts, USA},
series = {SIGITE '16}
}
@inproceedings{10.1007/978-3-030-39306-9_6,
author = {Combemale, Benoit and Wimmer, Manuel},
title = {Towards a Model-Based DevOps for Cyber-Physical Systems},
year = {2019},
isbn = {978-3-030-39305-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39306-9_6},
doi = {10.1007/978-3-030-39306-9_6},
abstract = {The emerging field of Cyber-Physical Systems (CPS) calls for new scenarios of the use of models. In particular, CPS require to support both the integration of physical and cyber parts in innovative complex systems or production chains, together with the management of the data gathered from the environment to drive dynamic reconfiguration at runtime or finding improved designs. In such a context, the engineering of CPS must rely on models to uniformly reason about various heterogeneous concerns all along the system life cycle. In the last decades, the use of models has been intensively investigated both at design time for driving the development of complex systems, and at runtime as a reasoning layer to support deployment, monitoring and runtime adaptations. However, the approaches remain mostly independent. With the advent of DevOps principles, the engineering of CPS would benefit from supporting a smooth continuum of models from design to runtime, and vice versa. In this vision paper, we introduce a vision for supporting model-based DevOps practices, and we infer the corresponding research roadmap for the modeling community to address this vision by discussing a CPS demonstrator.},
booktitle = {Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Ch\^{a}teau de Villebrumier, France, May 6–8, 2019, Revised Selected Papers},
pages = {84–94},
numpages = {11},
location = {Villebrumier, France}
}
@book{10.5555/3208552,
author = {Lines, Mark and Ambler, Scott William},
title = {Introduction to Disciplined Agile Delivery 2nd Edition: A Small Agile Team's Journey from Scrum to Disciplined DevOps},
year = {2018},
isbn = {1983891304},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
edition = {2nd},
abstract = {Introduction to Disciplined Agile Delivery 2nd Edition provides a quick overview of how agile software development works from beginning-to-end. It describes Disciplined Agile Delivery (DAD), the first of four levels of the Disciplined Agile (DA) process decision framework, and works through a case study describing a typical agile teams experiences adopting a DA approach. The book describes how the team develops the first release of a mission-critical application while working in a legacy enterprise environment. It describes their experiences from beginning-to-end, starting with their initial team initiation efforts through construction and finally to deploying the solution into production. It also describes how the team stays together for future releases, overviewing their process improvement efforts from their Scrum-based beginnings through to a lean continuous delivery approach that fits in with their organizations evolving DevOps strategy. The DAD framework is a hybrid of existing methods such as Scrum, Kanban, Agile Modeling, SAFe, Extreme Programming, Agile Data, Unified Process and many others. DAD provides the flexibility to use various approaches and plugs the gaps not addressed by mainstream agile methods. In a nutshell, DAD is pragmatic agile. DAD describes proven strategies to adapt and scale your agile initiatives to suit the unique realities of your enterprise without having to figure it all out by yourself. Heres an overview of what each chapter covers: Chapter 1: Introduction. This chapter provides a quick overview of the book and a brief history of Disciplined Agile. Chapter 2: Reality over Rhetoric. This chapter explores several common myths about DAD and more importantly disproves them. Chapter 3: Disciplined Agile Delivery in a Nutshell. This chapter provides a brief yet comprehensive overview of DAD. Chapter 4: Introduction to the Case Study. This chapter introduces us to the team, describes the market opportunity that they hope to address, and describes the environment in which theyre working. Chapter 5: Inception. The teams initiation effort includes initial requirements modeling and planning with their stakeholders in a streamlined manner, initial architecture modeling, setting up their physical work environment, setting up the start of their tooling infrastructure, initial risk identification, and finally securing stakeholder support and funding for the rest of the first release. Chapters 6 through 10: Construction. These chapters each describe a single Construction iteration, sharing the teams experiences during each of those two-week timeboxes. Chapter 11: Transition. The two-week transition phase focuses on final testing and fixing, training the support/help-desk staff, finishing a few short end-user how to videos, and deploying the solution into production. Chapter 12: The Road to Disciplined DevOps. This chapter overviews the teams improvement efforts over the next few releases, describing how they evolve from the agile Scrum-based lifecycle to a leaner approach and eventually to continuous delivery. All of this dovetails into their organizations efforts to implement a Disciplined DevOps strategy. Chapter 13: Closing Thoughts. This chapter overviews the disciplined agile resources that are available to you. Appendix: The Disciplined Agile Framework. This short appendix overviews our ongoing work on the Disciplined Agile framework to address the full scope of an agile business. At 111 pages, you should find this book to be a quick, informative read. Whats Different in This Edition: Chapter 3 was completely rewritten to reflect the changes to DAD. Chapter 12 was rewritten to describe how the team evolved into a Disciplined DevOps strategy. Appendix A was rewritten to reflect the latest release of the DA framework. General updates were made throughout the book.}
}
@inproceedings{10.1109/ASE51524.2021.9678554,
author = {Galappaththi, Akalanka and Anvik, John and Islam, Rafat Bin},
title = {Automatically Annotating Sentences for Task-Specific Bug Report Summarization},
year = {2021},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678554},
doi = {10.1109/ASE51524.2021.9678554},
abstract = {There is a need to summarize bug reports as they can become long due to many comments from conversations between developers and various DevOps tools. Although automated approaches to bug report summarization have been developed, we believe they aim at the wrong target - getting as close as possible to a gold-standard summary. Instead, researchers should create automated bug report annotation approaches that allow project members to create summaries based on their task-specific information needs. We present such an approach.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1177–1179},
numpages = {3},
keywords = {text annotation, natural language processing, text tagging, bug report summarization},
location = {Melbourne, Australia},
series = {ASE '21}
}
@book{10.5555/3131534,
author = {Chandrasekara, Chaminda},
title = {Beginning Build and Release Management with TFS 2017 and VSTS: Leveraging Continuous Delivery for Your Business},
year = {2017},
isbn = {1484228103},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Master build and release management with Team Foundation Service and Visual Studio Team Services to facilitate the continuous delivery of software updates to your development team. You'll receive detailed, practical guidance on automating website deployments in Azure App Service, database deployments to Azure platform, Micro Services deployments in Azure Service Fabric, and more. Each deployment is structured with the aid of hands-on lessons in a given target environment designed to empower your teams to achieve successful DevOps. This book provides lessons on how to optimize build release management definitions using capabilities, such as task groups. With the help of practical scenarios, youll also learn how to diagnose and fix issues in automated builds and deployments. Youll see how to enhance the capability of build and release management, using team services/TFS Marketplace extensions and writing your own extensions for any missing functionality via hands-on lessons. What You Will Learn Automate deployment to Azure platform, including Web App Service, Azure SQL and Azure Service FabricTest automation integration with builds and deployments Perform Dynamic CRM deployment handling and package management with TFS/VSTS Examine requirement to production delivery traceability in practical terms Review cross platform build/deployment capabilities of TFS/VSTS. Who This Book Is For Build/Release Engineers, Configuration Managers, Software Developers, Test Automation Engineers, System Engineers, Software Architects and System/Production Support Engineers or anyone who handles and involves in the software delivery process.}
}
@inproceedings{10.1145/3053600.3053618,
author = {Janes, Andrea and Lenarduzzi, Valentina and Stan, Alexandru Cristian},
title = {A Continuous Software Quality Monitoring Approach for Small and Medium Enterprises},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053618},
doi = {10.1145/3053600.3053618},
abstract = {Context: SMEs cannot always afford the effort required for software quality assurance, and therefore there is the need of easy and affordable practices to prevent issues in the software they develop.Object: In this paper we propose an approach to allow SMEs to access SQA practices, using an SQA approach based on a continuous issue and error monitoring and a recommendation system that will suggest quality practices, recommending a set of quality actions based on the issues that previously created errors, so as to help SMEs to maintain quality above a minimum threshold. Method: First, we aim to identify a set of SQA practices applicable in SMEs, based on the main constraints of SMEs and a set of tools and practices to fulfill a complete DevOps pipeline. Second, we aim to define a recommendation system to provide software quality feedback to micro-teams, suggesting which action(s) they should take to maintain a certain quality level and allowing them to remove the most severe issues with the lowest possible effort. Our approach will be validated by a set of local SMEs. Moreover, the tools developed will be published as Open Source.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {97–100},
numpages = {4},
keywords = {code smells, software monitoring, software maintenance, anti-patterns, continuous quality assurance},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}
@inproceedings{10.1109/ICSE-SEIP.2019.00034,
author = {Rong, Guoping and Jin, Zefeng and Zhang, He and Zhang, Youwen and Ye, Wenhua and Shao, Dong},
title = {DevDocOps: Towards Automated Documentation for DevOps},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00034},
doi = {10.1109/ICSE-SEIP.2019.00034},
abstract = {The proliferation of DevOps enables significant acceleration and automation of the delivery and deployment of massive software products. Unfortunately, the development of supporting documents that is vital for large scale software systems in many cases does not keep pace with the rhythm of feature delivery using DevOps in practice, which becomes the bottleneck for many software organizations to deliver full value to the customers as claimed by DevOps. This paper proposes, implements, and evaluates a new approach, DevDocOps, for continuous automated documentation, in particular for DevOps. With DevDocOps, developers are able to create the documents simultaneously with their working versions of software, which largely guarantees the accuracy and integrity of documents as well as significantly increases their delivery speed. Within an established delivery chain, a set of templates are created to collect and transform the required information from its origin to the target documents for delivery. A real system, iDoc, is implemented to map, collect, and synthesizethe information from document templates and automate the documentation process. The iDoc system supports the generation of documents in minutes and the instant feedback loop as well. DevDocOps has been successfully adopted in over 30 large software projects in a top tier global telecommunication enterprise. The lag time between the releases of the product version and its supporting document has been shortened from 1--2 months on average to less than 2 days. DevDocOps extends the scope of DevOps and enhances the value delivery by supporting continuous documentation and bridging the gap between feature delivery and document delivery with automation.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {243–252},
numpages = {10},
keywords = {continuous delivery, DevOps},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}
@inproceedings{10.1145/3011141.3011200,
author = {Ohtsuki, Mika and Ohta, Kazuki and Kakeshita, Tetsuro},
title = {Software Engineer Education Support System ALECSS Utilizing DevOps Tools},
year = {2016},
isbn = {9781450348072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011141.3011200},
doi = {10.1145/3011141.3011200},
abstract = {Various types of DevOps tools are widely used for software development in order to ensure software quality and quick delivery of the software. Typical examples of such DevOps tools are continuous integration tool Jenkins, version control tool Git, unit test tool JUnit, coding style checker Checkstyle and static code analysis tool FindBugs. In this paper, we propose an education support system ALECSS to train software developers by integrating several DevOps tools explained above. The system automatically checks the programs submitted by the student teams and provides feedbacks generated by the DevOps tools to the students. The feedbacks are valuable to learn various techniques for high quality software development and to support evaluation by the teacher. We also develop various scripts for output checking and Git working status checking. These scripts use exercise contents and student's information in checking and sometimes need to generate typical results from templates for comparing them with the students' answers. Such scripts are also integrated to ALECSS. We evaluate ALECSS by comparing the messages generated by Checkstyle and FindBugs with the review comments produced the student teams. We found that the automatically generated messages and the review comments are greatly differ so that both are important for effective education.},
booktitle = {Proceedings of the 18th International Conference on Information Integration and Web-Based Applications and Services},
pages = {209–213},
numpages = {5},
keywords = {education support system, software quality, DevOps tools, web-based system, cooperative software development, e-leaning},
location = {Singapore, Singapore},
series = {iiWAS '16}
}
@inproceedings{10.5220/0007966505360543,
author = {Papamichail, Michail and Diamantopoulos, Themistoklis and Matsoukas, Vasileios and Athanasiadis, Christos and Symeonidis, Andreas},
title = {Towards Extracting the Role and Behavior of Contributors in Open-Source Projects},
year = {2019},
isbn = {9789897583797},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0007966505360543},
doi = {10.5220/0007966505360543},
abstract = {Lately, the popular open source paradigm and the adoption of agile methodologies have changed the way software is developed. Effective collaboration within software teams has become crucial for building successful products. In this context, harnessing the data available in online code hosting facilities can help towards understanding how teams work and optimizing the development process. Although there are several approaches that mine contributions data, they usually view contributors as a uniform body of engineers, and focus mainly on the aspect of productivity while neglecting the quality of the work performed. In this work, we design a methodology for identifying engineer roles in development teams and determine the behaviors that prevail for each role. Using a dataset of GitHub projects, we perform clustering against the DevOps axis, thus identifying three roles: developers that are mainly preoccupied with code commits, operations engineers that focus on task assignment and acceptance testing, and the lately popular role of DevOps engineers that are a mix of both. Our analysis further extracts behavioral patterns for each role, this way assisting team leaders in knowing their team and effectively directing responsibilities to achieve optimal workload balancing and task allocation.},
booktitle = {Proceedings of the 14th International Conference on Software Technologies},
pages = {536–543},
numpages = {8},
keywords = {DevOps, Agile., GitHub Contributions, Developer Role Identification, Developer Behavior Extraction},
location = {Prague, Czech Republic},
series = {ICSOFT 2019}
}
@book{10.5555/3180962,
author = {Leonard, Andy and Currie, Scott and Alley, Jacob and Andersson, Martin and Avenant, Peter and Fellows, Bill and Peck, Simon and Smith, Reeves and Sondak, Raymond and Weissman, Benjamin and Wilhelmsen, Cathrine},
title = {The Biml Book: Business Intelligence and Data Warehouse Automation},
year = {2017},
isbn = {1484231341},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Learn Business Intelligence Markup Language (Biml)for automating much of the repetitive, manual labor involved in data integration. We teach you how to build frameworks and use advanced Biml features to get more out of SQL Server Integration Services (SSIS), Transact-SQL (T-SQL), and SQL Server Analysis Services (SSAS) than you ever thought possible. The first part of the book starts with the basicsgetting your development environment configured, Biml syntax, and scripting essentials. Whether a beginner or a seasoned Biml expert, the next part of the book guides you through the process of using Biml to build a framework that captures both your design patterns and execution management. Design patterns are reusable code blocks that standardize the approach you use to perform certain types of data integration, logging, and other key data functions. Design patterns solve common problems encountered when developing data integration solutions. Because you do not have to build the code from scratch each time, design patterns improve your efficiency as a Biml developer. In addition to leveraging design patterns in your framework, you will learn how to build a robust metadata store and how to package your framework into Biml bundles for deployment within your enterprise. In the last part of the book, we teach you more advanced Biml features and capabilities, such as SSAS development, T-SQL recipes, documentation autogeneration, and Biml troubleshooting. The Biml Book: Provides practical and applicable examples Teaches you how to use Biml to reduce development time while improving quality Takes you through solutions to common data integration and BI challenges What You'll Learn Master the basics of Business Intelligence Markup Language (Biml) Study patterns for automating SSIS package generation Build a Biml Framework Import and transform database schemasAutomate generation of scripts and projects Who This Book Is For BI developers wishing to quickly locate previously tested solutions, Microsoft BI specialists, those seeking more information about solution automation and code generation, and practitioners of Data Integration Lifecycle Management (DILM) in the DevOps enterprise}
}
@inproceedings{10.1109/ICSTW.2014.45,
author = {Harrer, Simon and R\"{o}ck, Cedric and Wirtz, Guido},
title = {Automated and Isolated Tests for Complex Middleware Products: The Case of BPEL Engines},
year = {2014},
isbn = {9781479957903},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSTW.2014.45},
doi = {10.1109/ICSTW.2014.45},
abstract = {Today, a plethora of enterprise middleware solutions are available, leading to the problem of choosing the right tool for a specific use case. Automated tests can support the selection of such software by determining decision relevant metrics, like e.g., throughput or the degree of standard conformance. To avoid side effects between tests, test isolation, i.e., to provide fresh instances of the software for each test execution, is essential. However, middleware suites are inherently complex, provide a large range of configuration options, have tedious or sometimes manual installation procedures, and long startup times. These idiosyncrasies aggravate the creation of fresh instances of such middleware suites, leading to slower turnaround times and increasing the cost for ensuring test isolation. We aim to overcome these issues with methods and tools from the area of virtualization and devops. In this work, we focus on BPEL engines which are common middleware components in Web Service based SOAs. We applied our proposed method to the BPEL Engine Test System (betsy), a conformance test suite and testing tool for BPEL engines. Results reveal that our method a) enables automatic creation of fresh instances of software without manual installation steps, b) reduces the time to create these fresh instance dramatically, and c) introduces only a neglectable performance overhead, therefore, reducing the overall costs of testing complex software.},
booktitle = {Proceedings of the 2014 IEEE International Conference on Software Testing, Verification, and Validation Workshops},
pages = {390–398},
numpages = {9},
keywords = {test automation, BPEL engines, virtualization, test isolation},
series = {ICSTW '14}
}
@inbook{10.1145/3475716.3475776,
author = {Rajapakse, Roshan Namal and Zahedi, Mansooreh and Babar, Muhammad Ali},
title = {An Empirical Analysis of Practitioners' Perspectives on Security Tool Integration into DevOps},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475776},
abstract = {Background: Security tools play a vital role in enabling developers to build secure software. However, it can be quite challenging to introduce and fully leverage security tools without affecting the speed or frequency of deployments in the DevOps paradigm. Aims: We aim to empirically investigate the key challenges practitioners face when integrating security tools into a DevOps workflow in order to provide recommendations for overcoming the challenges. Method: We conducted a study involving 31 systematically selected webinars on integrating security tools in DevOps. We used a qualitative data analysis method, i.e., thematic analysis, to identify the challenges and emerging solutions related to integrating security tools in rapid deployment environments. Results: We find that whilst traditional security tools are unable to cater for the needs of DevOps, the industry is moving towards new generations of security tools that have started focusing on the needs of DevOps. We have developed a DevOps workflow that integrates security tools and a set of guidelines by synthesizing practitioners' recommendations in the analyzed webinars. Conclusion: Whilst the latest security tools are addressing some of the requirements of DevOps, there are many tool-related drawbacks yet to be adequately addressed.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {6},
numpages = {12}
}
@book{10.5555/2901623,
author = {Weir, Luis Augusto and Bell, Andrew and Carrasco, Rolando and Viveros, Arturo},
title = {Oracle API Management 12c Implementation},
year = {2015},
isbn = {1785283634},
publisher = {Packt Publishing},
abstract = {Learn how to successfully implement API management using Oracle's API Management Solution 12cAbout This BookExplore the key concepts, goals, and objectives of API Management and learn how to implement it using the Oracle API Management SolutionUnderstand the concepts and objectives of the Application Service Governance (ASG), along with the governance framework that encompasses people, processes, and technologyGet to grips with API Management readiness assessments, gap analysis, digital reference architecture, and implementation roadmapsWho This Book Is ForThis book is for Enterprise Architects, Solution Architects, Technical Architects, and SOA and API consultants who want to successfully implement API Management using the Oracle API Management Solution products.What You Will LearnUnderstand how to manage a set of APIsDiscover the differences and similarities between API Management and SOA Governance, and where and how these two disciplines converge into Application Services Governance (ASG)Grasp information about ASG and how to define an ASG governance frameworkUnderstand the challenges for organizations looking to expose APIs to the external world. Identify common scenarios and how to solve themDefine an Oracle API management deployment topologyInstall and configure Oracle API Catalog (OAC), Oracle API Manager (OAPIM), and Oracle API Gateway (OAG)Learn about API subscriptions and API community management with the OAPIM portalImplement Oracle API Manager (OAPIM) including creation, publishing, management and deprecation of APIsIn DetailOracle SOA Governance is a comprehensive, service-orientated governance solution that is designed to make the transition to SOA easier. API management is the discipline that governs the software development lifecycle of APIs. It defines the tools and processes needed to build, publish and operate APIs including the management of the community of developers around it.This book illustrates how to successfully implement API Management in your organization. To achieve this, the importance of defining an API management strategy and implementation roadmap so that capabilities are implemented in the right order and timeframes is described.It starts by describing all of the fundamental concepts around API Management and related disciplines such as SOA Governance and DevOps in order to dispel the confusion surrounding these topics.The book then takes you on the journey of implementing API Management, using a realistic case study of an organization that needs an API Management solution. You will start by identifying the key business drivers to implement APIs and then create an API Management strategy and a roadmap to realize this strategy.You'll then go through a number of use cases, each focused on addressing specific business requirements. These will help you understand each of the Oracle API Management products, how they fit into an overall architecture, and how to implement them.The book concludes by providing some tips and guidelines around defining a deployment topology for the Oracle API Management products and the steps to install them.Style and approachThis book is a comprehensive guide to successfully implementing a complete API Management solution from inception to implementation. The initial chapters introduce you to Oracle SOA Governance and API Management and from there, chapters are mainly hands-on and provide a full step-by-step walkthrough of how to implement the products of the Oracle API management solution to address realistic use cases.}
}
@inproceedings{10.1145/3411564.3411608,
author = {Gimenez, Paulo J. A. and Santos, Gleison},
title = {DevOps Maturity Diagnosis – A Case Study in Two Public Organizations},
year = {2020},
isbn = {9781450388733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411564.3411608},
doi = {10.1145/3411564.3411608},
abstract = {Organizations have been applying practices and elements of DevOps culture in the last decade to approximate development and operation teams. Many software development processes address problems associated with keeping the desired stability in organizational operations while increasingly attending the frequency and quality of software deliveries. Nevertheless, the gap between the objectives of organizational units and development and operation teams persists due to the inadequacy of the solutions adopted for the unique scenarios each organization faces. Thus, to better support creating a DevOps culture in an organization and to guide the adoption of DevOps solutions it is necessary to diagnose its maturity and their teams’ to evaluate the knowledge and skills of the people involved. We present a process to diagnose DevOps maturity. We applied it to two public organizations. We found that both organizations are evolving from level initial to level conscious. Moreover, we noticed that the participants know the DevOps culture although the organizations do not fully adopt it yet.},
booktitle = {XVI Brazilian Symposium on Information Systems},
articleno = {11},
numpages = {8},
keywords = {Maturity, Continuous Software Engineering, DevOps, Case Study},
location = {S\~{a}o Bernardo do Campo, Brazil},
series = {SBSI'20}
}
@inproceedings{10.1109/SRDSW.2015.14,
author = {Chen, Hong-Mei and Kazman, Rick and Haziyev, Serge and Kropov, Valentyn and Chtchourov, Dmitri},
title = {Architectural Support for DevOps in a Neo-Metropolis BDaaS Platform},
year = {2015},
isbn = {9781509000920},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SRDSW.2015.14},
doi = {10.1109/SRDSW.2015.14},
abstract = {Big data as a Service (BDaaS) provides a viable strategy for organizations to implement scalable, tailorable big data infrastructure and applications built on this infrastructure. New trends in the BDaaS market are moving toward an open world model -- what we call the Neo-Metropolis model -- for developing BDaaS platforms. The key to the success of such large-scale technology-agnostic platforms, we posit, is an architectural strategy revolving around microservices and DevOps. This article presents the results of an action research with a Neo-Metropolis BDaaS vendor and illustrates how architectural support for DevOps is critical in achieving desired system qualities and enabling platform success. This research contributes to illuminate best practices of DevOps, and to validate and augment a set of DevOps tactics previously developed, while adding and recategorizing new instances of well-established architectural tactics.},
booktitle = {Proceedings of the 2015 IEEE 34th Symposium on Reliable Distributed Systems Workshop (SRDSW)},
pages = {25–30},
numpages = {6},
series = {SRDSW '15}
}
@book{10.5555/3180840,
author = {Daschner, Sebastian},
title = {Architecting Modern Java EE Applications: Designing Lightweight, Business-Oriented Enterprise Applications in the Age of Cloud, Containers, and Java EE 8},
year = {2017},
isbn = {1788393856},
publisher = {Packt Publishing},
abstract = {Find out how to craft effective, business-oriented Java EE 8 applications that target customers demands in the age of Cloud platforms and container technology. About This Book Understand the principles of modern Java EE and how to realize effective architectures Gain knowledge of how to design enterprise software in the age of automation, Continuous Delivery and Cloud platforms Learn about the reasoning and motivations behind state-of-the-art enterprise Java technology, that focuses on business Who This Book Is ForThis book is for experienced Java EE developers who are aspiring to become the architects of enterprise-grade applications, or software architects who would like to leverage Java EE to create effective blueprints of applications. What You Will Learn What enterprise software engineers should focus onImplement applications, packages, and components in a modern way Design and structure application architectures Discover how to realize technical and cross-cutting aspectsGet to grips with containers and container orchestration technology Realize zero-dependency, 12-factor, and Cloud-native applicationsImplement automated, fast, reliable, and maintainable software tests Discover distributed system architectures and their requirementsIn Detail Java EE 8 brings with it a load of features, mainly targeting newer architectures such as microservices, modernized security APIs, and cloud deployments. This book will teach you to design and develop modern, business-oriented applications using Java EE 8. It shows how to structure systems and applications, and how design patterns and Domain Driven Design aspects are realized in the age of Java EE 8. You will learn about the concepts and principles behind Java EE applications, and how to effect communication, persistence, technical and cross-cutting concerns, and asynchronous behavior. This book covers Continuous Delivery, DevOps, infrastructure-as-code, containers, container orchestration technologies, such as Docker and Kubernetes, and why and especially how Java EE fits into this world. It also covers the requirements behind containerized, zero-dependency applications and how modern Java EE application servers support these approaches. You will also learn about automated, fast, and reliable software tests, in different test levels, scopes, and test technologies. This book covers the prerequisites and challenges of distributed systems that lead to microservice, shared-nothing architectures. The challenges and solutions of consistency versus scalability will further lead us to event sourcing, event-driven architectures, and the CQRS principle. This book also includes the nuts and bolts of application performance as well as how to realize resilience, logging, monitoring and tracing in a modern enterprise world. Last but not least the demands of securing enterprise systems are covered. By the end, you will understand the ins and outs of Java EE so that you can make critical design decisions that not only live up to, but also surpass your clients' expectations. Style and approach This book focuses on solving business problems and meeting customer demands in the enterprise world. It covers how to create enterprise applications with reasonable technology choices, free of cargo-cult and over-engineering. The aspects shown in this book not only demonstrate how to realize a certain solution, but also explain its motivations and reasoning.}
}
@inproceedings{10.1145/3383219.3383280,
author = {Badshah, Sher and Khan, Arif Ali and Khan, Bilal},
title = {Towards Process Improvement in DevOps: A Systematic Literature Review},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383280},
doi = {10.1145/3383219.3383280},
abstract = {In recent years, the software release cost has been reduced dramatically due to the alteration from traditional shrink-wrapped software to software as a service. Organizations that can deliver their services continuously and with a high frequency have a higher ability to compete in the market. As a response to this, a substantial number of software companies acquired DevOps to establish a culture of effective communication and collaboration between development and operation teams and in order to enhance the production release frequency as well as to maintain the product quality. However, the DevOps environment requires a platform that aid in evaluating the performance of existing processes and provide improvement recommendations. On top of that, organizations can only achieve the perceived benefits of DevOps if their processes are mature and continuously measured. The objective of this research is to investigate the process improvement contributions made by researchers in the DevOps field. For this purpose, we performed a systematic literature review that resulted in several maturity models and best practices. Our ultimate aim is to develop a DevOps maturity model that can appraise and improve the processes in the DevOps environment.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {427–433},
numpages = {7},
keywords = {Continuous software engineering, DevOps, maturity models, process improvement, systematic review},
location = {Trondheim, Norway},
series = {EASE '20}
}
@article{10.1016/j.infsof.2021.106672,
author = {Leite, Leonardo and Pinto, Gustavo and Kon, Fabio and Meirelles, Paulo},
title = {The Organization of Software Teams in the Quest for Continuous Delivery: A Grounded Theory Approach},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106672},
doi = {10.1016/j.infsof.2021.106672},
journal = {Inf. Softw. Technol.},
month = {nov},
numpages = {14},
keywords = {Continuous delivery, Software teams, Release process, DevOps}
}
@inproceedings{10.1145/3462203.3475876,
author = {Shi, Zeshun and Farshidi, Siamak and Zhou, Huan and Zhao, Zhiming},
title = {An Auction and Witness Enhanced Trustworthy SLA Model for Decentralized Cloud Marketplaces},
year = {2021},
isbn = {9781450384780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462203.3475876},
doi = {10.1145/3462203.3475876},
abstract = {Cloud computing has become one of the most important technologies that have changed the traditional application development and operation (DevOps) lifecycle. However, current cloud software DevOps often faces the following key challenges: 1) selecting the best fitting service providers, customizing services and planning capacities for large-scale distributed applications; 2) guaranteeing high-quality and trustworthy service level agreements (SLAs) among multiple service providers; 3) enhancing the interoperability of cloud services across providers; 4) designing incentive model effectively among players. In this study, a framework called AWESOME is proposed to build a decentralized cloud marketplace and to address the above challenges. The proposed framework contains four subsystems including a customizable auction model, an incentive witness mechanism, and a social behavior-based simulator as one automated framework. We also provide a proof of concept to demonstrate that the AWESOME framework is feasible.},
booktitle = {Proceedings of the Conference on Information Technology for Social Good},
pages = {109–114},
numpages = {6},
keywords = {decentralized cloud marketplace, service level agreement, auction},
location = {Roma, Italy},
series = {GoodIT '21}
}
@book{10.5555/3122379,
author = {Butcher, Matt and Farina, Matt},
title = {Go in Practice: Includes 70 Techniques},
year = {2016},
isbn = {1633430073},
publisher = {Manning Publications Co.},
address = {USA},
edition = {1st},
abstract = {Summary Go in Practice guides you through 70 real-world techniques in key areas like package management, microservice communication, and more. Following a cookbook-style Problem/Solution/Discussion format, this practical handbook builds on the foundational concepts of the Go language and introduces specific strategies you can use in your day-to-day applications. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Technology Go may be the perfect systems language. Built with simplicity, concurrency, and modern applications in mind, Go provides the core tool set for rapidly building web, cloud, and systems applications. If you know a language like Java or C#, it's easy to get started with Go; the trick is finding the practical dirt-under-the-fingernails techniques that you need to build production-ready code. About the Book Go in Practice guides you through dozens of real-world techniques in key areas. Following a cookbook-style Problem/Solution/Discussion format, this practical handbook builds on the foundational concepts of the Go language and introduces specific strategies you can use in your day-to-day applications. You'll learn techniques for building web services, using Go in the cloud, testing and debugging, routing, network applications, and much more. After finishing this book, you will be ready to build sophisticated cloud-native Go applications. What's Inside Dozens of specific, practical Golang techniquesUsing Go for devops and cloudops Writing RESTful web services and microservicesPractical web dev techniques About the Reader Written for experienced developers who have already started exploring Go and want to use it effectively in a production setting. About the Authors Matt Farina is a software architect at Deis. Matt Butcher is a Principal Engineer in the Advanced Technology Group at Hewlett Packard Enterprise. They are both authors, speakers, and regular open source contributors.}
}
@inproceedings{10.1145/3442167.3442178,
author = {Ashenden, Debi and Ollis, Gail},
title = {Putting the Sec in DevSecOps: Using Social Practice Theory to Improve Secure Software Development},
year = {2020},
isbn = {9781450389952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442167.3442178},
doi = {10.1145/3442167.3442178},
abstract = {Practices such as open source development, agile, DevOps and DevSecOps mean that cyber security professionals need to find ways to blend cyber security with software development practices. One way of approaching this is as an awareness, education and training problem and many organisations are focusing on training software developers in cyber security. In this paper, however, we make the case for looking more broadly at group rather than individual behaviours, by examining the social practices of software developers. Changing software development practices are shaping the lived experience of software developers and we argue that understanding these practices will enable us to improve secure software development. We use social practice theory as a framework to develop recommendations for aligning and blending cyber security and software development. To achieve this, we carried out a rapid review of research on software development practices and supplemented this with data from ten key informant interviews to ascertain what we need to consider when developing an intervention for secure software development. Finally, we outline how our research could be used to develop a workshop that would facilitate the co-creation of security practices for software development. We conclude with suggestions for future research.},
booktitle = {New Security Paradigms Workshop 2020},
pages = {34–44},
numpages = {11},
keywords = {Cyber Security, Secure Software Development, Social Practice Theory, DevSecOps},
location = {Online, USA},
series = {NSPW '20}
}
@inproceedings{10.1145/2896941.2896957,
author = {Kerzazi, Noureddine and Adams, Bram},
title = {Who Needs Release and Devops Engineers, and Why?},
year = {2016},
isbn = {9781450341578},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896941.2896957},
doi = {10.1145/2896941.2896957},
abstract = {The recent surge in interest in continuous delivery has opened up the job market for release and DevOps engineers. However, despite an increasing number of conferences and publications on continuous delivery, smaller companies and start-ups still have a hard time determining the core tasks their future release and DevOps engineers should be responsible for (and what the differences between those two roles are), while universities are not sure what essential techniques and skills they should teach to their students. This paper performs an empirical analysis of online job postings to determine and compare the main tasks of release and DevOps engineers, globally and across countries. Our qualitative analysis shows that automation is the most important activity across the three roles, as articulated in job posting description data, and that the release engineer role combines the top activities of the DevOps and more traditional build engineer roles. Finally, different countries have a moderate degree of similarity between their ads, although each country has its specific focus.},
booktitle = {Proceedings of the International Workshop on Continuous Software Evolution and Delivery},
pages = {77–83},
numpages = {7},
keywords = {empirical study, release engineer, devops, job description},
location = {Austin, Texas},
series = {CSED '16}
}
@book{10.5555/3235135,
author = {Tak, Rohin and Modi, Jhalak},
title = {Mobile DevOps: Deliver Continuous Integration and Deployment within Your Mobile Applications},
year = {2018},
isbn = {1788296249},
publisher = {Packt Publishing},
abstract = {This step-by-step guide will teach you to continuously improve your mobile application development process Key Features Efficiently deliver continuous integration and deployment within all the stages of your application's lifecycle Learn to implement mobile DevOps with Xamarin and Visual Studio Deliver high quality and performing mobile applications Book Description Today's world is all about perfection, and there are hundreds of applications that are released each day out of which only a few succeed. Making sure that the app looks, performs, and behaves as expected is one of the biggest challenge developers face today. The main goal of this book is to teach developers to implement DevOps to build, test, and deliver. This book will teach you to implement Mobile DevOps at every stage of your application's lifecycle with Visual Studio and Xamarin Mobile Lifecycle solutions. Later, it will also show you how to leverage Mobile Center's continuous integration and automated testing to develop a high-quality applications. Next, you'll see how to mobilize your on-premises data to the cloud and increase your productivity with code reuse. Finally, you'll discover how to find and fix bugs beforehand, improving the efficiency of your application while it is being developed. By the end of this book, you will be well-versed with Mobile DevOps techniques, delivering high quality and high performance mobile apps. What you will learnBecome fluent with the basic components of Mobile DevopsFind out how to use code repositories and install Git on an EC2 server and manage users and groups Set up an Android device for development and install Visual Studio and Xamarin on Windows Create an Android project and UI for applications Add permissions to Android Manifest Write tests with Xamarin. UI and test using test cloud to check it on multiple devices Monitor and optimize the application using the Android monitoring tool Debug the mobile application and improve its efficiency Who This Book Is ForIf you are a programmer and developer who wants to increase the efficiency and scalability of your mobile application with the implementation of DevOps, then this book is for you. You need basic experience of the application process development.}
}
@inproceedings{10.5555/3398761.3399086,
author = {Amaral, Cleber Jorge and Kampik, Timotheus and Cranefield, Stephen},
title = {A Framework for Collaborative and Interactive Agent-Oriented Developer Operations},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Considering the increasing prevalence of autonomous systems in today's society, one could expect that agent-oriented programming (AOP) is gaining traction among mainstream software engineering practitioners. However, the tools and frameworks that are used and developed in the academic multi-agent systems engineering community struggle to keep up with recent developments in the software industry in regards to how complex information systems are developed and maintained. An important aspect of recent changes in software engineering practices is the application of technologies that supports the increasingly fast iteration of a programming-testing-deployment cycle. Such approaches require intense collaboration that crosses boundaries between traditionally separated roles like software development, quality assurance, and operations; these approaches are often referred to as DevOps. Researchers need to explore what additional value AOP has to offer in the context of new paradigms and practices. In this paper, we work towards the integration of DevOps and AOP by introducing an extension of jacamo-web, an Integrated Development Environment (IDE) that supports the collaborative, web-based development and real-time continuous integration of autonomous agents and Multi-Agent Systems (MAS).},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2092–2094},
numpages = {3},
keywords = {engineering multi-agent systems, agent-oriented programming, iterative software development, ide},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}
author = {Palermo, Jeffrey},
title = {..NET DevOps for Azure: A Developer's Guide to DevOps Architecture the Right Way},
year = {2019},
isbn = {1484253426},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Use this book as your one-stop shop for architecting a world-class DevOps environment with Microsoft technologies. .NET DevOps for Azure is a synthesis of practices, tools, and process that, together, can equip a software organization to move fast and deliver the highest quality software. The book begins by discussing the most common challenges faced by developers in DevOps today and offers options and proven solutions on how to implement DevOps for your team. Daily, millions of developers use .NET to build and operate mission-critical software systems for organizations around the world. While the marketplace has scores of information about the technology, it is completely up to you to put together all the blocks in the right way for your environment. This book provides you with a model to build on. The relevant principles are covered first along with how to implement that part of the environment. And while variances in tools, language, or requirements will change the needed implementation, the DevOps model is the architecture for the working environment for your team. You can modify parts of the model to customize it to your enterprise, but the architecture will enable all of your teams and applications to accelerate in performance. What You Will Learn Get your .NET applications into a DevOps environment in Azure Analyze and address the part of your DevOps process that causes delays or bottlenecks Track code using Azure Repos and conduct acceptance tests Apply the rules for segmenting applications into Git repositories Understand the different types of builds and when to use each Know how to think about code validation in your DevOps environment Provision and configure environments; deploy release candidates across the environments in Azure Monitor and support software that has been deployed to a production environment Who This Book Is For .NET Developers who are using or want to use DevOps in Azure but don't know where to begin}
}
@article{10.1016/j.jss.2017.06.022,
author = {Dunne, Jonathan and Malone, David},
title = {Obscured by the Cloud},
year = {2017},
issue_date = {September 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {131},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.06.022},
doi = {10.1016/j.jss.2017.06.022},
abstract = {A technique to model inter-arrival and service times of Cloud outages.A novel queue model approach to predict DevOps busy times.An evaluation of our model to demonstrate its effectiveness.A thorough approach to determine inter-arrival and service time correlation.A check for independence concerning overlapping outage events. As Small Medium Enterprises (SMEs) adopt Cloud technologies to provide high value customer offerings, uptime is considered important. Cloud outages represent a challenge to SMEs and micro teams to maintain a services platform. If a Cloud platform suffers from downtime this can have a negative effect on business revenue. Additionally, outages can divert resources from product development/delivery tasks to reactive remediation. These challenges are immediate for SMEs or micro teams with a small levels of resources. In this paper we present a framework that can model the arrival of Cloud outage events. This framework can be used by DevOps teams to manage their scarce pool of resources to resolve outages, thereby minimising impact to service delivery. We analysed over 300 Cloud outage events from an enterprise data set. We modelled the inter-arrival and service times of each outage event and found a Pareto and a lognormal distribution to be a suitable fit. We used this result to produce a special case of the G/G/1 queue system to predict busy times of DevOps personnel. We also investigated dependence between overlapping outage events. Our predictive queuing model compared favourably with observed data, 72% precision was achieved using one million simulations.},
journal = {J. Syst. Softw.},
month = {sep},
pages = {218–229},
numpages = {12},
keywords = {Cloud computing, Queuing theory, Outage simulation, Resource allocation model}
}
@inproceedings{10.1145/3287324.3287382,
author = {Melegati, Jorge and Chanin, Rafael and Wang, Xiaofeng and Sales, Afonso and Prikladnicki, Rafael},
title = {Perceived Benefits and Challenges of Learning Startup Methodologies for Software Engineering Students},
year = {2019},
isbn = {9781450358903},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287324.3287382},
doi = {10.1145/3287324.3287382},
abstract = {The need of skills other than technical from software developers is becoming evident. The DevOps movement is an example of that applied to operational tasks. Startup development methodologies focus on business activities in innovative organizations. Several universities offer courses based on these methodologies to software engineering students, mainly to improve their creativity, problem solving, and business skills. This paper investigates how software engineering students learned startup development methodologies and discusses what are the challenges and benefits in their learning process. We conducted a multi-method study in three different universities. The data was collected in two phases and analyzed using thematic analysis. Our study reveals that students realized the importance of collaboration with other courses and the importance of user involvement in development. However, students tend to over-simplify concepts, trying to adapt them to what they are familiar with. The results indicate the necessity of business education for technical students and directions for improvements.},
booktitle = {Proceedings of the 50th ACM Technical Symposium on Computer Science Education},
pages = {204–210},
numpages = {7},
keywords = {software engineering education, empirical study, lean startup},
location = {Minneapolis, MN, USA},
series = {SIGCSE '19}
}
@inproceedings{10.5555/3370272.3370313,
author = {Pourmajidi, William and Miranskyy, Andriy and Steinbacher, John and Erwin, Tony and Godwin, David},
title = {Dogfooding: Using IBM Cloud Services to Monitor IBM Cloud Infrastructure},
year = {2019},
publisher = {IBM Corp.},
address = {USA},
abstract = {The stability and performance of Cloud platforms are essential as they directly impact customers' satisfaction. Cloud service providers use Cloud monitoring tools to ensure that rendered services match the quality of service requirements indicated in established contracts such as service-level agreements.Given the enormous number of resources that need to be monitored, highly scalable and capable monitoring tools are designed and implemented by Cloud service providers such as Amazon, Google, IBM, and Microsoft. Cloud monitoring tools monitor millions of virtual and physical resources and continuously generate logs for each one of them. Considering that logs magnify any technical issue, they can be used for disaster detection, prevention, and recovery. However, logs are useless if they are not assessed and analyzed promptly. Thus, we argue that the scale of Cloud-generated logs makes it impossible for DevOps teams to analyze them effectively. This implies that one needs to automate the process of monitoring and analysis (e.g., using machine learning and artificial intelligence). If the automation will witness an anomaly in the logs --- it will alert DevOps staff.The automatic anomaly detectors require a reliable and scalable platform for gathering, filtering, and transforming the logs, executing the detector models, and sending out the alerts to the DevOps staff. In this work, we report on implementing a prototype of such a platform based on the 7-layered architecture pattern, which leverages micro-service principles to distribute tasks among highly scalable, resources-efficient modules. The modules interact with each other via an instance of the Publish-Subscribe architectural pattern. The platform is deployed on the IBM Cloud service infrastructure and is used to detect anomalies in logs emitted by the IBM Cloud services, hence the dogfooding. In particular, we leverage IBM Cloud Functions to deploy the computing modules, IBM Event Streams to establish communication among the modules, and IBM Cloud Object Storage and IBM Cloudant for persistent storage.The prototype efficiency is promising: it takes the platform 17 seconds or less from the point of receiving a new log record to emitting an alert to the IBM Cloud DevOps team.},
booktitle = {Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering},
pages = {344–353},
numpages = {10},
location = {Toronto, Ontario, Canada},
series = {CASCON '19}
}
@book{10.5555/3303909,
author = {Filipova, Olga and Vilo, Rui},
title = {Software Development From A to Z: A Deep Dive into All the Roles Involved in the Creation of Software},
year = {2018},
isbn = {148423944X},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Understand the big picture of the software development process. We use software every day operating systems, applications, document editing programs, home banking but have you ever wondered who creates software and how its created? This book guides you through the entire process, from conception to the finished product with the aid of user-centric design theory and tools. Software Development: From A to Zprovidesan overview of backend development - from databases to communication protocols including practical programming skills in Java and of frontend development - from HTML and CSS to npm registry and Vue.js framework. You'll review quality assurance engineering, including the theory about different kind of tests and practicing end-to-end testing using Selenium. Dive into the devops world where authors discuss continuous integration and continuous delivery processes along with each topic's associated technologies. You'll then explore insightful product and project management coverage where authors talk about agile, scrum and other processes from their own experience. The topics that are covered do not require a deep knowledge of technology in general; anyone possessing basic computer and programming knowledge will be able to complete all the tasks and fully understand the concepts this book aims at delivering. You'll wear the hat of a project manager, product owner, designer, backend, frontend, QA and devops engineer, and find your favorite role. What You'll Learn Understand the processes and roles involved in the creation of software Organize your ideas when building the concept of a new product Experience the work performed by stakeholders and other departments of expertise, their individual challenges, and how to overcome possible threats Improve the ways stakeholders and departments can work with each other Gain ideas on how to improve communication and processes Who This Book Is For Anyone who is on a team that creates software and is curious to learn more about other stakeholders or departments involved. Those interested in a career change and want to learn about how software gets created. Those who want to build technical startups and wonder what roles might be involved in the process.}
}
@inproceedings{10.1109/ICSE-NIER.2017.20,
author = {Laukkarinen, Teemu and Kuusinen, Kati and Mikkonen, Tommi},
title = {DevOps in Regulated Software Development: Case Medical Devices},
year = {2017},
isbn = {9781538626757},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2017.20},
doi = {10.1109/ICSE-NIER.2017.20},
abstract = {DevOps and continuous development are getting popular in the software industry. Adopting these modern approaches in regulatory environments, such as medical device software, is not straightforward because of the demand for regulatory compliance. While DevOps relies on continuous deployment and integration, regulated environments require strict audits and approvals before releases. Therefore, the use of modern development approaches in regulatory environments is rare, as is the research on the topic. However, as software is more and more predominant in medical devices, modern software development approaches become attractive. This paper discusses the fit of DevOps for regulated medical device software development. We examine two related standards, IEC 62304 and IEC 82304-1, for obstacles and benefits of using DevOps for medical device software development. We found these standards to set obstacles for continuous delivery and integration. Respectively, development tools can help fulfilling the requirements of traceability and documentation of these standards.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Results Track},
pages = {15–18},
numpages = {4},
keywords = {DevOps, medical software development standards, agile development, regulated software},
location = {Buenos Aires, Argentina},
series = {ICSE-NIER '17}
}
@article{10.4018/IJDAI.2021010104,
author = {Trad, Antoine},
title = {The Business Transformation Enterprise Architecture Framework: Intelligent Strategic Development and Operations (ISDevOps)},
year = {2021},
issue_date = {Jan 2021},
publisher = {IGI Global},
address = {USA},
volume = {13},
number = {1},
issn = {2637-7888},
url = {https://doi.org/10.4018/IJDAI.2021010104},
doi = {10.4018/IJDAI.2021010104},
abstract = {This chapter's author based his cross-functional research on an authentic and proprietary mixed research method that is supported by intelligent neural networks combined with a heuristics motor, named the applied mathematical model (AMM). The proposed AMM base functions like the human empiric decision-making process that can be compared to the behaviour-driven development. The AMM is supported by many real-life cases of business and architecture transformation projects in the domain of intelligent strategic development and operations (iSDevOps) that is supported by the alignment of various standards and development strategies that biases the standard market development and operations (DevOps) procedures, which are Sisyphean tasks.},
journal = {International Journal of Distributed Artificial Intelligence},
month = {jan},
pages = {74–101},
numpages = {28},
keywords = {Enterprise Architecture, Intelligent Systems, Development and Operations, Information Systems}
}
@book{10.5555/2810078,
author = {Abbott, Martin L. and Fisher, Michael T.},
title = {The Art of Scalability: Scalable Web Architecture, Processes, and Organizations for the Modern Enterprise},
year = {2015},
isbn = {0134032802},
publisher = {Addison-Wesley Professional},
edition = {2nd},
abstract = {The Comprehensive, Proven Approach to IT Scalability Updated with New Strategies, Technologies, and Case Studies In The Art of Scalability, Second Edition, leading scalability consultants Martin L. Abbott and Michael T. Fisher cover everything you need to know to smoothly scale products and services for any requirement. This extensively revised edition reflects new technologies, strategies, and lessons, as well as new case studies from the authors pioneering consulting practice, AKF Partners. Writing for technical and nontechnical decision-makers, Abbott and Fisher cover everything that impacts scalability, including architecture, process, people, organization, and technology. Their insights and recommendations reflect more than thirty years of experience at companies ranging from eBay to Visa, and Salesforce.com to Apple. Youll find updated strategies for structuring organizations to maximize agility and scalability, as well as new insights into the cloud (IaaS/PaaS) transition, NoSQL, DevOps, business metrics, and more. Using this guides tools and advice, you can systematically clear away obstacles to scalabilityand achieve unprecedented IT and business performance. Coverage includes Why scalability problems start with organizations and people, not technology, and what to do about it Actionable lessons from real successes and failures Staffing, structuring, and leading the agile, scalable organization Scaling processes for hyper-growth environments Architecting scalability: proprietary models for clarifying needs and making choicesincluding 15 key success principles Emerging technologies and challenges: data cost, datacenter planning, cloud evolution, and customer-aligned monitoring Measuring availability, capacity, load, and performance}
}
@book{10.5555/3161311,
author = {Winn, Duncan C. E.},
title = {Cloud Foundry: The Definitive Guide Develop, Deploy, and Scale},
year = {2017},
isbn = {1491932430},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {How can Cloud Foundry help you develop and deploy business-critical applications and tasks with velocity? This practical guide demonstrates how this open source, cloud-native application platform not only significantly reduces the develop-to-deploy cycle time, but also raises the value line for application operators by changing the way applications and supporting services are deployed and run. Learn how Cloud Foundry can help you improve your product velocity by handling many of essential tasks required to run applications in production. Author Duncan Winn shows DevOps and operations teams how to configure and run Cloud Foundry at scale. Youll examine Cloud Foundrys technical conceptsincluding how various platform components interrelateand learn how to choose your underlying infrastructure, define the networking architecture, and establish resiliency requirements. This book covers: Cloud-native concepts that make the app build, test, deploy, and scale faster How to deploy Cloud Foundry and the BOSH release engineering toolchain Concepts and components of Cloud Foundrys runtime architecture Cloud Foundrys routing mechanisms and capabilities The platforms approach to container tooling and orchestration BOSH concepts, deployments, components, and commands Basic tools and techniques for debugging the platform Recent and soon-to-emerge features of Cloud Foundry}
}
@inproceedings{10.1145/2899415.2899426,
author = {Christensen, Henrik B\ae{}rbak},
title = {Teaching DevOps and Cloud Computing Using a Cognitive Apprenticeship and Story-Telling Approach},
year = {2016},
isbn = {9781450342315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2899415.2899426},
doi = {10.1145/2899415.2899426},
abstract = {DevOps is a new way of developing software that is challenging from a teaching perspective. In this paper, we outline these challenges and propose teaching methods that focus on skill acquisition and technical practices that focus on performant virtualization to overcome them. We describe central elements from our course Cloud Computing and Architecture that has been designed and executed upon these methods and practices and report our experiences and lessons learned.},
booktitle = {Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {174–179},
numpages = {6},
keywords = {cloud computing, virtualization, programming education, devops, course design},
location = {Arequipa, Peru},
series = {ITiCSE '16}
}
@book{10.5555/3236006,
author = {Raj, Pethuru and Raman, Anupama},
title = {Software-Defined Cloud Centers: Operational and Management Technologies and Tools},
year = {2018},
isbn = {3319786369},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {This practical text/reference provides an exhaustive guide to setting up and sustaining software-defined data centers (SDDCs). Each of the core elements and underlying technologies are explained in detail, often supported by real-world examples. The text illustrates how cloud integration, brokerage, and orchestration can ensure optimal performance and usage of data resources, and what steps are required to secure each component in a SDDC. The coverage also includes material on hybrid cloud concepts, cloud-based data analytics, cloud configuration, enterprise DevOps and code deployment tools, and cloud software engineering. Topics and features: highlights how technologies relating to cloud computing, IoT, blockchain, and AI are revolutionizing business transactions, operations, and analytics; introduces the concept of Cloud 2.0, in which software-defined computing, storage, and networking are applied to produce next-generation cloud centers; examines software-defined storage for storage virtualization, covering issues of cloud storage, storage tiering, and deduplication; discusses software-defined networking for network virtualization, focusing on techniques for network optimization in data centers; reviews the qualities and benefits of hybrid clouds, that bridge private and public cloud environments; investigates the security management of a software-defined data center, and proposes a framework for managing hybrid IT infrastructure components; describes the management of multi-cloud environments through automated tools, and cloud brokers that aim to simplify cloud access, use and composition; covers cloud orchestration for automating application integration, testing, infrastructure provisioning, software deployment, configuration, and delivery. This comprehensive work is an essential reference for all practitioners involved with software-defined data center technologies, hybrid clouds, cloud service management, cloud-based analytics, and cloud-based software engineering.}
}
@book{10.5555/3207793,
author = {Leonard, Andy},
title = {Data Integration Life Cycle Management with SSIS: A Short Introduction by Example},
year = {2017},
isbn = {1484232755},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Build a custom BimlExpress framework that generates dozens of SQL Server Integration Services (SSIS) packages in minutes. Use this framework to execute related SSIS packages in a single command. You will learn to configure SSIS catalog projects, manage catalog deployments, and monitor SSIS catalog execution and history. Data Integration Life Cycle Management with SSISshows you how to bring DevOps benefits to SSIS integration projects. Practices in this book enable faster time to market, higher quality of code, and repeatable automation. Code will be created that is easier to support and maintain. The book teaches you how to more effectively manage SSIS in the enterprise environment by drawing on the art and science of modern DevOps practices. What You'll Learn Generate dozens of SSIS packages in minutes to speed your integration projects Reduce the execution of related groups of SSIS packages to a single command Successfully handle SSIS catalog deployments and their projects Monitor the execution and history of SSIS catalog projects Manage your enterprise data integration life cycle through automated tools and utilities Who This Book Is For Database professionals working with SQL Server Integration Services in enterprise environments. The book is especially useful to those readers following, or wishing to follow, DevOps practices in their use of SSIS.}
}
@inproceedings{10.1007/978-3-030-87595-4_19,
author = {Hensen, Benedikt and Klamma, Ralf},
title = {VIAProMa: An Agile Project Management Framework for Mixed Reality},
year = {2021},
isbn = {978-3-030-87594-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87595-4_19},
doi = {10.1007/978-3-030-87595-4_19},
abstract = {With the COVID-19 pandemic, distributed and remote working became a necessity but in agile project management, social interactions like daily standup meetings in Scrum are vital for the project success. Mixed reality can provide a new way of combining remote collaboration with innovative 3D visualizations to analyze the project status. In this paper, we present a visual immersive analytics framework for project management (VIAProMa). It imports data from project management tools like the GitHub issue tracker for open-source projects. With these task data as the basis, it can generate three-dimensional visualizations, e.g. about the overall progress or the competences of individual developers. Developers, stakeholders and end users can meet in the collaborative virtual environment as avatars and establish a spatial structure with the task cards and visualizations. Therefore, VIAProMa with its adapted and customized mixed reality project management features supports both the shared meetings and the information flow in the project. The shared environment makes it a suitable tool for DevOpsUseXR, an extension to the DevOps workflow, where end users are able to participate in the development process in mixed reality. The resulting implementation is available as an open-source project with cross-platform capabilities targeting the Microsoft HoloLens, HTC VIVE and Android smartphones, as well as tablets. The framework is applied in university teaching classes to convey agile methodology in mixed reality programming practices.},
booktitle = {Augmented Reality, Virtual Reality, and Computer Graphics: 8th International Conference, AVR 2021, Virtual Event, September 7–10, 2021, Proceedings},
pages = {254–272},
numpages = {19},
keywords = {Project management, Mixed reality, Agile methodology}
}
@inproceedings{10.1145/3162957.3162985,
author = {Rubasinghe, I. D. and Meedeniya, D. A. and Perera, I.},
title = {Towards Traceability Management in Continuous Integration with SAT-Analyzer},
year = {2017},
isbn = {9781450353656},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3162957.3162985},
doi = {10.1145/3162957.3162985},
abstract = {Software system engineering is rapidly growing to larger scales and software maintenance tends to be complex. The number of involving software artefacts increases with the growth of software systems. Thus, different software development methodologies, processes and practices are getting introduced to ease the software management. Consequently, the management of excessive software artefacts is also important towards a successful maintenance. Therefore, the notion of traceability management of software artefacts is given prominence along with continuous integration. This paper explores the existing traceability management approaches to propose an optimized framework that overcomes current limitations. Hence, the previous work of this research, SAT-Analyzer, which is a prototype tool, is extended to support continuous integration with DevOps practices.},
booktitle = {Proceedings of the 3rd International Conference on Communication and Information Processing},
pages = {77–81},
numpages = {5},
keywords = {impact analysis, traceability management, change detection, continuous integration, devops},
location = {Tokyo, Japan},
series = {ICCIP '17}
}
@inproceedings{10.1109/FIE49875.2021.9637201,
author = {Rahman, Akond and Shahriar, Hossain and Bose, Dibyendu Brinto},
title = {How Do Students Feel About Automated Security Static Analysis Exercises?},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/FIE49875.2021.9637201},
doi = {10.1109/FIE49875.2021.9637201},
abstract = {This Innovative Practice, work in progress (WIP) paper presents our experience related to two exercises that focus on automated security static analysis, a practice used to integrate security into development and operations (DevOps). The concept has gained popularity amongst information technology (IT) organizations. However, security-related concerns, such as security weaknesses in DevOps artifacts can cause serious consequences. Our preliminary findings indicate that (i) students positively perceive the introduced exercises; and (ii) the students perform well if they are provided necessary background on the exercises. Our WIP paper lays the groundwork to build course materials that will facilitate development, deployment, and dissemination of DevOps-related education materials that also incorporate cybersecurity concepts.},
booktitle = {2021 IEEE Frontiers in Education Conference (FIE)},
pages = {1–4},
numpages = {4},
location = {Lincoln, NE, USA}
}
@inproceedings{10.1145/3125659.3125670,
author = {Chung, Sam},
title = {Object-Oriented Programming with DevOps},
year = {2017},
isbn = {9781450351003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3125659.3125670},
doi = {10.1145/3125659.3125670},
abstract = {DevOps is an emerging culture that emphasizes continuous collaboration between software developers and IT operators through continuous standard process with automated tools for continuous delivery. DevOps participants take diverse roles to support its values - continuous collaboration, continuous process, and continuous delivery. A development team needs to be familiar with user cases, Object-Oriented Analysis (OOA), Object-Oriented Design (OOD), Object-Oriented Programming (OOP), and software testing. A quality assurance team must know use cases, abuse cases, software testing, and penetration testing. An operation team requires understanding deployment of Application Programming Interface (API) documents and executable components, and monitoring them and sharing their monitoring outcomes with both development and quality assurance teams.},
booktitle = {Proceedings of the 18th Annual Conference on Information Technology Education},
pages = {65},
numpages = {1},
keywords = {ebp, reengineering, oop, devops, oop with devops},
location = {Rochester, New York, USA},
series = {SIGITE '17}
}
@inproceedings{10.1145/3473465.3473479,
author = {Li, Chi-Jung and Shih, Heh-Jiann},
title = {The One-Key Seamless Integrating Platform for Open-Source DevOps Tools, to Solve Interconnecting Issues and Boost CI/CD Efficiency},
year = {2021},
isbn = {9781450389884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3473465.3473479},
doi = {10.1145/3473465.3473479},
abstract = {With the widespread of DevOps and agile developments, and IT industries are concerning about license and compliance issues while adopting commercial developing solutions. Those IT industries desperately need open-source alternative solutions, as well as guidelines to follow SDLC standards. This study planned to establish a one-key seamless open-source DevOps developing platform, to solve interconnecting issues between open-source DevOps tools, boost CI/CD efficiency, and assure quality of software developments and products.},
booktitle = {2021 3rd International Conference on Information Technology and Computer Communications},
pages = {80–83},
numpages = {4},
location = {Guangzhou, China},
series = {ITCC 2021}
}
@article{10.1145/3329781.3338532,
author = {Wiedemann, Anna and Forsgren, Nicole and Wiesche, Manuel and Gewald, Heiko and Krcmar, Helmut},
title = {The DevOps Phenomenon: An Executive Crash Course},
year = {2019},
issue_date = {March-April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/3329781.3338532},
doi = {10.1145/3329781.3338532},
abstract = {Stressful emergency releases are a thing of the past for companies that subscribe to the DevOps method of software development and delivery. New releases are frequent. Bugs are fixed rapidly. New business opportunities are sought with gusto and confidence. New features are released, revised, and improved with rapid iterations. DevOps presents a strategic advantage for organizations when compared with traditional software-development methods. Leadership plays an important role during that transformation. DevOps is about providing guidelines for faster time to market of new software features and achieving a higher level of stability. Implementing cross-functional, product-oriented teams helps bridge the gaps between software development and operations. By ensuring their transformations include all of the principles outlined in CALMS, teams can achieve superior performance and deliver value to their organizations. DevOps is often challenging, but stories from across the industry show that many organizations have already overcome the early hurdles and plan to continue their progress, citing the value to their organizations and the benefits to their engineers.},
journal = {Queue},
month = {apr},
pages = {93–112},
numpages = {20}
}
@inproceedings{10.1007/978-3-030-97457-2_10,
author = {Kampik, Timotheus and Amaral, Cleber Jorge and H\"{u}bner, Jomi Fred},
title = {Developer Operations and Engineering Multi-Agent Systems},
year = {2021},
isbn = {978-3-030-97456-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-97457-2_10},
doi = {10.1007/978-3-030-97457-2_10},
abstract = {In this paper, we propose the integration of approaches to Engineering Multi-Agent Systems (EMAS) with the Developer Operations (DevOps) industry best practice. Whilst DevOps facilitates the organizational autonomy of software teams, as well as the technological automation of testing, deployment, and operations pipelines, EMAS and the agent-oriented programming paradigm help instill autonomy into software artifacts. We discuss the benefits of integrating DevOps and EMAS, for example by highlighting the need for agent-oriented abstractions for quality assurance and test automation approaches. More generally, we introduce an agent-oriented perspective on the DevOps life-cycle and list a range of research challenges that are relevant for the integration of the DevOps and EMAS perspectives.},
booktitle = {Engineering Multi-Agent Systems: 9th International Workshop, EMAS 2021, Virtual Event, May 3–4, 2021, Revised Selected Papers},
pages = {175–186},
numpages = {12},
keywords = {Agent-oriented programming, Developer Operations, Engineering Multi-Agent Systems}
}
@article{10.4018/IJSSSP.2020070103,
author = {Russo, Barbara and Jaatun, Martin Gilje and Abrahamsson, Pekka and Botterweck, Goetz and Ghanbari, Hadi and Kettunen, Petri and Mikkonen, Tommi J. and Mjeda, Anila and M\"{u}nch, J\"{u}rgen and Duc, Anh Nguyen and Wang, Xiaofeng},
title = {Towards a Secure DevOps Approach for Cyber-Physical Systems: An Industrial Perspective},
year = {2020},
issue_date = {Jul 2020},
publisher = {IGI Global},
address = {USA},
volume = {11},
number = {2},
issn = {2640-4265},
url = {https://doi.org/10.4018/IJSSSP.2020070103},
doi = {10.4018/IJSSSP.2020070103},
abstract = {With the expansion of cyber-physical systems (CPSs) across critical and regulated industries, systems must be continuously updated to remain resilient. At the same time, they should be extremely secure and safe to operate and use. The DevOps approach caters to business demands of more speed and smartness in production, but it is extremely challenging to implement DevOps due to the complexity of critical CPSs and requirements from regulatory authorities. In this study, expert opinions from 33 European companies expose the gap in the current state of practice on DevOps-oriented continuous development and maintenance. The study contributes to research and practice by identifying a set of needs. Subsequently, the authors propose a novel approach called Secure DevOps and provide several avenues for further research and development in this area. The study shows that, because security is a cross-cutting property in complex CPSs, its proficient management requires system-wide competencies and capabilities across the CPSs development and operation.},
journal = {International Journal of Systems and Software Security and Protection},
month = {jul},
pages = {38–57},
numpages = {20},
keywords = {Healthcare, Aerospace, Software Security, Continuous Deployment, CPS, Energy, Empirical Research, Automotive, Secure Software Engineering, Agile Development, Development Methodologies}
}
@book{10.5555/3311987,
author = {Indrasiri, Kasun and Siriwardena, Prabath},
title = {Microservices for the Enterprise: Designing, Developing, and Deploying},
year = {2018},
isbn = {1484238575},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Understand the key challenges and solutions around building microservices in the enterprise application environment. This book provides a comprehensive understanding of microservices architectural principles and how to use microservices in real-world scenarios. Architectural challenges using microservices with service integration and API management are presented and you learn how to eliminate the use of centralized integration products such as the enterprise service bus (ESB) through the use of composite/integration microservices. Concepts in the book are supported with use cases, and emphasis is put on the reality that most of you are implementing in a brownfield environment in which you must implement microservices alongside legacy applications with minimal disruption to your business. Microservices for the Enterprisecovers state-of-the-art techniques around microservices messaging, service development and description, service discovery, governance, and data management technologies and guides you through the microservices design process. Also included is the importance of organizing services as core versus atomic, composite versus integration, and API versus edge, and how such organization helps to eliminate the use of a central ESB and expose services through an API gateway. What You'll Learn Design and develop microservices architectures with confidence Put into practice the most modern techniques around messaging technologies Apply the Service Mesh pattern to overcome inter-service communication challenges Apply battle-tested microservices security patterns to address real-world scenarios Handle API management, decentralized data management, and observability Who This Book Is ForDevelopers and DevOps engineers responsible for implementing applications around a microservices architecture, and architects and analysts who are designing such systems}
}
@article{10.2478/acss-2018-0008,
author = {Onokoy, Lyudmila and Lavendels, Jurijs},
title = {Evolution and Development Prospects of Information System Design Methodologies},
year = {2018},
issue_date = {May 2018},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {23},
number = {1},
issn = {2255-8691},
url = {https://doi.org/10.2478/acss-2018-0008},
doi = {10.2478/acss-2018-0008},
abstract = {The article investigates different approaches to the design of information systems. Much attention is paid to comparative analysis of criteria for selecting methodologies for software development, and also to not well-known methodology of DevOps (Development &amp; Operation) [1], [2], which aims at consolidation of software developers (Development) and IT professionals’ (Operation) efforts, and automation of implementation process. In conclusion, based on the retrospective analysis and practical experience, the authors formulate regularities and prospects of information systems design methodology development.},
journal = {Appl. Comput. Syst.},
month = {may},
pages = {63–68},
numpages = {6},
keywords = {methodology of DevOps, Heavyweight and agile methodologies, lean software development}
}
@book{10.5555/3309053,
author = {Medina, Oscar and Schumann, Ethan},
title = {DevOps for SharePoint: With Packer, Terraform, Ansible, and Vagrant},
year = {2018},
isbn = {1484236874},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Deploy a SharePoint farm in a repeatable, predictable, and reliable fashion using Infrastructure as Code (IaC) techniques to automate provisioning. Savvy IT pros will learn how to use DevOps practices and open source tools to greatly reduce costs, and streamline management operations for SharePoint farms deployed via Amazon Web Services (AWS), Azure, or on premise. DevOps for SharePointwill help you navigate the complex challenges of deploying and managing SharePoint Server farms. You will learn how to reduce time-consuming tasks and errors when generating development, testing, or production environments. And you will benefit from learning proven methods to apply Microsoft updates with minimal downtime and productivity loss. Whether you are a SharePoint architect, IT pro, or developer helping customers with the SharePoint platform, this book will teach you the most useful DevOps practices to tackle those issues and broaden your skill set. What Youll Learn Understand the basics of the most popular open source tools Vagrant, Packer, Terraform, and Ansibleand how to use them in the context of deploying and scaling a SharePoint farm Use Vagrant to build SharePoint development environments in less than an hour, and add automated testing Use Packer to create a golden image with preconfigured settings, and then use it as the base image in your Terraform configuration for both AWS and Azure farms Use Terraform to scale your SharePoint farm topology Use Red Hats Ansible Playbooks to perform configuration management on your farm Use Terraform to deploy immutable infrastructure environments using IaC (Infrastructure as Code) Use InSpec 2.0 to stay in compliance by testing your cloud infrastructure Use Ansible to apply Microsoft updates and patches Who This Book Is ForIT pros and developers who are looking to expand their knowledge and take a modern approach by using open source technologies to work with Microsoft products. Experience installing SharePoint, and a basic understanding of either Azure or AWS, is helpful.}
}
@inproceedings{10.1109/CLOUD.2015.63,
author = {Wettinger, Johannes and Breitenb\"{u}cher, Uwe and Leymann, Frank},
title = {Dyn Tail - Dynamically Tailored Deployment Engines for Cloud Applications},
year = {2015},
isbn = {9781467372879},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CLOUD.2015.63},
doi = {10.1109/CLOUD.2015.63},
abstract = {Shortening software release cycles increasingly becomes a critical competitive advantage, not exclusively for software vendors in the field of Web applications, mobile apps, and the Internet of Things. Today's users, customers, and other stakeholders expect quick responses to occurring issues and feature requests. DevOps and Cloud computing are two key paradigms to enable rapid, continuous deployment and delivery of applications utilizing automated software delivery pipelines. However, it is a highly complex and sophisticated challenge to implement such pipelines by installing, configuring, and integrating corresponding general-purpose deployment automation tooling. Therefore, we present a method in conjunction with a framework and implementation to dynamically generate tailored deployment engines for specific application stacks to deploy corresponding applications. Generated deployment engines are packaged in a portable manner to run them on various platforms and infrastructures. The core of our work is based on generating APIs for arbitrary deployment executables such as scripts and plans that perform different tasks in the automated deployment process. As a result, deployment tasks can be triggered through generated API endpoints, abstracting from lower-level, technical details of different deployment automation tooling.},
booktitle = {Proceedings of the 2015 IEEE 8th International Conference on Cloud Computing},
pages = {421–428},
numpages = {8},
keywords = {Cloud Computing, Deployment Engine, Deployment, APIfication, DevOps, Provisioning, Application Topology},
series = {CLOUD '15}
}
@book{10.5555/3294416,
author = {Enriquez, Rene and Salazar, Alberto},
title = {Software Architecture with Spring 5.0: Design and Architect Highly Scalable, Robust, and High-Performance Java Applications},
year = {2018},
isbn = {9781788992992},
publisher = {Packt Publishing},
abstract = {Discover how different software architectural models can help you solve problems, and learn best practices for the software development cycle Key Features Learn concepts related to software architecture and embrace them using the latest features of Spring 5Discover architectural models and learn when to apply them Gain knowledge of architectural principles and how they can be used to provide accountability and rationale for architectural decisions Book Description Spring 5 and its ecosystem can be used to build robust architectures effectively. Software architecture is the underlying piece that helps us accomplish our business goals whilst supporting the features that a product demands. This book explains in detail how to choose the right architecture and apply best practices during your software development cycle to avoid technical debt and support every business requirement. Choosing the right architecture model to support your business requirements is one of the key decisions you need to take when a new product is being created from scratch or is being refactored to support new business demands. This book gives you insights into the most common architectural models and guides you when and where they can be used. During this journey, youll see cutting-edge technologies surrounding the Spring products, and understand how to use agile techniques such as DevOps and continuous delivery to take your software to production effectively. By the end of this book, youll not only know the ins and outs of Spring, but also be able to make critical design decisions that surpass your clients expectations. What you will learn Understand the key principles of software architecture Uncover the most common architectural models available Analyze scenarios where an architecture model should be used Implement agile techniques to take your software to production Secure the products you are working on Master tricks that will help you build high-performant applications Use cutting-edge technologies to build products Who this book is for If youre an experienced Spring developer aspiring to become an architect of enterprise-grade applications, this book is for you. Its also ideal for software architects who want to leverage Spring to create effective application blueprints.}
}
@book{10.5555/3350820,
author = {Singh, Himanshu},
title = {Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python},
year = {2019},
isbn = {1484241487},
publisher = {APress},
edition = {1st},
abstract = {Gain insights into image-processing methodologies and algorithms, using machine learning and neural networks in Python. This book begins with the environment setup, understanding basic image-processing terminology, and exploring Python concepts that will be useful for implementing the algorithms discussed in the book. You will then cover all the core image processing algorithms in detail before moving onto the biggest computer vision library: OpenCV. You'll see the OpenCV algorithms and how to use them for image processing. The next section looks at advanced machine learning and deep learning methods for image processing and classification. You'll work with concepts such as pulse coupled neural networks, AdaBoost, XG boost, and convolutional neural networks for image-specific applications. Later you'll explore how models are made in real time and then deployed using various DevOps tools. All the concepts in Practical Machine Learning and Image Processing are explained using real-life scenarios. After reading this book you will be able to apply image processing techniques and make machine learning models for customized application. What You Will Learn Discover image-processing algorithms and their applications using Python Explore image processing using the OpenCV library Use TensorFlow, scikit-learn, NumPy, and other libraries Work with machine learning and deep learning algorithms for image processing Apply image-processing techniques to five real-time projects Who This Book Is For Data scientists and software developers interested in image processing and computer vision.}
}
@article{10.1007/s10664-020-09919-3,
author = {D\'{\i}az, Jessica and L\'{o}pez-Fern\'{a}ndez, Daniel and P\'{e}rez, Jorge and Gonz\'{a}lez-Prieto, \'{A}ngel},
title = {Why Are Many Businesses Instilling a DevOps Culture into Their Organization?},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09919-3},
doi = {10.1007/s10664-020-09919-3},
journal = {Empirical Softw. Engg.},
month = {mar},
numpages = {50},
keywords = {Empirical software engineering, DevOps, Exploratory case study}
}
@article{10.1016/j.is.2018.06.007,
author = {Satyal, Suhrid and Weber, Ingo and Paik, Hye-young and Di Ciccio, Claudio and Mendling, Jan},
title = {Business Process Improvement with the AB-BPM Methodology},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {84},
number = {C},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2018.06.007},
doi = {10.1016/j.is.2018.06.007},
journal = {Inf. Syst.},
month = {sep},
pages = {283–298},
numpages = {16},
keywords = {DevOps, Business process management, Process performance indicators, AB testing, Trace simulation}
}
@book{10.5555/3006348,
author = {Lowy, Juval and Montgomery, Michael},
title = {Programming WCF Services: Design and Build Maintainable Service-Oriented Systems},
year = {2015},
isbn = {1491944838},
publisher = {O'Reilly Media, Inc.},
edition = {4th},
abstract = {Programming WCF Services is the authoritative, bestselling guide to Microsofts unified platform for developing modern, service-oriented applications on Windows. Hailed as the definitive treatment of WCF, this guide provides unique insight, rather than documentation, to help you learn the topics and skills you need for building maintainable, extensible, and reusable WCF-based applications. Authors Juval Lwyone of the worlds top .NET expertsand Michael Montgomery have revised this edition to include the productivity-enhancing features of .NET Framework 4.6, along with the latest WCF ideas and techniques. By teaching you the why and the how of WCF programming, this book will help you master WCF and make you a better software engineer. Learn WCFs architecture and essential building blocks, including key concepts such as reliability and transport sessions Use built-in features such as service contracts, instance and concurrency management, transactions, queued services, and security Increase the quality of your WCF services by using design options, tips, and best practices in Lwys ServiceModelEx framework Understand the rationale behind particular design decisions, and rarely understood aspects of WCF development Learn why Azure Service Fabric is the killer app for modern DevOps}
}
@inproceedings{10.1145/3178461.3178485,
author = {Younoussi, Siham and Roudies, Ounsa},
title = {A New Reuse Capability and Maturity Model: An Overview},
year = {2018},
isbn = {9781450354387},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3178461.3178485},
doi = {10.1145/3178461.3178485},
abstract = {Throughout the last decade, increasingly sophisticated processes models, methods and tools have evolved as a result of structure and culture changes of software organizations. Software reuse is considered as a major factor for increasing productivity and quality. Reuse is implemented more and more by organizations, thereby giving them headway. To be more competitive these organizations try to invest in software reuse, by identifying the most effective reuse strategies, methods and practices. However, there is a high up-front risk of reuse adoption, because a significant initial organization investment is required, while the ROI is not guaranteed. Several Software Reuse Models have been suggested in literature to face the reuse adoption problem, but until now there is no widely accepted model. This paper proposed a new Reuse Capability Maturity Model based on international standards, literature and completed with the most recent and popular approaches as Lean and Devops, to help organizations implementing an efficient reuse program.},
booktitle = {Proceedings of the 2018 International Conference on Software Engineering and Information Management},
pages = {26–31},
numpages = {6},
keywords = {Software reuse, Capability Maturity Models, Maturity levels},
location = {Casablanca, Morocco},
series = {ICSIM2018}
}
@inbook{10.1145/3311790.3399620,
author = {Tripathi, Ravi and Monroe, William Stonewall and Hanby, Mike and Robinson, John-Paul},
title = {Building a Scalable Infrastructure: To Grow Computational Research and Enhance Collaboration across the Research Enterprise},
year = {2020},
isbn = {9781450366892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311790.3399620},
abstract = {This paper documents our experience in building a scalable cyberinfrastructure to grow computational research and enhance collaboration across the research enterprise. It describes a modernized research computing system built on the principles of Software Defined Infrastructure (SDI) and DevOps. This approach helps develop, test and deploy enhancements to our High Performance Computing (HPC) platform. By separating development from production, the approach offers opportunities to train developers new to distributed systems and HPC platforms, safely gaining advanced skills in demand but not common in today’s job market. Providing a deployment pipeline empowers teams with varying skill levels to effectively contribute enhancements to HPC platforms extending the capacity of operations professionals. The paper highlights our experience in setting up a web frontend for HPC resources in the form of Open OnDemand. The Open OnDemand web interface new users transition from their dedicated workstations to the HPC ecosystem. Most recently this model has been extended to manifest a DataOps team focused on analyzing operational cluster data sets. Their analysis uses XDMOD and Jupyter notebooks, available on the cluster through Open OnDemand, to review wait times and utilization providing direct feedback on scheduling policy. This review helps validate user experiences and ensures we define our infrastructure in a way that is most useful for our researchers. This knowledge has contributed to optimize workflows for research teams on campus. An open-source SDI and DevOps principles enable broader collaboratations with with research teams on and off campus, delivering rapid improvements across teams that can share processes. This discussion further highlights the importance to collaboration of open-source tooling and sites like GitHub.com and self-hosted community edition of GitLab.},
booktitle = {Practice and Experience in Advanced Research Computing},
pages = {530–533},
numpages = {4}
}
@inproceedings{10.1145/3383219.3383278,
author = {Rafi, Saima and Yu, Wu and Akbar, Muhammad Azeem},
title = {RMDevOps: A Road Map for Improvement in DevOps Activities in Context of Software Organizations},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383278},
doi = {10.1145/3383219.3383278},
abstract = {DevOps is a new software engineering paradigm adopted by various software organizations to develop an environment of continuous deployment and delivery within time. Numerous experts are offering their services to help organizations, how to implement DevOps activities in software organization. Though, still there are various issues for software organizations to adopt DevOps activities. To overcome such issues, there must be an approach that could assist software organizations towards better adoption of DevOps activities. The core objective of this research is to design a Readiness Model for DevOps (RMDevOps) to improve the adoption of DevOps activities in a software organization. Based on existing models in other fields of software engineering, we will develop this model. We have conducted a systematic literature review and empirical study on DevOps, for understanding the impact of the success factors of DevOps in the real world and literature. This study covers the first step of development of RMDevOps model, by identifying the success factors of DevOps and presenting the outcomes in the form of robust framework.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {413–418},
numpages = {6},
keywords = {Readiness model, systematic literature review, guidelines, software organizations},
location = {Trondheim, Norway},
series = {EASE '20}
}
@book{10.5555/3159140,
author = {Bentley, Walter},
title = {OpenStack Administration with Ansible 2 - Second Edition},
year = {2017},
isbn = {1787121631},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Key Features Automate real-world OpenStack cloud operator administrative tasksConstruct a collection of the latest automation code to save time on managing your OpenStack cloudManage containers on your cloud and check the health of your cloud using NagiosBook DescriptionMost organizations are seeking methods to improve business agility because they have realized just having a cloud is not enough. Being able to improve application deployments, reduce infrastructure downtime, and eliminate daily manual tasks can only be accomplished through some sort of automation. We start with a brief overview of OpenStack and Ansible 2 and highlight some best practices. Each chapter will provide an introduction to handling various Cloud Operator administration tasks such as managing containers within your cloud; setting up/utilizing open source packages for monitoring; creating multiple users/tenants; taking instance snapshots; and customizing your cloud to run multiple active regions. Each chapter will also supply a step-by-step tutorial on how to automate these tasks with Ansible 2. Packed with real-world OpenStack administrative tasks, this book will walk you through working examples and explain how these tasks can be automated using one of the most popular open source automation tools on the market today. What you will learn Efficiently execute OpenStack administrative tasksFamiliarize yourself with how Ansible 2 works and assess the defined best practicesCreate Ansible 2 playbooks and roles Automate tasks to customize your OpenStack cloudReview OpenStack automation considerations when automating administrative tasks Examine and automate advanced OpenStack tasks and designated use casesGet a high-level overview of Open Stack and current production-ready projectsExplore OpenStack CLI tools and learn how to use them About the Author Walter Bentley is a Rackspace Private Cloud Technical Marketing Engineer and author with a diverse background in production systems administration and solutions architecture. He has more than 15 years of experience in sectors such as online marketing, financial, insurance, aviation, the food industry, education, and now in technology. In the past, he was typically the requestor, consumer, and advisor to companies in the use of technologies such as OpenStack. Today, hes an OpenStack promoter and cloud educator. In his current role, Walter helps customers build, design, and deploy private clouds built on OpenStack. That includes professional services engagements around operating OpenStack clouds and DevOps engagements creating playbooks/roles with Ansible. He presents and speaks regularly at OpenStack Summits, AnsibleFest, and other technology conferences, plus webinars, blog posts and technical reviews. His first book, OpenStack Administration with Ansible, was released in 2016.}
}
@article{10.1007/s10723-021-09572-0,
author = {Kumara, Indika and Mundt, Paul and Tokmakov, Kamil and Radolovi\'{c}, Dragan and Maslennikov, Alexander and Gonz\'{a}lez, Rom\'{a}n Sosa and Fabeiro, Jorge Fern\'{a}ndez and Quattrocchi, Giovanni and Meth, Kalman and Di Nitto, Elisabetta and Tamburri, Damian A. and Van Den Heuvel, Willem-Jan and Meditskos, Georgios},
title = {SODALITE@RT: Orchestrating Applications on Cloud-Edge Infrastructures},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {3},
issn = {1570-7873},
url = {https://doi.org/10.1007/s10723-021-09572-0},
doi = {10.1007/s10723-021-09572-0},
abstract = {IoT-based applications need to be dynamically orchestrated on cloud-edge infrastructures for reasons such as performance, regulations, or cost. In this context, a crucial problem is facilitating the work of DevOps teams in deploying, monitoring, and managing such applications by providing necessary tools and platforms. The SODALITE@RT open-source framework aims at addressing this scenario. In this paper, we present the main features of the SODALITE@RT: modeling of cloud-edge resources and applications using open standards and infrastructural code, and automated deployment, monitoring, and management of the applications in the target infrastructures based on such models. The capabilities of the SODALITE@RT are demonstrated through a relevant case study.},
journal = {J. Grid Comput.},
month = {sep},
numpages = {23},
keywords = {Containers, Edge, Heterogeneous infrastructures, Orchestration, Cloud, TOSCA}
}
@article{10.1109/MS.2016.64,
author = {Balalaie, Armin and Heydarnoori, Abbas and Jamshidi, Pooyan},
title = {Microservices Architecture Enables DevOps: Migration to a Cloud-Native Architecture},
year = {2016},
issue_date = {May 2016},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {33},
number = {3},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2016.64},
doi = {10.1109/MS.2016.64},
abstract = {When DevOps started gaining momentum in the software industry, one of the first service-based architectural styles to be introduced, be applied in practice, and become popular was microservices. Migrating monolithic architectures to cloud-native architectures such as microservices reaps many benefits, such as adaptability to technological changes and independent resource management for different system components. This article reports on experiences and lessons learned during incremental migration and architectural refactoring of a commercial MBaaS (mobile back end as a service) to microservices. It explains how adopting DevOps facilitated a smooth migration. Furthermore, the researchers transformed their experiences in different projects into reusable migration practices, resulting in microservices migration patterns. This article is part of a theme issue on DevOps. The Web extra at https://youtu.be/MF3-dKTCQ88 is an audio recording of Brian Brannon speaking with author Pooyan Jamshidi and James Lewis, principal engineer at ThoughtWorks, about DevOps and microservices architecture.},
journal = {IEEE Softw.},
month = {may},
pages = {42–52},
numpages = {11}
}
@article{10.1109/MC.2016.56,
author = {Khoshkbarforoushha, Alireza and Wang, Meisong and Ranjan, Rajiv and Wang, Lizhe and Alem, Leila and Khan, Samee U. and Benatallah, Boualem},
title = {Dimensions for Evaluating Cloud Resource Orchestration Frameworks},
year = {2016},
issue_date = {February 2016},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {49},
number = {2},
issn = {0018-9162},
url = {https://doi.org/10.1109/MC.2016.56},
doi = {10.1109/MC.2016.56},
abstract = {Despite the proliferation of cloud resource orchestration frameworks (CROFs), DevOps managers and application developers still have no systematic tool for evaluating their features against desired criteria. The authors present generic technical dimensions for analyzing CROF capabilities and understanding prominent research to refine them.},
journal = {Computer},
month = {feb},
pages = {24–33},
numpages = {10}
}
@inproceedings{10.1145/3421537.3421539,
author = {Sharif, Muddsair and Janto, Skowronek and Lueckemeyer, Gero},
title = {COaaS: Continuous Integration and Delivery Framework for HPC Using Gitlab-Runner},
year = {2020},
isbn = {9781450375504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3421537.3421539},
doi = {10.1145/3421537.3421539},
abstract = {To quickly and securely deploy the latest version of hardware and software resources, DevOps communities use continuous delivery, continuous integration, and continuous deployment framework. This paper presents the methodology adopted by the m41ab team of the University of Applied Sciences to use the CI/CD framework in the development of workflows and shows the benefits that can be achieved using the CI/CD framework. Using High-Performance Computing (HPC) along with GitLab runners, we show that the use of Continuous Integration and Delivery framework can efficiently overcome software management challenges even without knowing much about HPC. We present our CI/CD infrastructure deployed for the transfer portal for m41ab, and explain how Gitlab-Runner allows end-user to adapt the environment to use HPC for computation diligently. The research, by use-case, shows the way forward to use the m41ab transfer portal for developing and maintaining the computing resources. Similarly traditional software, HPC software management is a complicated process that shares a number of objectives with enterprise-scale software development which obliges trustworthy updates and validation on a hard deadline.},
booktitle = {Proceedings of the 2020 the 4th International Conference on Big Data and Internet of Things},
pages = {54–58},
numpages = {5},
keywords = {High Performance Computing (HPC), continuous deployment (CD), software automation, software builds, containers, continuous integration (CI), M4LAB, continuous delivery (CD), Message Passing Interface (MPI), simstadt},
location = {Singapore, Singapore},
series = {BDIOT 2020}
}
@proceedings{10.5555/3338657,
title = {AST '19: Proceedings of the 14th International Workshop on Automation of Software Test},
year = {2019},
publisher = {IEEE Press},
abstract = {Welcome to the 14th edition of the IEEE/ACM Workshop on Automation of Software Test (AST). Effective and efficient testing with reduced costs and a high fault detection capability is the desirable goal in industry which can be achieved only through automation of all parts of the testing process. In the past decades, a great amount of research effort has been spent on automating all various parts of the testing process such as test case derivation, test selection, test oracle construction, test execution, and others. In addition, there has been a rapid growth in automated software testing tools which is stimulated in part through the shift towards agile development practices in industry that demands a high level of automation. Work on this topic has long been published as an important part of software engineering. In recent years, testing has been consistently among the top-most popular topics in submissions to software engineering conferences. The practice of software test automation (TA) has also moved forward significantly in the past few years. However, progress in TA is still required. Software systems have become more and more complicated through the integration of components developed by different vendors and using different techniques in different programming languages running on different platforms. The advent of cloud computing, mobile computing and the Internet of Things has imposed grave new challenges to TA. Those systems become increasingly reactive to changes in their environment, requiring equally adaptive TA approaches. Few software testing tools can currently handle the needed requirements to test such systems.This year's theme for AST is Testing and Continuous Deployment. Continuous deployment has become a major strategy in industry even for large software projects and continues to be a relevant topic in research. As one of the main strategies in modern DevOps environments, continuous deployment aims to increase code velocity---the time between making a code change and shipping the change to customers. At the same time, DevOps and continuous deployment impose heavy constraints onto testing: (a) testing must be completely automated and act as the last safeguard against customer incidents; (b) testing should be fast without slowing down code velocity; and (c) testing is happening within the engineering teams (DevOps) rather than dedicated testing teams. In other words, test automation may have become more wanted than ever before and we seek contributions to highlight solutions, challenges, and problem statements for test automation in a continuous deployment world. Choosing this special theme, our goal was to spark interest from industry partners to show and describe issues and solutions in this area and thus to foster the communication between researchers and industry and thus to reduce the gap between both worlds.},
location = {Montreal, Quebec, Canada}
}
@inproceedings{10.23919/INM.2017.7987445,
author = {John, Wolfgang and Moradi, Farnaz and Pechenot, Bertrand and Sk\"{o}ldstr\"{o}m, Pontus},
title = {Meeting the Observability Challenges for VNFs in 5G Systems},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/INM.2017.7987445},
doi = {10.23919/INM.2017.7987445},
abstract = {5G mobile communication systems will need to accommodate a variety of use-cases, resulting in a diverse set of requirements. To meet these requirements, 5G systems take advantage of modern virtualization possibilities offered by Network Function Virtualization (NFV), enabling deployment agility and dynamicity of virtualized network functions. With the transformation of telecom towards virtualized environments, advanced observability possibilities gain increasing importance as one of the essential prerequisites, especially for successful DevOps operations. However, deployment agility also puts specific requirements on monitoring solutions in order to adapt automatically and continuously to frequent changes in service deployments. In this short-paper, we establish and discuss essential properties of observability systems for virtual network functions in a 5G context. We take these properties as guiding design principles for our software-defined monitoring framework and outline how to evolve our existing components towards a flexible, scalable, and programmable observability solution for microservice-based NFV with features for increased manageability.},
booktitle = {2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM)},
pages = {1127–1130},
numpages = {4},
location = {Lisbon, Portugal}
}
@book{10.5555/3055651,
author = {Aiello, Bob and Sachs, Leslie},
title = {Agile Application Lifecycle Management: Using DevOps to Drive Process Improvement},
year = {2016},
isbn = {0321774108},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {Integrate Agile ALM and DevOps to Build Better Software and Systems at Lower Cost Agile Application Lifecycle Management (ALM) is a comprehensive development lifecycle that encompasses essential Agile principles and guides all activities needed to deliver successful software or other customized IT products and services. Flexible and robust, Agile ALM offers just enough process to get the job done efficiently and utilizes the DevOps focus on communication and collaboration to enhance interactions among all participants. Agile Application Lifecycle Management offers practical advice and strategies for implementing Agile ALM in your complex environment. Leading experts Bob Aiello and Leslie Sachs show how to fully leverage Agile benefits without sacrificing structure, traceability, or repeatability. Youll find realistic guidance for managing source code, builds, environments, change control, releases, and more. The authors help you support Agile in organizations that maintain traditional practices, conventional ALM systems, or siloed, non-Agile teams. They also show how to scale Agile ALM across large or distributed teams and to environments ranging from cloud to mainframe. Coverage includes Understanding key concepts underlying modern application and system lifecycles Creating your best processes for developing your most complex software and systems Automating build engineering, continuous integration, and continuous delivery/deployment Enforcing Agile ALM controls without compromising productivity Creating effective IT operations that align with Agile ALM processes Gaining more value from testing and retrospectives Making ALM work in the cloud, and across the enterprise Preparing for the future of Agile ALM Today, you need maximum control, quality, and productivity, and this guide will help you achieve these capabilities by combining the best practices found in Agile ALM, Configuration Management (CM), and DevOps.}
}
@inproceedings{10.1109/ICSE-Companion.2019.00024,
author = {Czarnecki, Krzysztof},
title = {Software Engineering for Automated Vehicles: Addressing the Needs of Cars That Run on Software and Data},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion.2019.00024},
doi = {10.1109/ICSE-Companion.2019.00024},
abstract = {Automated vehicles are AI-based safety-critical robots that fulfill transportation needs while interacting with the general public in traffic. Software engineering for automated vehicles requires a DevOps-style process with special considerations for functions based on machine learning and incremental safety assurance at vehicle and fleet level. This technical briefing reviews current challenges, industry practices, and opportunities for future research in software engineering for automated vehicles.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings},
pages = {6–8},
numpages = {3},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}
@inproceedings{10.1145/3417990.3421446,
author = {Hugues, Jerome and Hristosov, Anton and Hudak, John J. and Yankel, Joe},
title = {TwinOps - DevOps Meets Model-Based Engineering and Digital Twins for the Engineering of CPS},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3421446},
doi = {10.1145/3417990.3421446},
abstract = {The engineering of Cyber-Physical Systems (CPS) requires a large set of expertise to capture the system requirements and to derive a correct solution. Model-based Engineering and DevOps aim to efficiently deliver software with increased quality. Model-based Engineering relies on models as first-class artifacts to analyze, simulate, and ultimately generate parts of a system. DevOps focuses on software engineering activities, from early development to integration, and then improvement through the monitoring of the system at run-time. We claim these can be efficiently combined to improve the engineering process of CPS.In this paper, we present TwinOps, a process that unifies Model-based Engineering, Digital Twins, and DevOps practice in a uniform workflow. TwinOps illustrates how to leverage several best practices in MBE and DevOps for the engineering Cyber-Physical systems. We illustrate our contribution using a Digital Twins case study to illustrate TwinOps benefits, combining AADL and Modelica models, and an IoT platform.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {94},
numpages = {5},
location = {Virtual Event, Canada},
series = {MODELS '20}
}
@inproceedings{10.1109/IC2E.2015.23,
author = {Wettinger, Johannes and Andrikopoulos, Vasilios and Leymann, Frank},
title = {Automated Capturing and Systematic Usage of DevOps Knowledge for Cloud Applications},
year = {2015},
isbn = {9781479982189},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/IC2E.2015.23},
doi = {10.1109/IC2E.2015.23},
abstract = {DevOps is an emerging paradigm to actively foster the collaboration between system developers and operations in order to enable efficient end-to-end automation of software deployment and management processes. DevOps is typically combined with Cloud computing, which enables rapid, on-demand provisioning of underlying resources such as virtual servers, storage, or database instances using APIs in a self-service manner. Today, an ever-growing amount of DevOps tools, reusable artifacts such as scripts, and Cloud services are available to implement DevOps automation. Thus, informed decision making on the appropriate approach (es) for the needs of an application is hard. In this work we present a collaborative and holistic approach to capture DevOps knowledge in a knowledgebase. Beside the ability to capture expert knowledge and utilize crowd sourcing approaches, we implemented a crawling framework to automatically discover and capture DevOps knowledge. Moreover, we show how this knowledge is utilized to deploy and operate Cloud applications.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Cloud Engineering},
pages = {60–65},
numpages = {6},
keywords = {Cloud Computing, Knowledge Management, Crawling, Knowledge Model, DevOps},
series = {IC2E '15}
}
@inproceedings{10.1145/2994291.2994302,
author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
title = {Automated Workflow Regression Testing for Multi-Tenant SaaS: Integrated Support in Self-Service Configuration Dashboard},
year = {2016},
isbn = {9781450344012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2994291.2994302},
doi = {10.1145/2994291.2994302},
abstract = {Single-instance multi-tenant SaaS applications allow tenant administrators to (extensively) customize the application according to the requirements of their organizations. In the specific case of workflow-driven applications, the SaaS provider may offer a set of pre-defined workflow activities and leave their composition to the tenant administrators. In such cases, the tenant administrator can instantiate new variants of the application without deploying new software. This effectively makes these tenant administrators part of the DevOps team, and in turn creates the need for the SaaS provider to provide them with Quality Assurance tool support. One such tool is a regression testing framework that allows them to make sure that a new version of a workflow can behave similarly as to a successful execution of a previous version. This paper highlights the potential and discusses the inherent challenges of running regression tests on workflows in the production environment of a multi-tenant SaaS application and outlines a solution in terms of architecture and automation techniques for mocking and regression detection under control of tenant administrators.},
booktitle = {Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation},
pages = {70–73},
numpages = {4},
keywords = {Automated Regression Testing, Application-level Multi-tenancy, Software-as-a-Service},
location = {Seattle, WA, USA},
series = {A-TEST 2016}
}
@inproceedings{10.1145/3194810.3194818,
author = {Baudry, Benoit and Harrand, Nicolas and Schulte, Eric and Timperley, Chris and Tan, Shin Hwei and Selakovic, Marija and Ugherughe, Emamurho},
title = {A Spoonful of DevOps Helps the GI Go Down},
year = {2018},
isbn = {9781450357531},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194810.3194818},
doi = {10.1145/3194810.3194818},
abstract = {DevOps emphasizes a high degree of automation at all phases of the software development lifecyle. Meanwhile, Genetic Improvement (GI) focuses on the automatic improvement of software artifacts. In this paper, we discuss why we believe that DevOps offers an excellent technical context for easing the adoption of GI techniques by software developers. We also discuss A/B testing as a prominent and clear example of GI taking place in the wild today, albeit one with human-supervised fitness and mutation operators.},
booktitle = {Proceedings of the 4th International Workshop on Genetic Improvement Workshop},
pages = {35–36},
numpages = {2},
keywords = {genetic improvement, DevOps, continuous integration},
location = {Gothenburg, Sweden},
series = {GI '18}
}
@book{10.5555/3202536,
author = {Gmez, Jorge Marx and Mora, Manuel and Raisinghani, Mahesh S. and Nebel, Wolfgang and O'Connor, Rory V.},
title = {Engineering and Management of Data Centers: An IT Service Management Approach},
year = {2017},
isbn = {3319650815},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {This edited volume covers essential and recent development in the engineering and management of data centers. Data centers are complex systems requiring ongoing support, and their high value for keeping business continuity operations is crucial. The book presents core topics on the planning, design, implementation, operation and control, and sustainability of a data center from a didactical and practitioner viewpoint. Chapters include: Foundations of data centers: Key Concepts and Taxonomies ITSDM: A Methodology for IT Services Design Managing Risks on Data Centers through Dashboards Risk Analysis in Data Center Disaster Recovery Plans Best practices in Data Center Management Case: KIO Networks QoS in NaaS (Network as a Service) using Software Defined Networking Optimization of Data Center Fault-Tolerance Design Energetic Data Centre Design Considering Energy Efficiency Improvements During Operation Demand-side Flexibility and Supply-side Management: The Use Case of Data Centers and Energy Utilities DevOps: Foundations and its Utilization in Data Centers Sustainable and Resilient Network Infrastructure Design for Cloud Data Centres Application Software in Cloud-Ready Data Centers This book bridges the gap between academia and the industry, offering essential reading for practitioners in data centers, researchers in the area, and faculty teaching related courses on data centers. The book can be used as a complementary text for traditional courses on Computer Networks, as well as innovative courses on IT Architecture, IT Service Management, IT Operations, and Data Centers.}
}
@book{10.5555/3299606,
author = {Raheja, Yogesh and Borgese, Giuseppe and Felsen, Nathaniel},
title = {Effective DevOps with AWS: Implement Continuous Delivery and Integration in the AWS Environment, 2nd Edition},
year = {2018},
isbn = {1789539978},
publisher = {Packt Publishing},
abstract = {Scale and maintain outstanding performance in your AWS-based infrastructure using DevOps principles Key Features Implement continuous integration and continuous deployment pipelines on AWS Gain insight from an expert who has worked with Silicon Valley's most high-profile companies Implement DevOps principles to take full advantage of the AWS stack and services Book Description The DevOps movement has transformed the way modern tech companies work. Amazon Web Services (AWS), which has been at the forefront of the cloud computing revolution, has also been a key contributor to the DevOps movement, creating a huge range of managed services that help you implement DevOps principles. Effective DevOps with AWS, Second Edition will help you to understand how the most successful tech start-ups launch and scale their services on AWS, and will teach you how you can do the same. This book explains how to treat infrastructure as code, meaning you can bring resources online and offline as easily as you control your software. You will also build a continuous integration and continuous deployment pipeline to keep your app up to date. Once you have gotten to grips will all this, we'll move on to how to scale your applications to offer maximum performance to users even when traffic spikes, by using the latest technologies, such as containers. In addition to this, you'll get insights into monitoring and alerting, so you can make sure your users have the best experience when using your service. In the concluding chapters, we'll cover inbuilt AWS tools such as CodeDeploy and Cloud Formation, which are used by many AWS administrators to perform DevOps. By the end of this book, you'll have learned how to ensure the security of your platform and data, using the latest and most prominent AWS tools. What you will learn Implement automatic AWS instance provisioning using Cloud Formation Deploy your application on a provisioned infrastructure with Ansible Manage infrastructure using Terraform Build and deploy a CI/CD pipeline with Automated Testing on AWS Understand the container journey for a CI/CD pipeline using AWS ECS Monitor and secure your AWS environment Who this book is for Effective DevOps with AWS is for you if you are a developer, DevOps engineer, or you work in a team which wants to build and use AWS for software infrastructure. Basic computer science knowledge is required to get the most out of this book.}
}
@phdthesis{10.5555/AAI28963842,
author = {Snyder, Patrick R. and Samuel, Sambasivam, and Abdullah, Alshboul,},
advisor = {Marie, Cini,},
title = {A Qualitative Inquiry into the Benefits of Microservice Technological Agnosticism on Small Development Teams},
year = {2021},
isbn = {9798762199476},
publisher = {Colorado Technical University},
abstract = {This research addressed the problem small software development teams face with Microservice Architecture (MSA), known as the Tower of Babel issue, in which the individual services within the overarching architecture are allowed to be developed independently with no regard for standardizing technologies. The purpose of this study was to determine whether the technology agnosticism championed by MSA and contributing to the Tower of Babel problem is beneficial for small teams. The qualitative exploratory methodology was elected after considering the study's purpose and target problem as the best approach to exploring the research question: What benefits do small development teams gain from the technology agnosticism enabled through MSA? Semi-structured in-depth interviews framed by ten open-ended questions were how the experiences of the studies twelve subjects were retrieved and recorded. Creswell's data analysis spiral involving an iterative application of open, axial, and selective coding was applied to the interview transcripts to arrive at meaningful findings. The six themes relevant to the research question and identified through the 27 identified categories were teams, benefits, challenges, frameworks &amp; standardization, Development and Operations (DevOps), and technology agnosticism. The lessons learned and insights derived from the combined experiences of the study's participants could prove invaluable to teams currently considering MSA initiatives or charting a path forward for greenfield projects.},
note = {AAI28963842}
}
@inproceedings{10.1109/FIE.2018.8658817,
author = {Bai, Xiaoying and Pei, Dan and Li, Mingjie and Li, Shanshan},
title = {The DevOps Lab Platform for Managing Diversified Projects in Educating Agile Software Engineering},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/FIE.2018.8658817},
doi = {10.1109/FIE.2018.8658817},
abstract = {This Research Work-in-Progress paper presents the design of a Software Engineering (SE) course to support project-based practical training. Group projects, especially projects from industry partners, are deemed to be necessary for students to gain hands-on experiences. With projects from the real world, students learn not only practical engineering solutions, but also the context, constraints, and social aspects of SE. For a course having over 100 students with different interests and experiences, it is desired to provide diversified choices of projects to stimulate enthusiasm for learning. However, management and evaluation of diversified projects are challenging. Following the Agile principles, we need to continuously track progress and activities of each group, to provide quick feedback of deliveries, and to periodically evaluate students’ performance. Therefore, we built a DevOps platform based on GitLab version control and continuous integration framework. Commits to GitLab code repositories automatically trigger build, testing, and analysis functions (which provide both qualitative and quantitative feedback to the students). This system has been in operations since 2014 for an undergraduate SE course, with over 500 students participating in over 130 project teams in total. The preliminary research showed promising results in improving SE education.},
booktitle = {2018 IEEE Frontiers in Education Conference (FIE)},
pages = {1–5},
numpages = {5},
location = {San Jose, CA, USA}
}
@inproceedings{10.1109/ICSE-C.2017.162,
author = {Arta\v{c}, Matej and Borov\v{s}ak, Tadej and Di Nitto, Elisabetta and Guerriero, Michele and Tamburri, Damian Andrew},
title = {DevOps: Introducing Infrastructure-as-Code},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.162},
doi = {10.1109/ICSE-C.2017.162},
abstract = {DevOps entails a series of software engineering tactics aimed at shortening the actionable operation of software design changes. One of these tactics is to harness infrastructure-as-code, that is, writing a blueprint that contains deployment specifications ready for orchestration in the cloud. This abstract briefly discusses all necessary elements and abstractions in writing and maintaining that blueprint, revolving around a key standard for its expression, namely, the OASIS "Topology and Orchestration Specification for Cloud Applications" (TOSCA) industrial standard adopted by as many as 60+ big industrial players worldwide.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {497–498},
numpages = {2},
keywords = {TOSCA, infrastructure-as-code, DevOps},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}
author = {Vadapalli, Sricharan},
title = {Hands-on DevOps: Explore the Concept of Continuous Delivery and Integrate It with Data Science Concepts},
year = {2017},
isbn = {1788471180},
publisher = {Packt Publishing},
abstract = {Transform yourself into a specialist in DevOps adoption for Big Data on cloudKey FeaturesLearn the concepts of Bigdata and Devops and Implement themGet Acquainted with DevOps Frameworks Methodologies and ToolsA practical approach to build and work efficiently with your big data clusterGet introduced to multiple flavors of tools and platforms from vendors on Hadoop, Cloud, Containers and IoT OfferingsIn-Depth Technology understanding on Data Sciences, Microservices, BigdataBook DescriptionDevOps strategies have really become an important factor for big data environments. This book initially provides an introduction to big data, DevOps, and Cloud computing along with the need for DevOps strategies in big data environments. We move on to explore the adoption of DevOps frameworks and business scenarios. We then build a big data cluster, deploy it on the cloud, and explore DevOps activities such as CI/CD and containerization. Next, we cover big data concepts such as ETL for data sources, Hadoop clusters, and their applications. Towards the end of the book, we explore ERP applications useful for migrating to DevOps frameworks and examine a few case studies for migrating big data and prediction models. By the end of this book, you will have mastered implementing DevOps tools and strategies for your big data clusters. What you will learnLearn about the DevOps culture, its frameworks, maturity, and design patternsGet acquainted with multiple niche technologies microservices, containers, kubernetes, IoT, and cloudBuild big data clusters, enterprise applications and data science modelsApply DevOps concepts for continuous integration, delivery, deployment and monitoringGet introduced to Open source tools, service offerings from multiple vendorsStart digital journey to apply DevOps concepts to migrate big data, cloud, microservices, IoT, security, ERP systemsWho This Book Is ForIf you are a Big Data Architects, solutions provider, or any stakeholder working in big data environment and wants to implement the strategy of DevOps, then this book is for you.}
}
@book{10.5555/3181056,
author = {Saito, Hideto and Lee, Hui-Chuan Chloe and Wu, Cheng-Yang},
title = {DevOps with Kubernetes: Accelerating Software Delivery with Container Orchestrators},
year = {2017},
isbn = {1788396642},
publisher = {Packt Publishing},
abstract = {Learn to implement DevOps using Docker &amp; Kubernetes. About This Book Learning DevOps, container, and Kubernetes within one book. Leverage Kubernetes as a platform to deploy, scale, and run containers efficiently. A practical guide towards container management and orchestration Who This Book Is ForThis book is targeted for anyone, who wants to learn containerization and clustering in a practical way using Kubernetes. No prerequisite skills required, however, essential DevOps skill and public/private Cloud knowledge will accelerate the reading speed. If you're advanced readers, you can also get a deeper understanding of all the tools and technique described in the book. What You Will Learn Learn fundamental and advanced DevOps skills and tools Get a comprehensive understanding for container Learn how to move your application to container world Learn how to manipulate your application by KubernetesLearn how to work with Kubernetes in popular public cloud Improve time to market with Kubernetes and Continuous DeliveryLearn how to monitor, log, and troubleshoot your application with Kubernetes In Detail Containerization is said to be the best way to implement DevOps. Google developed Kubernetes, which orchestrates containers efficiently and is considered the frontrunner in container orchestration. Kubernetes is an orchestrator that creates and manages your containers on clusters of servers. This book will guide you from simply deploying a container to administrate a Kubernetes cluster, and then you will learn how to do monitoring, logging, and continuous deployment in DevOps. The initial stages of the book will introduce the fundamental DevOps and the concept of containers. It will move on to how to containerize applications and deploy them into. The book will then introduce networks in Kubernetes. We then move on to advanced DevOps skills such as monitoring, logging, and continuous deployment in Kubernetes. It will proceed to introduce permission control for Kubernetes resources via attribute-based access control and role-based access control. The final stage of the book will cover deploying and managing your container clusters on the popular public cloud Amazon Web Services and Google Cloud Platform. At the end of the book, other orchestration frameworks, such as Docker Swarm mode, Amazon ECS, and Apache Mesos will be discussed. Style and approach Readers will be taken through fundamental DevOps skills and Kubernetes concept and administration with detailed examples. It introduces comprehensive DevOps topics, including microservices, automation tools, containers, monitoring, logging, continuous delivery, and popular public cloud environments. At each step readers will learn how to leverage Kubernetes in their everyday lives and transform their original delivery pipeline for fast and efficient delivery.}
}
@book{10.5555/3294726,
author = {Ingeno, Joseph},
title = {Software Architect's Handbook: Become a Successful Software Architect by Implementing Effective Architecture Concepts},
year = {2018},
isbn = {1788624068},
publisher = {Packt Publishing},
abstract = {A comprehensive guide to exploring software architecture concepts and implementing best practices Key Features Enhance your skills to grow your career as a software architectDesign efficient software architectures using patterns and best practicesLearn how software architecture relates to an organization as well as software development methodologyBook DescriptionThe Software Architects Handbook is a comprehensive guide to help developers, architects, and senior programmers advance their career in the software architecture domain. This book takes you through all the important concepts, right from design principles to different considerations at various stages of your career in software architecture. The book begins by covering the fundamentals, benefits, and purpose of software architecture. You will discover how software architecture relates to an organization, followed by identifying its significant quality attributes. Once you have covered the basics, you will explore design patterns, best practices, and paradigms for efficient software development. The book discusses which factors you need to consider for performance and security enhancements. You will learn to write documentation for your architectures and make appropriate decisions when considering DevOps. In addition to this, you will explore how to design legacy applications before understanding how to create software architectures that evolve as the market, business requirements, frameworks, tools, and best practices change over time. By the end of this book, you will not only have studied software architecture concepts but also built the soft skills necessary to grow in this field. What you will learn Design software architectures using patterns and best practices Explore the different considerations for designing software architecture Discover what it takes to continuously improve as a software architect Create loosely coupled systems that can support change Understand DevOps and how it affects software architecture Integrate, refactor, and re-architect legacy applications Who this book is for The Software Architects Handbook is for you if you are a software architect, chief technical officer (CTO), or senior developer looking to gain a firm grasp of software architecture.}
}
@inproceedings{10.1145/3318236.3318254,
author = {R\'{e}v\'{e}sz, \'{A}d\'{a}m and Pataki, Norbert},
title = {Continuous A/B Testing in Containers},
year = {2019},
isbn = {9781450362450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318236.3318254},
doi = {10.1145/3318236.3318254},
abstract = {Software version ranking plays an important role in improved user experience and software quality. A/B testing is a technique to distinguish between the popularity and usability of two quite similar versions (A and B) of a product, marketing strategy, search ad, etc. It is a kind of two-sample hypothesis testing, used in the field of statistics. This controlled experiment can evaluate user engagement or satisfaction with a new service, feature, or product. A/B testing is typically used in evaluation of user-experience design in software technology. DevOps is an emerging software methodology in which the development and operations are not independent processes, they affect each other. DevOps emphasizes the usage of virtualization technologies (e.g. containers). Docker is widely-used technology for containerization. In this paper, we deal with a new approach for regular A/B testing via Docker containers. Our solution provides an API that can be available from many DevOps tools. This approach is DevOps-style A/B testing because after the evaluation the better version remains in production.},
booktitle = {Proceedings of the 2019 2nd International Conference on Geoinformatics and Data Analysis},
pages = {11–14},
numpages = {4},
keywords = {A/B testing, containers, Docker, DevOps},
location = {Prague, Czech Republic},
series = {ICGDA 2019}
}
@book{10.5555/3086873,
author = {Mead, Nancy R. and Woody, Carol},
title = {Cyber Security Engineering: A Practical Approach for Systems and Software Assurance},
year = {2016},
isbn = {0134189809},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {Cyber Security Engineering is the definitive modern reference and tutorial on the full range of capabilities associated with modern cyber security engineering. Pioneering software assurance experts Dr. Nancy R. Mead and Dr. Carol C. Woody bring together comprehensive best practices for building software systems that exhibit superior operational security, and for considering security throughout your full system development and acquisition lifecycles. Drawing on their pioneering work at the Software Engineering Institute (SEI) and Carnegie Mellon University, Mead and Woody introduce seven core principles of software assurance, and show how to apply them coherently and systematically. Using these principles, they help you prioritize the wide range of possible security actions available to you, and justify the required investments. Cyber Security Engineering guides you through risk analysis, planning to manage secure software development, building organizational models, identifying required and missing competencies, and defining and structuring metrics. Mead and Woody address important topics, including the use of standards, engineering security requirements for acquiring COTS software, applying DevOps, analyzing malware to anticipate future vulnerabilities, and planning ongoing improvements. This book will be valuable to wide audiences of practitioners and managers with responsibility for systems, software, or quality engineering, reliability, security, acquisition, or operations. Whatever your role, it can help you reduce operational problems, eliminate excessive patching, and deliver software that is more resilient and secure.}
}
@book{10.5555/2967130,
author = {Passmore, Eric},
title = {Migrating Large-Scale Services to the Cloud},
year = {2016},
isbn = {1484218728},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {This book reveals the technical challenges and successful implementation details of migrating MSN, Microsofts consumer content portal--a business with 450 million worldwide users--into the Cloud. Following a technique long used in aviation, medicine, and other fields, MSNs Chief Technical Officer, Eric Passmore, describes the set of release, deployment, monitoring, and mitigation checklists used to build cloud services supporting hundreds of millions of users on Azure, Microsofts Public Cloud. An undertaking of this scale--involving services supported by a large team of engineers--involves unique challenges and risks. This book demonstrates through personal experience how to cut through the theory and provides checklists as a surprisingly simple antidote to the competing methodologies. This book works at two levels. At a fundamental level, businesses need to be successful in the cloud if they want to seize new opportunities and transform their business to compete successfully. This book provides a framework for success by identifying the "hidden" work as part of moving to the cloud. At a more practical, level there is an incredible hunger for simple to follow, "how-to" information on Cloud migration. This book is a reference guide to reduce risk and achieve success without requiring the busy reader to wade through theory. It contains simple to follow, "how-to" information on cloud migration. It is a reference guide to achieving success, and any team can modify these tasks to fit the needs of their own organization. Who This Book is For: Technology professionals who deploy services in the cloud or are thinking of moving to the cloud. Professionals in the DevOps and Cloud services fields need these skills to succeed in their current jobs or advance their careers.}
}
@inproceedings{10.1007/978-3-030-58817-5_50,
author = {Lohrasbinasab, Iraj and Acharya, Prameet Bhakta and Colomo-Palacios, Ricardo},
title = {BizDevOps: A Multivocal Literature Review},
year = {2020},
isbn = {978-3-030-58816-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58817-5_50},
doi = {10.1007/978-3-030-58817-5_50},
abstract = {BizDevOps as an extension of DevOps, reinforces the collaboration between business, development, and operation stakeholders in the organization in order to enhance the software cycle. While BizDevOps has not yet received much attention in academic circles, it has gained considerable prestige in the industry area. This situation reflects a gap between theory and practice in this context. In this work and by means of a Multivocal Literature Review authors gather visions from both academic and industry spheres on the topic. The result is a gathered image of BizDevOps, including definition, characteristics, related motivating issues, and potential challenges and benefits.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part VI},
pages = {698–713},
numpages = {16},
keywords = {DevOps 2.0, BizDevOps, Multivocal literature review},
location = {Cagliari, Italy}
}
@book{10.5555/3303915,
author = {Riti, Pierluigi},
title = {Pro DevOps with Google Cloud Platform: With Docker, Jenkins, and Kubernetes},
year = {2018},
isbn = {1484238966},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Use DevOps principles with Google Cloud Platform (GCP) to develop applications and services. This book builds chapter by chapter to a complete real-life scenario, explaining how to build, monitor, and maintain a complete application using DevOps in practice. Starting with core DevOps concepts, continuous integration, and continuous delivery, youll cover common tools including Jenkins, Docker, and Kubernetes in the context of a real microservices application to deploy in the cloud. You will also create a monitor for your cloud and see how to use its data to prevent errors and improve the stability of the system. By the end of Pro DevOps with Google Cloud Platform, you will be able to deploy, maintain, and monitor a real application with GCP. What You Will Learn Build and deploy applications and services using DevOps on Google Cloud Platform Maintain a complete continuous integration (CI) and continuous delivery (CD) pipeline Use containerization with Docker and Kubernetes Carry out CD with GCP and Jenkins Create microservices with Jenkins, Docker, and Kubernetes Monitor your newly deployed application and its deployment and performance Set up security and manage your network with GCP Who This Book Is For Developers and software architects who want to implement DevOps in practice. Some prior programming experience is recommended as well as a basic knowledge of a Linux command-line environment.}
}
@book{10.5555/3180902,
author = {Farcic, Viktor},
title = {The DevOps 2.2 Toolkit: Self-Sufficient Docker Clusters Building Self-Adaptive And Self-Healing Docker Clusters (Volume 3)},
year = {2017},
isbn = {1979347190},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
abstract = {It seems that with each new book the scope gets fuzzier and less precise. When I started writing Test-Driven Java Development the scope of the whole book was done in advance. I had a team working with me. We defined the index and a short description of each chapter. From there on we worked on a schedule as most technical authors do. Then I started writing the second book. The scope was more obscure. I wanted to write about DevOps practices and processes and had only a very broad idea what will be the outcome. I knew that Docker had to be there. I knew that configuration management is a must. Microservices, centralized logging, and a few other practices and tools that I used in my projects were part of the initial scope. For that book, I had no one behind me. There was no team but me, a lot of pizzas, an unknown number of cans of Red Bull, and many sleepless nights. The result is "The DevOps 2.0 Toolkit: Automating the Continuous Deployment Pipeline with Containerized Microservices". With the third book, the initial scope became even more obscure. I started writing without a plan. It was supposed to be about cluster management. After a couple of months of work, I attended DockerCon in Seattle where we were presented with the new Docker Swarm Mode. My immediate reaction was to throw everything I wrote to trash and start over. I did not know what will the book be about except that it must be something about Docker Swarm. I was impressed with the new design. Something about Swarm ended up being "The DevOps 2.1 Toolkit: Docker Swarm: Building, testing, deploying, and monitoring services inside Docker Swarm clusters". While working on it, I decided to make DevOps Toolkit Series. I thought that it would be great to record my experiences from different experiments, and from working with various companies and open source projects. So, naturally, I started thinking and planning the third installment in the series; "The DevOps Toolkit 2."2. The only problem is that, this time, I honestly did not have a clue what will it about. One idea was to do a deep comparison of different schedulers (e.g., Docker Swarm, Kubernetes, and Mesos/Maraton). The another was to explore serverless. Even though it is a terrible name (there are servers, we just don't manage them), it is a great subject. The ideas kept coming, but there was no clear winner. So, I decided not to define the scope. Instead, I defined some general objectives. The goals I set in front of were to build a self-adaptive and self-healing system based on Docker. When I started writing this book, I did not know how I will do that. There were different bits of practices and tools I've been using, but there was no visible light at the end of the tunnel. Instead of defining what the book will be, I defined what I want to accomplish. You can think of this book as my recording of the journey. I had to explore a lot. I had to adopt some new tools and write some code myself. Think of this book as "Viktor's diary while trying to do stuff." The objectives are to go beyond a simple setup of a cluster, services, continuous deployment, and all the other things you probably already know. If you don't, read my older books.}
}
@book{10.5555/3158882,
author = {Farcic, Viktor},
title = {The DevOps 2.1 Toolkit: Docker Swarm},
year = {2017},
isbn = {1787289702},
publisher = {Packt Publishing},
abstract = {Viktor Farcic's latest book, The DevOps 2.1 Toolkit: Docker Swarm, shows you how to successfully integrate Docker Swarm into your DevOps toolset. About This Book * Expand your DevOps Toolkit with the DevOps thought leader, Viktor Farcic * Build, test, deploy, and monitor services inside Docker Swarm clusters * Translate your understanding to different hosting providers like AWS, Azure, and DigitalOcean * Go beyond simple deployment to explore how to create a continuous deployment process * Extend the deep understanding you gained from Viktor's DevOps 2.0 Toolkit book Who This Book Is For This book is for professionals interested in the full microservices life cycle combined with continuous deployment and containers. Target audience could be architects who want to know how to design their systems around microservices. It could be DevOps wanting to know how to apply modern configuration management practices and continuously deploy applications packed in containers. It is for developers who would like to take the process back into their hands as well as for managers who would like to gain a better understanding of the process used to deliver software from the beginning to the end. This book is for everyone wanting to know more about the software development life cycle starting from requirements and design, through the development and testing all the way until deployment and post-deployment phases. We'll create the processes taking into account the best practices developed by and for some of the biggest companies. What You Will Learn * Learn all aspects of Docker Swarm from building, testing, deploying, and monitoring services inside Docker Swarm clusters, available since Docker 1.12. * Master the deeper logic of DevOps with Viktor, so that you can successfully apply that logic across any specific set of tools you're working with. * Translate a deep understanding to different hosting providers like AWS, Azure, DigitalOcean, among others. * You'll go beyond simple deployment: you will explore with Viktor how to create a continuous deployment process. Accomplish zero-downtime deployments, and what to do in case of a failover. * Know how to run services at scale, how to monitor the systems, and how to make it heal itself. In Detail Viktor Farcic's latest book, The DevOps 2.1 Toolkit: Docker Swarm, takes you deeper into one of the major subjects of his international best seller, The DevOps 2.0 Toolkit, and shows you how to successfully integrate Docker Swarm into your DevOps toolset. Viktor shares with you his expert knowledge in all aspects of building, testing, deploying, and monitoring services inside Docker Swarm clusters. You'll go through all the tools required for running a cluster. You'll travel through the whole process with clusters running locally on a laptop. Once you're confident with that outcome, Viktor shows you how to translate your experience to different hosting providers like AWS, Azure, and DigitalOcean. Viktor has updated his DevOps 2.0 framework in this book to use the latest and greatest features and techniques introduced in Docker. We'll go through many practices and even more tools. While there will be a lot of theory, this is a hands-on book. You won't be able to complete it by reading it on the metro on your way to work. You'll have to read this book while in front of the computer and get your hands dirty. Style and approach We'll go through many practices and even more tools. While there will be a lot of theory, this is a hands-on book. You'll have to read this book while in front of the computer and get your hands dirty. The goal is not to master one particular set of tools, but to learn the logic behind them so that you can apply it to your job in various contexts.}
}
@inproceedings{10.1145/3316615.3316670,
author = {Ibrahim, Mahmoud Mohammad Ahmad and Syed-Mohamad, Sharifah Mashita and Husin, Mohd Heikal},
title = {Managing Quality Assurance Challenges of DevOps through Analytics},
year = {2019},
isbn = {9781450365734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316615.3316670},
doi = {10.1145/3316615.3316670},
abstract = {DevOps is an intermarriage between developmental practices and operational modalities. The methodology employs the practices of continuous integration and delivery and places the deployment pipeline as the main requirement to automate, deliver and operate software in a robust way, without compromising on the quality in the software development process. Over time, many systems and tools have been developed to implement the deployment pipeline and support the continuous delivery process. A pipeline splits the process of software delivery into various stages. Each stage is designed to verify the quality of new features from a new perspective to attest to the functionality and prevent either small or big errors from impacting the end users. The pipeline must provide a response and feedback loop to the concerned team and provide a window into the flow of changes that takes place. However, there is no clear rule to define what goes into a pipeline. This paper reviews the challenges of quality assurance of DevOps and provides tentative recommendations to deal with quality issues. Our proposed pipeline with analytic features is expected to provide accurate metrics on a real-time basis.},
booktitle = {Proceedings of the 2019 8th International Conference on Software and Computer Applications},
pages = {194–198},
numpages = {5},
keywords = {quality assurance, continuous integration, continuous delivery, devops analytics, continuous deployment, DevOps, deployment pipeline},
location = {Penang, Malaysia},
series = {ICSCA '19}
}
@book{10.5555/3002587,
author = {Axelos},
title = {ITIL Practitioner Guidance},
year = {2016},
isbn = {0113314876},
publisher = {The Stationery Office},
address = {GBR},
abstract = {ITIL Practitioner Guidance is the essential reference text which accompanies the ITIL Practitioner qualification. Fully integrated with the ITIL Practitioner syllabus, this publication is also a practical guide that helps IT service management (ITSM) professionals turn ITIL theory into practice through case studies, worksheets, templates and scenarios. The book assumes knowledge of ITIL and ITSM up to ITIL Foundation level, and begins with a discussion of the guiding principles of ITSM: Focus on value Start where you are Progress iteratively Be transparent Keep it simple Design for experience Work holistically Observe directly Collaborate It goes on to explain how these guiding principles are essential for ITSM and how they relate to philosophies, frameworks and methodologies such as DevOps, Lean, Agile etc. The publication shows how following the CSI (continual service improvement) approach, and how the core skills of organizational change management, communication, metrics and measurement, can underpin successful ITSM improvement initiatives. Assembled by the Practitioner Architect Team of Kevin Behr, Karen Ferris, Lou Hunnebeck, Stuart Rance, Barclay Rae and Paul Wilkinson, a team of renowned ITSM experts under the guidance of AXELOS' Kaimar Karu, ITIL Practitioner Guidance concludes with a practical toolkit containing templates, worksheets and assessments that will help ITSM professionals to improve the value of the service they provide to their customers.}
}
@inproceedings{10.1007/978-3-030-87013-3_19,
author = {Umar, Muhammad and Colomo-Palacios, Ricardo},
title = {DevOps Job Roles: A Multivocal Literature Review},
year = {2021},
isbn = {978-3-030-87012-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87013-3_19},
doi = {10.1007/978-3-030-87013-3_19},
abstract = {DevOps bridges the gap between software development and operations to provide rapid deliveries and integrated collaboration. However, DevOps entails lots of factors and challenges involved in its implementation including technical, organizational and personnel aspects. Focusing on the last set of aspects, this paper identifies current DevOps job roles, an aspect that is crucial to implement and to support DevOps practices in organizations. It also highlights collaboration between different actors under different automation levels in DevOps to deliver software at high speed.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part IX},
pages = {247–256},
numpages = {10},
keywords = {Software development, Job roles, DevOps, Multivocal literature review},
location = {Cagliari, Italy}
}
@book{10.5555/2789645,
author = {Humble, Jez and Molesky, Joanne and O'Reilly, Barry},
title = {Lean Enterprise: How High Performance Organizations Innovate at Scale},
year = {2015},
isbn = {1449368425},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {How well does your organization respond to changing market conditions, customer needs, and emerging technologies when building software-based products? This practical guide presents Lean and Agile principles and patterns to help you move fast at scaleand demonstrates why and how to apply these methodologies throughout your organization, rather than with just one department or team.Through case studies, youll learn how successful enterprises have rethought everything from governance and financial management to systems architecture and organizational culture in the pursuit of radically improved performance. Adopting Lean will take time and commitment, but its vital for harnessing the cultural and technical forces that are accelerating the rate of innovation.Discover how Lean focuses on people and teamwork at every level, in contrast to traditional management practicesApproach problem-solving experimentally, by exploring solutions, testing assumptions, and getting feedback from real usersLead and manage large-scale programs in a way that empowers employees, increases the speed and quality of delivery, and lowers costsLearn how to implement ideas from the DevOps and Lean Startup movements even in complex, regulated environments}
}
@book{10.5555/2588209,
author = {Jackson, Kevin and Bunch, Cody},
title = {OpenStack Cloud Computing Cookbook},
year = {2013},
isbn = {1782167587},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Over 100 recipes to successfully set up and manage your OpenStack cloud environments with complete coverage of Nova, Swift, Keystone, Glance, Horizon, Neutron, and Cinder Overview Updated for OpenStack Grizzly Learn how to install, configure, and manage all of the OpenStack core projects including new topics like block storage and software defined networking Learn how to build your Private Cloud utilizing DevOps and Continuous Integration tools and techniques In Detail OpenStack is an open source cloud operating stack that was born from Rackspace and NASA and became a global success, developed by scores of people around the globe and backed by some of the leading players in the cloud space today. OpenStack Cloud Computing Cookbook, Second Edition will show you exactly how to install the components that are required to make up a private cloud environment. You will learn how to set up an environment that you manage just as you would a public cloud provider like Rackspace with the help of experienced OpenStack administrators and architects. We begin by configuring the key components such as identity, image compute, and storage in a safe, virtual environment that we will then build on this throughout the book. The book will also teach you about provisioning and managing OpenStack in the datacenter using proven DevOps tools and techniques. From installing or creating a sandbox environment using Vagrant and VirtualBox to installing OpenStack in the datacenter, from understanding logging to automating OpenStack installations, whatever level of experience or interest you have with OpenStack there is a chapter for you. Installation steps cover compute, object storage, identity, block storage volumes, image, horizon, software defined networking and DevOps tools for automating your infrastructure OpenStack Cloud Computing Cookbook, Second edition gives you clear step-by-step instructions to installing and running your own private cloud. What you will learn from this book Understand, install, configure, and manage Nova, the OpenStack cloud compute resource Dive headfirst into managing software defined networks with the OpenStack networking project and Open vSwitch Install and configure, Keystone, the OpenStack identity &amp; authentication service Install, configure and operate the OpenStack block storage project: Neutron Install and manage Swift, the highly scalable OpenStack object storage service Gain hands on experience with the OpenStack dashboard Horizon Explore different monitoring frameworks to ensure your OpenStack cloud is always online and performing optimally Automate your installations using Vagrant and Chef. Create custom Windows and Linux images for use in your private cloud environment. Approach OpenStack Cloud Computing Cookbook Second Edition will give you clear step-by-step instructions to installing and running your own private cloud successfully. It is full of practical and applicable recipes that enable you to use the latest capabilities of OpenStack and implement them. The book explains every step in detail so that you can build your knowledge about how things work.}
}
@book{10.5555/3312469,
author = {Chelliah, Pethuru Raj and Naithani, Shreyash and Singh, Shailender},
title = {Practical Site Reliability Engineering: Automate the Process of Designing, Developing, and Delivering Highly Reliable Apps and Services with SRE},
year = {2018},
isbn = {1788839560},
publisher = {Packt Publishing},
abstract = {Create, deploy, and manage applications at scale using SRE principles Key Features Build and run highly available, scalable, and secure software Explore abstract SRE in a simplified and streamlined way Enhance the reliability of cloud environments through SRE enhancements Book Description Site reliability engineering (SRE) is being touted as the most competent paradigm in establishing and ensuring next-generation high-quality software solutions. This book starts by introducing you to the SRE paradigm and covers the need for highly reliable IT platforms and infrastructures. As you make your way through the next set of chapters, you will learn to develop microservices using Spring Boot and make use of RESTful frameworks. You will also learn about GitHub for deployment, containerization, and Docker containers. Practical Site Reliability Engineering teaches you to set up and sustain containerized cloud environments, and also covers architectural and design patterns and reliability implementation techniques such as reactive programming, and languages such as Ballerina and Rust. In the concluding chapters, you will get well-versed with service mesh solutions such as Istio and Linkerd, and understand service resilience test practices, API gateways, and edge/fog computing. By the end of this book, you will have gained experience on working with SRE concepts and be able to deliver highly reliable apps and services. What you will learn Understand how to achieve your SRE goals Grasp Docker-enabled containerization concepts Leverage enterprise DevOps capabilities and Microservices architecture (MSA) Get to grips with the service mesh concept and frameworks such as Istio and Linkerd Discover best practices for performance and resiliency Follow software reliability prediction approaches and enable patterns Understand Kubernetes for container and cloud orchestration Explore the end-to-end software engineering process for the containerized world Who this book is for Practical Site Reliability Engineering helps software developers, IT professionals, DevOps engineers, performance specialists, and system engineers understand how the emerging domain of SRE comes handy in automating and accelerating the process of designing, developing, debugging, and deploying highly reliable applications and services.}
}
@book{10.5555/2961874,
author = {Kort, Wouter de},
title = {DevOps on the Microsoft Stack},
year = {2016},
isbn = {1484214471},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {This book tells you everything you need to know to help your organization implement DevOps on the Microsoft platform. You will learn how to use Visual Studio, Visual Studio Team Services, and Azure to implement a complete DevOps process in your company. You will learn about Agile Project Management, Continuous Integration, Continuous Delivery, Technical Debt Management, Automatic Testing and Monitoring, and see how all these areas fit together. DevOps is important for organizations that want to make the best use of their resources and avoid costly mistakes. Teams that embrace DevOps deploy code up to 30 times more frequently than their competition and less than 50% of their deployments fail according to Puppet Labs State of DevOps survey. DevOps on the Microsoft Stack shows you how to help your organization implement DevOps, covering the tooling they will need and how to make everything work together while following best practices. The focus is not only on technology but also on the cultural issues that teams will face when implementing DevOps. The authors goal is to not only show you which tooling there is but help you to successfully use everything together to implement DevOps in your projects and organization. In this book, you'll learn: What DevOps is and how it can help development teams How to use Visual Studio, Visual Studio Team Services, and Azure to setup a DevOps process How to introduce DevOps to your organization and how to overcome problems}
}
@book{10.5555/2838860,
author = {Bumgardner, V.K. Cody},
title = {OpenStack in Action},
year = {2015},
isbn = {1617292168},
publisher = {Manning Publications Co.},
address = {USA},
edition = {1st},
abstract = {In the cloud computing model, a cluster of physical computers hosts an environment that provides shared services (public and private) and offers the flexibility to easily add, remove, and expand virtual servers and applications. OpenStack is an open source framework that can be installed on individual physical servers to a cloud platform and enables the building of custom infrastructure (IaaS), platform (PaaS), and software (SaaS) services without the high cost and vendor lock-in associated with proprietary cloud platforms. OpenStack in Action offers real world use cases and step-by-step instructions to develop cloud platforms from inception to deployment. It explains the design of both the physical hardware cluster and the infrastructure services needed to create a custom cloud platform. It shows how to select and set up virtual and physical servers, implement software-defined networking, and the myriad other technical details required to design, deploy, and operate an OpenStack cloud in an enterprise. It also discusses the cloud operation techniques needed to establish security practices, access control, efficient scalability, and day-to-day DevOps practices. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications.}
}
@inproceedings{10.1145/3377811.3380406,
author = {Henkel, Jordan and Bird, Christian and Lahiri, Shuvendu K. and Reps, Thomas},
title = {Learning from, Understanding, and Supporting DevOps Artifacts for Docker},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380406},
doi = {10.1145/3377811.3380406},
abstract = {With the growing use of DevOps tools and frameworks, there is an increased need for tools and techniques that support more than code. The current state-of-the-art in static developer assistance for tools like Docker is limited to shallow syntactic validation. We identify three core challenges in the realm of learning from, understanding, and supporting developers writing DevOps artifacts: (i) nested languages in DevOps artifacts, (ii) rule mining, and (iii) the lack of semantic rule-based analysis. To address these challenges we introduce a toolset, binnacle, that enabled us to ingest 900,000 GitHub repositories.Focusing on Docker, we extracted approximately 178,000 unique Dockerfiles, and also identified a Gold Set of Dockerfiles written by Docker experts. We addressed challenge (i) by reducing the number of effectively uninterpretable nodes in our ASTs by over 80% via a technique we call phased parsing. To address challenge (ii), we introduced a novel rule-mining technique capable of recovering two-thirds of the rules in a benchmark we curated. Through this automated mining, we were able to recover 16 new rules that were not found during manual rule collection. To address challenge (iii), we manually collected a set of rules for Dockerfiles from commits to the files in the Gold Set. These rules encapsulate best practices, avoid docker build failures, and improve image size and build latency. We created an analyzer that used these rules, and found that, on average, Dockerfiles on GitHub violated the rules five times more frequently than the Dockerfiles in our Gold Set. We also found that industrial Dockerfiles fared no better than those sourced from GitHub.The learned rules and analyzer in binnacle can be used to aid developers in the IDE when creating Dockerfiles, and in a post-hoc fashion to identify issues in, and to improve, existing Dockerfiles.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {38–49},
numpages = {12},
keywords = {docker, static checking, DevOps, mining},
location = {Seoul, South Korea},
series = {ICSE '20}
}
@inproceedings{10.1145/2961111.2962587,
author = {Shahin, Mojtaba and Babar, Muhammad Ali and Zhu, Liming},
title = {The Intersection of Continuous Deployment and Architecting Process: Practitioners' Perspectives},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962587},
doi = {10.1145/2961111.2962587},
abstract = {Context: Development and Operations (DevOps) is an emerging software industry movement to bridge the gap between software development and operations teams. DevOps supports frequently and reliably releasing new features and products-- thus subsuming Continuous Deployment (CD) practice. Goal: This research aims at empirically exploring the potential impact of CD practice on architecting process. Method: We carried out a case study involving interviews with 16 software practitioners. Results: We have identified (1) a range of recurring architectural challenges (i.e., highly coupled monolithic architecture, team dependencies, and ever-changing operational environments and tools) and (2) five main architectural principles (i.e., small and independent deployment units, not too much focus on reusability, aggregating logs, isolating changes, and testability inside the architecture) that should be considered when an application is (re-) architected for CD practice. This study also supports that software architecture can better support operations if an operations team is engaged at an early stage of software development for taking operational aspects into considerations. Conclusion: These findings provide evidence that software architecture plays a significant role in successfully and efficiently adopting continuous deployment. The findings contribute to establish an evidential body of knowledge about the state of the art of architecting for CD practice},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {44},
numpages = {10},
keywords = {empirical study, DevOps, continuous deployment, Software architecture},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}
@book{10.5555/3036143,
author = {Ravichandran, Aruna and Taylor, Kieran and Waterhouse, Peter},
title = {DevOps for Digital Leaders: Reignite Business with a Modern DevOps-Enabled Software Factory},
year = {2016},
isbn = {1484218418},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {This book provides digital leaders who are accountable for the rapid development of high-quality software applications a concise guide to designing, implementing, measuring, and improving DevOps programs that are tailored to their organizations. In DevOps for Digital Leaders, deep collective experience on both sides of the devops divide informs the global thought leadership and penetrating insights of the authors, all three of whom are cross-portfolio DevOps leaders at CA Technologies. Aruna Ravichandran, Kieran Taylor, and Peter Waterhouse analyze the organizational benefits, costs, freedoms, and constraints of DevOps. They chart the coordinated strategy of organizational change, metrics, lean thinking, and investment that an enterprise must undertake to realize the full potential of DevOps and reach the sweet spot where accelerating code deployments drive increasing customer satisfaction, revenue, and profitability. Digital leaders are charged to bridge the devops disconnect if their organizations are to survive and flourish in a business world increasingly differentiated by the degree to which dynamic application software development harmonizes with operational resilience and reliability. This short book applies the DevOps perspective to the competitive challenge, faced by every high-performance IT organization today, of integrating and automating open source, cloud, and enterprise tools, processes, and techniques across the software development life cycle from requirements to release. What Readers Will Learn Remove dependencies and constraints so that parallel practices can accelerate the development of defect-free software Automate continuous delivery across the software life cycle to eliminate release bottlenecks, manual labor waste, and technical debt accumulation Generate virtualized production-style testing of applications through real-time behavioral analytics Adopt agile practices so operations teams can support developer productivity with automated feedback, streamline infrastructure monitoring, spot and resolve operations issues before they impact production, and improve customer experience Identify the DevOps metrics appropriate to your organization and integrate DevOps with your existing best practices and investment Who This Book Is ForIT leaders in largecompanies and government agencies who have any level of responsibility for the rapid development of high-quality software applications. The secondary readership is members of development and operations teams, security professionals, and service managers.}
}
@inproceedings{10.1145/3316615.3316619,
author = {Toh, M. Zulfahmi and Sahibuddin, Shamsul and Mahrin, Mohd Naz'ri},
title = {Adoption Issues in DevOps from the Perspective of Continuous Delivery Pipeline},
year = {2019},
isbn = {9781450365734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316615.3316619},
doi = {10.1145/3316615.3316619},
abstract = {DevOps and Continuous Delivery (CD) are the terms that are always related to each other in Software Delivery and Operation Process area. DevOps introduces a significant agile perspective to deliver the software product in short cycle time that will reduce technical debt that is caused by delay. Continuous Delivery is one of the DevOps' practices that enables software organization to release new features and new products rapidly. However, the correct practices are still in ambiguity to the current CD process. This paper investigates the advantages and limitation of DevOps adoption to improve the CD process. A qualitative web survey has been conducted to identify the DevOps and Continuous Delivery advantages and adoption problems. 13 respondents' feedbacks have been collected and analyzed. Based on the survey, there are four significant DevOps' practices that need to be considered and developed as a proper guideline to introduce to practitioners.},
booktitle = {Proceedings of the 2019 8th International Conference on Software and Computer Applications},
pages = {173–177},
numpages = {5},
keywords = {software operation, DevOps, agile, continuous integration, agile operations, continuous software engineering, continuous delivery},
location = {Penang, Malaysia},
series = {ICSCA '19}
}
@book{10.5555/3164941,
author = {Felsen, Nathaniel},
title = {Effective DevOps with AWS},
year = {2017},
isbn = {1786466813},
publisher = {Packt Publishing},
abstract = {Key Features Implement DevOps principles to take full advantage of the AWS stack and servicesTake expert look at solving problems faced by real developers and operation teams and learn to overcome themLearn from expert insights of the author who has worked with Silicon Valley's most high-profile companies Book Description The DevOps movement has transformed the way modern tech companies work. AWS which has been on the forefront of the Cloud computing revolution has also been a key contributor of this DevOps movement creating a huge range of managed services that help you implement the DevOps principles. In this book, you'll see how the most successful tech start-ups launch and scale their services on AWS and how you can too. Written by a lead member of Mediums DevOps team, this book explains how to treat infrastructure as code, meaning you can bring resources online and offline as necessary with the code as easily as you control your software. You will also build a continuous integration and continuous deployment pipeline to keep your app up to date. You'll find out how to scale your applications to offer maximum performance to users anywhere in the world, even when traffic spikes with the latest technologies, such as containers and serverless computing. You will also take a deep dive into monitoring and alerting to make sure your users have the best experience when using your service. Finally, you'll get to grips with ensuring the security of your platform and data. What you will learnFind out what it means to practice DevOps and what its principles areBuild repeatable infrastructures using templates and configuration managementDeploy}
}
@inproceedings{10.1109/IECON.2019.8927081,
author = {di Orio, Giovanni and Mal\'{o}, Pedro and Barata, Jos\'{e}},
title = {NOVAAS: A Reference Implementation of Industrie4.0 Asset Administration Shell with Best-of-Breed Practices from IT Engineering},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2019.8927081},
doi = {10.1109/IECON.2019.8927081},
abstract = {The fundamental role played by “new technologies” to enhance the manufacturing infrastructure, products and services is confirmed by the strategies, roadmaps and initiatives established by the developed countries such as EU-28, US, China and Japan. Putting the light on Europe, the key priorities for manufacturing are aligned with the Industry 4.0 strategy/program where the proliferation of cyber-physical systems (CPSs) and technologies like predictive data analytics, cloud and edge computing are creating the foundation for smart factory, i.e. the efficient and effective connection between products, processes and their related services. However, even if the smart factory vision is quite clear, in practice, it is still unclear how it can be implemented in a way to allow the transparent data exchange between all the layers of a manufacturing company, as well as, between the manufacturing company and the value chain partners. Within the German Industrie4.0 program, the Asset Administration Shell concept is defined to create a standardized digital representation of the asset while ensuring interoperability between all the applications within the manufacturing ecosystem. In this paper, an implementation of the asset administration shell is provided – also called NOVAAS – based on the deep usage of internet technologies, languages and software engineering techniques and methods (such as DevOps, microservices, continuous integration, etc.). The main goal is to contribute towards a generic and extensible reference implementation of the concept.},
booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
pages = {5505–5512},
numpages = {8},
location = {Lisbon, Portugal}
}
@book{10.5555/3306694,
author = {Swartout, Paul},
title = {Continuous Delivery and DevOps A Quickstart Guide: Start Your Journey to Successful Adoption of CD and DevOps, 3rd Edition},
year = {2018},
isbn = {1788995473},
publisher = {Packt Publishing},
edition = {3rd},
abstract = {A practical and engaging guide to help map out, plan and navigate through the journey to successful CD and DevOps adoption. Key Features Identify and overcome the issues that stifle the delivery of quality software Learn how Continuous Delivery and DevOps work together with other agile tools Real-world examples, tricks and tips that will help the successful adoption of CD &amp; DevOps Book Description Over the past few years, Continuous Delivery (CD) and DevOps have been in the spotlight in tech media, at conferences, and in boardrooms alike. Many articles and books have been written covering the technical aspects of CD and DevOps, yet the vast majority of the industry doesn't fully understand what they actually are and how, if adopted correctly they can help organizations drastically change the way they deliver value. This book will help you figure out how CD and DevOps can help you to optimize, streamline, and improve the way you work to consistently deliver quality software. In this edition, you'll be introduced to modern tools, techniques, and examples to help you understand what the adoption of CD and DevOps entails. It provides clear and concise insights in to what CD and DevOps are all about, how to go about both preparing for and adopting them, and what quantifiable value they bring. You will be guided through the various stages of adoption, the impact they will have on your business and those working within it, how to overcome common problems, and what to do once CD and DevOps have become truly embedded. Included within this book are some real-world examples, tricks, and tips that will help ease the adoption process and allow you to fully utilize the power of CD and DevOps What you will learn Explore Continuous Delivery and DevOps in depth Discover how CD and DevOps fits in with recent trends such as DataOps, SecOps, pipelines and CI Understand the root causes of the pain points within your existing product delivery process Understand the human elements of CD and DevOps and how intrinsic they are to your success Avoid common traps, pitfalls and hurdles as you implement CD and DevOps Monitor and communicate the relative success of DevOps and CD adoption Extend and reuse CD and DevOps approaches Who this book is for Whether you are a software developer, a system administrator, an agile coach, a product manager, a project manager, a CTO, a VP, a CEO or anyone else involved in software delivery, you will have a common problem which is delivering quality software. This book has been written for anyone and everyone who wants to understand how to regularly deliver quality software to their customers without said pain.}
}
@inproceedings{10.1109/HICSS.2016.671,
author = {Lwakatare, Lucy Ellen and Karvonen, Teemu and Sauvola, Tanja and Kuvaja, Pasi and Olsson, Helena Holmstrom and Bosch, Jan and Oivo, Markku},
title = {Towards DevOps in the Embedded Systems Domain: Why is It So Hard?},
year = {2016},
isbn = {9780769556703},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HICSS.2016.671},
doi = {10.1109/HICSS.2016.671},
abstract = {DevOps is a predominant phenomenon in the web domain. Its two core principles emphasize collaboration between software development and operations, and the use of agile principles to manage deployment environments and their configurations. DevOps techniques, such as collaboration and behaviour-driven monitoring, have been used by web companies to facilitate continuous deployment of new functionality to customers. The techniques may also offer opportunities for continuous product improvement when adopted in the embedded systems domain. However, certain characteristics of embedded software development present obstacles for DevOps adoption, and as yet, there is no empirical evidence of its adoption in the embedded systems domain. In this study, we present the challenges for DevOps adoption in embedded systems using a multiple-case study approach with four companies. The contribution of this paper is to introduce the concept of DevOps adoption in the embedded systems domain and then to identify key challenges for the DevOps adoption.},
booktitle = {Proceedings of the 2016 49th Hawaii International Conference on System Sciences (HICSS)},
pages = {5437–5446},
numpages = {10},
series = {HICSS '16}
}
@inproceedings{10.1007/978-3-030-39306-9_9,
author = {Ferry, Nicolas and Dominiak, Jacek and Gallon, Anne and Gonz\'{a}lez, Elena and Iturbe, Eider and Lavirotte, St\'{e}phane and Martinez, Saturnino and Metzger, Andreas and Munt\'{e}s-Mulero, Victor and Nguyen, Phu H. and Palm, Alexander and Rego, Angel and Rios, Erkuden and Riviera, Diego and Solberg, Arnor and Song, Hui and Tigli, Jean-Yves and Winter, Thierry},
title = {Development and Operation of Trustworthy Smart IoT Systems: The ENACT Framework},
year = {2019},
isbn = {978-3-030-39305-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39306-9_9},
doi = {10.1007/978-3-030-39306-9_9},
abstract = {To unleash the full potential of IoT, it is critical to facilitate threation and operation of trustworthy Smart IoT Systems (SIS). Software development and delivery of SIS would greatly benefit from DevOps as devices and IoT services requirements for reliability, quality, security and safety are paramount. However, DevOps practices are far from widely adopted in the IoT, in particular, due to a lack of key enabling tools. In last year paper at DevOps’18, we presented the ENACT research roadmap that identified the critical challenges to enable DevOps in the realm of trustworthy SIS. In this paper, we present the ENACT DevOps Framework as our current realization of these methods and tools.},
booktitle = {Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Ch\^{a}teau de Villebrumier, France, May 6–8, 2019, Revised Selected Papers},
pages = {121–138},
numpages = {18},
keywords = {Trustworthiness, DevOps, Internet-of-Things},
location = {Villebrumier, France}
}
@inproceedings{10.1145/3468264.3473101,
author = {Sokolowski, Daniel},
title = {Deployment Coordination for Cross-Functional DevOps Teams},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473101},
doi = {10.1145/3468264.3473101},
abstract = {Software stability and reliability are the core concerns of DevOps. They are improved by tightening the collaboration between developers and operators in cross-functional teams on the one hand and by automating operations through continuous integration (CI) and infrastructure as code (IaC) on the other hand. Ideally, teams in DevOps are fully independent. Still, their applications often depend on each other in practice, requiring them to coordinate their deployment through centralization or manual coordination. With this work, we propose and implement the novel IaC solution µs ([mju:z] ”muse”), which automates deployment coordination in a decentralized fashion. µs is the first approach that is compatible with the DevOps goals as it enables truly independent operations of the DevOps teams. We define our research problem through a questionnaire survey with IT professionals and evaluate the solution by comparing it to other modern IaC approaches, assessing its performance, and applying it to existing IaC programs.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1630–1634},
numpages = {5},
keywords = {Cloud, DevOps, Resource Orchestration, Infrastructure as Code},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}
@inproceedings{10.1145/3425269.3425277,
author = {Costa, Diego Ivo Campos and Filho, Eduardo Pereira e Silva and Silva, Reginaldo Florencio da and de C. Quaresma Gama, Thiago Dias and Cort\'{e}s, Mariela I.},
title = {Microservice Architecture: A Tertiary Study},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425277},
doi = {10.1145/3425269.3425277},
abstract = {Context. The large-scale use of microservices and their increasing adoption in the industry in recent years has motivated researches on the most diverse aspects related to microservice-based development. However, as it is a relatively new topic, there is still no consolidated body of knowledge in the area. Objective. The present work intends to investigate the current state of research on microservices based on the formulation of six research questions covering fundamental aspects, such as: main interest topics and adopted standards, techniques and tools have been used and application areas. Method. From four digital libraries, 22 secondary studies were selected as a data source, which were analyzed and synthesized in the present study following the proposed research protocol. Results. Among the main topics of interest addressed, we highlight researches related to the applicability of microservice architecture, both by industry and academia. Results indicated that standards focus on challenges related to communication have been the most commonly considered by researchers of the area. Finally, the predominance in the use of the Docker container and the presence of DevOps practices in the automation of operations are noteworthy. Conclusions. The present mapping study points to some directions of research based on the identified gaps, such as modeling and testing of microservice applications, and addressing security aspects. Another promising point to be explored involves the combined use of microservice architecture with other related concepts such as IoT, smart cities, FOG computing and reactive systems, in order to reinforce the use of microservices, as well as creating new solutions and challenges to be researched.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {61–70},
numpages = {10},
keywords = {Microsservi\c{c}os, Industria, Academia, Padr\~{o}es de arquitetura, Mapeamento sistem\'{a}tico, Arquitetura de software},
location = {Natal, Brazil},
series = {SBCARS '20}
}
@inproceedings{10.1109/HICSS.2016.665,
author = {Chen, Hong-Mei and Kazman, Rick and Haziyev, Serge},
title = {Agile Big Data Analytics Development: An Architecture-Centric Approach},
year = {2016},
isbn = {9780769556703},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HICSS.2016.665},
doi = {10.1109/HICSS.2016.665},
abstract = {Agile development for big data analytics has become the new normal. However, research questions remain: 1) how should a big data system be designed and developed to effectively support advanced analytics__ __ and 2) how should the agile process be adapted for big data analytics development__ __ This article contributes an Architecture-centric Agile Big data Analytics (AABA) development methodology evolved and validated in 10 case studies through Collaborative Practice Research. Our studies showed that architecture agility is the key for successful agile big data analytics development. Employing an architecture-centric approach, the AABA methodology integrates the Big Data system Design (BDD) method and Architecture-centric Agile Analytics with architecture-supported DevOps (AAA) model for effective value discovery and rapid continuous delivery of value. The uses of a design concepts catalog and architectural spikes are advancements to architecture design methods that have proven to be critical to agile big data analytics development.},
booktitle = {Proceedings of the 2016 49th Hawaii International Conference on System Sciences (HICSS)},
pages = {5378–5387},
numpages = {10},
series = {HICSS '16}
}
@book{10.5555/3169510,
author = {Das, Satyajit and Modi, Jhalak},
title = {AWS Networking Cookbook: Powerful Recipes to Overcome the Pain Points of Optimizing Your Virtual Private Cloud (VPC)},
year = {2017},
isbn = {1787123243},
publisher = {Packt Publishing},
abstract = {Key FeaturesMaster AWS networking concepts with AWS Networking Cookbook. Design and implement highly available connectivity and multi-regioned AWS solutionsA recipe-based guide that will eliminate the complications of AWS networking. A guide to automate networking services and featuresBook DescriptionThis book starts with practical recipes on the fundamentals of cloud networking and gradually moves on to configuring networks and implementing infrastructure automation. This book then supplies in-depth recipes on networking components like Network Interface, Internet Gateways, DNS, Elastic IP addresses, and VPN CloudHub. Later, this book also delves into designing, implementing, and optimizing static and dynamic routing architectures, multi-region solutions, and highly available connectivity for your enterprise. Finally, this book will teach you to troubleshoot your VPC's network, increasing your VPC's efficiency. By the end of this book, you will have advanced knowledge of AWS networking concepts and technologies and will have mastered implementing infrastructure automation and optimizing your VPC. What you will learnCreate basic network in AWS Create production grade network in AWSCreate global scale network in AWS Security and Compliance with AWS Network Troubleshooting, best practices and limitations of AWS network Pricing model of AWS network components Route 53 and Cloudfront concepts and routing policies VPC Automation using Ansible and Cloud Formation About the AuthorSatyajit Das has more than sixteen years of IT experience. He is currently working as an AWS CoE lead cloud architect in a large enterprise. He has also worked as an enterprise architect, solution architect, and technical architect in recent engagements. He has guided, designed, integrated, implemented, and governed enterprise-grade applications. He works on building solutions using microservices on the hybrid cloud using DevOps principles. He has extensively worked on IoT, AWS, and cloud migration. Satyajit has worked in leading organizations, such as Wipro, Infosys, PwC, and Accenture, in various challenging roles. Jhalak Modi is a DevOps, cloud architect, and an AWS trainer with a deep interest and expertise in implementing multi-tier architectures, cluster platforms, and automation solutions. She is an AWS certified solutions architect professional and a certified DevOps professional with 10+ certifications in trending technologies. Jhalak is also a public speaker at various AWS events, colleges/universities, and meet-ups, and has provided AWS and Linux training at several renowned institutes and corporates. Currently, she is working with KOGENTiX and has worked with Wipro Technologies and Electromech Corporation in the past.}
}
@book{10.5555/2987830,
author = {Williamson, Leigh and Barcia, Roland and Chandgadkar, Omkar and Mathur, Ashish and Ray, Soma and Schrag, Darrell and Snook, Roger},
title = {Enterprise Class Mobile Application Development: A Complete Lifecycle Approach for Producing Mobile Apps},
year = {2015},
isbn = {0133478637},
publisher = {IBM Press},
edition = {1st},
abstract = {Build and Deploy Mobile Business Apps That Smoothly Integrate with Enterprise IT For todays enterprises, mobile apps can have a truly transformational impact. However, to maximize their value, you cant build them in isolation. Your new mobile apps must reflect the revolutionary mobile paradigm and delight todays mobile users--but they must also integrate smoothly with existing systems and leverage previous generations of IT investment. In this guide, a team of IBMs leading experts show how to meet all these goals. Drawing on extensive experience with pioneering enterprise clients, they cover every facet of planning, building, integrating, and deploying mobile apps in large-scale production environments. Youll find proven advice and best practices for architecture, cloud integration, security, user experience, coding, testing, and much more. Each chapter can stand alone to help you solve specific real-world problems. Together, they help you establish a flow of DevOps activities and lifecycle processes fully optimized for enterprise mobility. Coverage Includes How mobile applications motivate business innovation--and why they present unique challenges for enterprise IT Understanding how the enterprise mobile app lifecycle resembles and differs from conventional development Designing mobile business apps that delight their users Choosing more effective mobile development techniques, languages, and architectural approaches Optimizing linkages between mobile front-ends and enterprise back-end systems Testing for complex, constantly changing device environments Practicing DevOps to accelerate and increase value, from ideation to delivery}
}
@inproceedings{10.1007/978-3-030-89159-6_1,
author = {Tegeler, Tim and Teumert, Sebastian and Sch\"{u}rmann, Jonas and Bainczyk, Alexander and Busch, Daniel and Steffen, Bernhard},
title = {An Introduction to Graphical Modeling of CI/CD Workflows with Rig},
year = {2021},
isbn = {978-3-030-89158-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89159-6_1},
doi = {10.1007/978-3-030-89159-6_1},
abstract = {We present an introduction to the usage of Rig, our Cinco product for the graphical modeling of CI/CD workflows. While CI/CD has become a de facto standard in modern software engineering (e.g. DevOps) and the benefits of its practice are without a doubt, developers are still facing inconvenient solutions. We will briefly outline the basic concept of CI/CD and discuss the challenges involved in maintaining such workflows with current implementations before we explain and illustrate the advantages of our model-driven approach step by step along on the treatment of a typical web application.},
booktitle = {Leveraging Applications of Formal Methods, Verification and Validation: 10th International Symposium on Leveraging Applications of Formal Methods, ISoLA 2021, Rhodes, Greece, October 17–29, 2021, Proceedings},
pages = {3–17},
numpages = {15},
keywords = {Language-driven engineering, DevOps, Graphical modeling, Software engineering, Purpose-Specific Language, Domain-specific tools, Continuous Integration and Deployment},
location = {Rhodes, Greece}
}
@inproceedings{10.1145/3422392.3422501,
author = {Barros, Daniel D. R. and Horita, Fl\'{a}vio and Fantinato, Denis G.},
title = {Data Mining Tool to Discover DevOps Trends from Public Repositories: Predicting Release Candidates with Gthbmining.Rc},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422501},
doi = {10.1145/3422392.3422501},
abstract = {Public repositories have been performing an essential role in bringing software and services to technical communities and general users. Most of the cases, public repositories have a DevOps tool, with a live and historical database behind it, to support delivering and all steps this software or service should adopt before going to production. This paper introduces gthbmining, a data mining set of tools to discover DevOps trends from public repositories, and presents the module gthbmining.rc. Considering the premise of a GitHub public repository, the main contribution here is predicting release candidates, an important label a software release has. The methodology, architecture, components and interfaces are explained, as well as potential users. The results show a reliable and flexible tool, as classifiers metrics and graphics are provided, along with the possibility to add new data mining algorithms in the open source module presented. Related works are also supplied, and a conclusion shows the outcomes gthbmining.rc can provide.},
booktitle = {Proceedings of the 34th Brazilian Symposium on Software Engineering},
pages = {658–663},
numpages = {6},
keywords = {Data Mining, GitHub Mining Tool, Release Candidate, DevOps},
location = {Natal, Brazil},
series = {SBES '20}
}
@book{10.5555/3161271,
author = {Buenosvinos, Carlos and Soronellas, Christian and Akbary, Keyvan},
title = {Domain-Driven Design in PHP},
year = {2017},
isbn = {1787284948},
publisher = {Packt Publishing},
abstract = {Key Features Focuses on practical code rather than theoryFull of real-world examples that you can apply to your own projectsShows how to build PHP apps using DDD principles Book Description Domain-Driven Design (DDD) has arrived in the PHP community, but for all the talk, there is very little real code. Without being in a training session and with no PHP real examples, learning DDD can be challenging. This book changes all that. It details how to implement tactical DDD patterns and gives full examples of topics such as integrating Bounded Contexts with REST, and DDD messaging strategies. In this book, the authors show you, with tons of details and examples, how to properly design Entities, Value Objects, Services, Domain Events, Aggregates, Factories, Repositories, Services, and Application Services with PHP. They show how to apply Hexagonal Architecture within your application whether you use an open source framework or your own. What you will learnCorrectly design all design elements of Domain-Driven Design with PHPLearn all tactical patterns to achieve a fully worked-out Domain-Driven Design Apply hexagonal architecture within your application Integrate bounded contexts in your applicationsUse REST and Messaging approaches About the Author Carlos Buenosvinos is a PHP Extreme Programmer with more than 15 years of experience developing web applications and more than 10 years experience as a Tech Lead and CTO leading teams of between 20 and 100 people. He is a Certified ScrumMaster (CSM) and has coached and trained close to two dozen different companies in Agile practices, both as an employee and as a consultant. On the technical side, he is a Zend PHP Engineer, a Zend Framework Engineer, and MySQL certified. He is also a board member of the PHP Barcelona User Group. He has worked with e-commerce (Atrapalo and eBay), payment processing (Vendo), classifieds (Emagister), and B2B recruiting tools (XING). He is interested in JavaScript, DevOps, and Scala. He likes developing for mobile, Raspberry Pi, and games. Christian Soronellas is a passionate Software Developer, Software Journeyman, and Craftsman Apprentice. He's an Extreme Programmer soul with more than 10 years of experience in web development. He's also a Zend PHP 5.3 Certified Engineer, a Zend Framework Certified Engineer, and a SensioLabs Certified Symfony Developer. He has worked as a freelancer, as well as at Privalia, Emagister, Atrapalo, and Enalquiler as a Software Architect. Keyvan Akbary is a polyglot Software Developer who loves Software fundamentals, the Craftsmanship movement, Extreme Programming, SOLID principles, Clean Code, Design Patterns, and Testing. He's also a sporadic Functional Programmer. He understands technology as a medium for providing value. He has worked on countless projects as a freelancer, on video streaming (Youzee), and on an online marketplace (MyBuilder) - all in addition to founding a crowdfunding company (Funddy). Currently, Keyvan is working in FinTech as a Lead Developer at Transfer Wise London.}
}
@inproceedings{10.1145/3382494.3410679,
author = {Lie, Martin Forsberg and S\'{a}nchez-Gord\'{o}n, Mary and Colomo-Palacios, Ricardo},
title = {DevOps in an ISO 13485 Regulated Environment: A Multivocal Literature Review},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410679},
doi = {10.1145/3382494.3410679},
abstract = {Background: Medical device development projects must follow proper directives and regulations to be able to market and sell the end-product in their respective territories. The regulations describe requirements that seem to be opposite to efficient software development and short time-to-market. As agile approaches, like DevOps, are becoming more and more popular in software industry, a discrepancy between these modern methods and traditional regulated development has been reported. Although examples of successful adoption in this context exist, the research is sparse. Aims: The objective of this study is twofold: to review the current state of DevOps adoption in regulated medical device environment; and to propose a checklist based on that review for introducing DevOps in that context. Method: A multivocal literature review is performed and evidence is synthesized from sources published between 2015 to March of 2020 to capture the opinions of experts and community in this field. Results: Our findings reveal that adoption of DevOps in a regulated medical device environment such as ISO 13485 has its challenges, but potential benefits may outweigh those in areas such as regulatory, compliance, security, organizational and technical. Conclusion: DevOps for regulated medical device environments is a highly appealing approach as compared to traditional methods and could be particularly suited for regulated medical development. However, an organization must properly anchor a transition to DevOps in top-level management and be supportive in the initial phase utilizing professional coaching and space for iterative learning; as such an initiative is a complex organizational and technical task.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {9},
numpages = {11},
keywords = {ISO 13485, Medical device software development, Multivocal Literature Review, DevOps},
location = {Bari, Italy},
series = {ESEM '20}
}
@book{10.5555/3158955,
author = {Gilchrist, Alasdair},
title = {A Concise Guide to SSL/TLS for DevOps: 2nd Edition},
year = {2017},
isbn = {1521278628},
publisher = {Independently published},
abstract = {This book, 'A Concise Guide to SSL/TLS for DevOps' is an introduction to SSL &amp; TLS in application and operational environments and as such is a more technical in depth study than is typically the case in the Executive and Management series. This book aims to cover the theory and practice of SSL in working operational situations. Consequently, although no prior knowledge of authentication and encryption methods is required, a good deal of this text will involve certificate and encryption theory, OpenSSL installation and configuration, SSL vulnerabilities and best practices in SSL certificate management.}
}
@inproceedings{10.5555/3291291.3291317,
author = {Rivera, Luis F. and Villegas, Norha M. and Tamura, Gabriel and Jim\'{e}nez, Miguel and M\"{u}ller, Hausi A.},
title = {UML-Driven Automated Software Deployment},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software companies face the challenge of ensuring customer satisfaction through the continuous delivery of functionalities and rapid response to quality issues. However, achieving frequent software delivery is not a trivial task. It requires agile---and continuous---design, development and deployment of existing and new software features. Over time, managing these systems becomes increasingly complex. This complexity stems, in part, from the deployment pipelines and the myriad possible configurations of the software components. Furthermore, software deployment is a time-consuming and error-prone process, which, even when automated, can lead to configuration errors and cost overruns. In this paper, we address deployment challenges that developers face during continuous delivery and DevOps. Our proposal consists of Urano, a mechanism for automating the deployment process, which uses UML, an interoperable and de facto modeling standard, as a means of specifying a software architecture and its associated deployment. Our approach is based on the model-driven architecture principles to generate executable deployment specifications from user-defined UML deployment diagrams. We extend this kind of diagrams by defining and applying a UML profile that captures the semantics and requirements of the installation, configuration, and update of software components. Thus, enabling more expressive deployment specifications and their automatic realization. To evaluate Urano, we conducted three case studies that demonstrate its potential to effectively automate software deployment processes in industry.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {257–268},
numpages = {12},
keywords = {model-driven engineering, continuous delivery, DevOps, model-driven architecture, UML, deployment},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}
@inbook{10.1145/3487075.3487116,
author = {Liu, Li and Xie, Dongmei and Cheng, YunChang and Li, Gongliang},
title = {Architecture Scheme of DevOps for Cross Network and Multiple Environment Collaboration},
year = {2021},
isbn = {9781450389853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487075.3487116},
abstract = {In the process of traditional enterprises exploring the middle platform architecture, DevOps is the cornerstone of its digital platform's long-term iterative construction and sustainable operation and maintenance. Aiming at the problems of physical isolation of multiple environments and cross regional collaboration of R&amp;D teams faced by high security applications, based on the systematic analysis of DevOps concept, support tools and adoption situation, and based on the DevOps standard, this paper designs a DevOps architecture scheme for internal and external collaboration within cross-network multiple environments.},
booktitle = {The 5th International Conference on Computer Science and Application Engineering},
articleno = {41},
numpages = {5}
}
@inproceedings{10.1007/978-3-030-91452-3_20,
author = {Toivakka, Henrik and Granlund, Tuomas and Poranen, Timo and Zhang, Zheying},
title = {Towards RegOps: A DevOps Pipeline for Medical Device Software},
year = {2021},
isbn = {978-3-030-91451-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91452-3_20},
doi = {10.1007/978-3-030-91452-3_20},
abstract = {The manufacture of medical devices is a strictly regulated domain in the European Union. Traditionally, medical software compliance activities have been considered manual, document-centric, and burdensome. At the same time, over the last decade, software companies have maintained competitiveness and improved by relying on essential practices of DevOps, such as process automation and delivery pipelines. However, applying the same principles in medical software can be challenging due to regulatory requirements. In this paper, we utilize a systematic approach to align the essential medical device software regulatory requirements from the standards IEC 62304 and IEC 82304-1 and integrate them into the software delivery pipeline, which is the main contribution of our work. The outcome supports practitioners to establish more efficient software delivery models while maintaining compliance with the medical device standards.},
booktitle = {Product-Focused Software Process Improvement: 22nd International Conference, PROFES 2021, Turin, Italy, November 26, 2021, Proceedings},
pages = {290–306},
numpages = {17},
keywords = {DevOps, Regulatory compliance, RegOps, Medical device software, Medical device standards},
location = {Turin, Italy}
}
@article{10.4018/IJRCM.2018100105,
author = {Subramanian, Aishwarya and Krishnamachariar, Priyadarsini Kannan and Gupta, Manish and Sharman, Raj},
title = {Auditing an Agile Development Operations Ecosystem},
year = {2018},
issue_date = {October 2018},
publisher = {IGI Global},
address = {USA},
volume = {7},
number = {4},
issn = {2160-9624},
url = {https://doi.org/10.4018/IJRCM.2018100105},
doi = {10.4018/IJRCM.2018100105},
abstract = {In an enterprise software development, DevOps is a practice of integrating development and operations to deliver cost-efficient, improved quality solutions to the customer by automating the existing processes to achieve "continuous delivery." In the current dynamic IT Ecosystem where there is a rising need to prove a competitive edge to maximize profitability, it is pivotal to drive business value with profound emphasis on quality. Agile enables us to take calculated risks during development whereas its affinity to adopting DevOps will promote continuous delivery with reduced friction to improve business efficiency. As this approach requires a change in people, process, technology, culture, usage of right tools and techniques, the early involvement of IT Auditors during the process of transformation could aid to build effective Risk Management strategies to handle organizational challenges. This article aims to present a risk-based audit approach to effectively use audit tools and techniques in an Agile-DevOps transformation environment to achieve maximum business value.},
journal = {Int. J. Risk Conting. Manag.},
month = {oct},
pages = {90–110},
numpages = {21},
keywords = {Software Development, DevOps, Risk Management, Project Management, Agile, IT Audit}
}
@inproceedings{10.1109/ICSSP.2019.00033,
author = {Kruchten, Philippe},
title = {The End of Agile as We Know It},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSSP.2019.00033},
doi = {10.1109/ICSSP.2019.00033},
abstract = {It's been 20 years or so, but the end is in sight. We have successfully placed the adjective 'agile' in front of about every important noun in our software development / IT world: agile design, agile testing, agile management, agile database, agile architecture, agile user-interaction.... Agile has won the war. "What is next?" is the question I've been asked again and again. What is the future of software engineering? The next best thing? Is it DevOps, cloud-something, micro-services, AI? The adjective agile has lost some of its weight and novelty, only a few laggards are still asking "what is it?"It is time to reflect on the fundamental aspects of agility: what does it really means, what are the fundamental principles behind it, that made its successes. The agile movement has had some tremendous impact in the way we work, putting the human being and human interaction more central in these processes, by using extensively iterations, direct interactions, and feedback loops. But at the same time, some aspects of agile have become dogmatic, fossilized, and the agile movement has not been always very agile in its application to itself. These dogmatic aspects have slowed the expansion of its own principles to some of the more complex or much larger software development endeavours.Now, the increasing need for speed, the availability of opensource software repositories, the shifts in technology, such as the cloud, the emergence of software ecosystems are creating new needs in terms of process and project management, that can exploit the fundamental principles of agile, beyond the dogma of this or that method, this or that practice. As the amount of software in use is growing and will outgrow the capacity of our industry to maintain and evolve it, the industry faces a massive amount of technical debt, which we do not know well how to mitigate or repay. Agile has been very valuable, but once its lessons are fully integrated in the way we work we have to look beyond and stop repeating it like a mantra. Agile is dead. Long live agility.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {104},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICSSP '19}
}
@inproceedings{10.1145/3098954.3105819,
author = {Yasar, Hasan},
title = {Implementing Secure DevOps Assessment for Highly Regulated Environments},
year = {2017},
isbn = {9781450352574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3098954.3105819},
doi = {10.1145/3098954.3105819},
abstract = {Secure DevOps has become a standard option for entities seeking to streamline and increase comprehensive participation by all stakeholders in their secure Security Development Lifecycle (SDLC)[1]. In most case in industry, academia, and government, applying DevOps is a straight forward process. There is a subset of entities in these three sectors where applying Secure DevOps is challenging. These are entities that are highly regulated (HRE) as mandated by policies for various reasons, the most often being general security and protection of intellectual property. Even if an entity is highly regulated, its secure SDLC can still benefit from implementing DevOps as long as the implementation does not break any policy[2].},
booktitle = {Proceedings of the 12th International Conference on Availability, Reliability and Security},
articleno = {70},
numpages = {3},
keywords = {DevOps, AppSec, Security Engineering, Highly Regulated Environment, DevSecOps, Secure DevOps assessment, Secure DevOps},
location = {Reggio Calabria, Italy},
series = {ARES '17}
}
@book{10.5555/3006361,
author = {Morris, Kief},
title = {Infrastructure as Code: Managing Servers in the Cloud},
year = {2016},
isbn = {1491924357},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Virtualization, cloud, containers, server automation, and software-defined networking are meant to simplify IT operations. But many organizations adopting these technologies have found that it only leads to a faster-growing sprawl of unmanageable systems. This is where infrastructure as code can help. With this practical guide, author Kief Morris of Thought Works shows you how to effectively use principles, practices, and patterns pioneered through the DevOps movement to manage cloud age infrastructure. Ideal for system administrators, infrastructure engineers, team leads, and architects, this book demonstrates various tools, techniques, and patterns you can use to implement infrastructure as code. In three parts, youll learn about the platforms and tooling involved in creating and configuring infrastructure elements, patterns for using these tools, and practices for making infrastructure as code work in your environment. Examine the pitfalls that organizations fall into when adopting the new generation of infrastructure technologies Understand the capabilities and service models of dynamic infrastructure platforms Learn about tools that provide, provision, and configure core infrastructure resources Explore services and tools for managing a dynamic infrastructureLearn specific patterns and practices for provisioning servers, building server templates, and updating running servers}
}
@article{10.1147/JRD.2016.2517498,
author = {Oliveira, F. and Eilam, T. and Nagpurkar, P. and Isci, C. and Kalantar, M. and Segmuller, W. and Snible, E.},
title = {Delivering Software with Agility and Quality in a Cloud Environment},
year = {2016},
issue_date = {March/May 2016},
publisher = {IBM Corp.},
address = {USA},
volume = {60},
number = {2–3},
issn = {0018-8646},
url = {https://doi.org/10.1147/JRD.2016.2517498},
doi = {10.1147/JRD.2016.2517498},
abstract = {Cloud computing and the DevOps movement are two pillars that facilitate software delivery with extreme agility. "Born on the cloud" companies, such as Netflix®, have demonstrated rapid growth to their business and continuous improvement to the service they provide, by reportedly applying DevOps principles. In this paper, we claim that to fulfill the vision of fast software delivery, without compromising the quality of the provided services, we need a new approach to detecting problems, including problems that may have occurred during the continuous deployment cycle. A native DevOps-centric approach to problem resolution puts the focus on a wider range of possible error sources (including code commits), makes use of DevOps metadata to clearly define the source of the problem, and leads to a quick problem resolution. We propose such a continuous quality assurance approach, and we demonstrate it by preliminary experiments in our public Container Cloud environment and in a private OpenStack® cloud environment.},
journal = {IBM J. Res. Dev.},
month = {mar},
pages = {10:1–10:11},
numpages = {11}
}
@inproceedings{10.1145/3423423.3423474,
author = {Gonnin, Thibaut and Dechavanne, Frank and Rocher, G\'{e}rald and Lavirotte, St\'{e}phane and Tigli, Jean-Yves and Capocchi, Laurent and Santucci, Jean-Fran\c{c}ois},
title = {Actuation Conflict Management Enabler for DevOps in IoT},
year = {2020},
isbn = {9781450388207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3423423.3423474},
doi = {10.1145/3423423.3423474},
abstract = {DevOps methodology is well known in the field of classical software development to improve the software quality and the frequency of the deliveries. However, DevOps has not yet been popularized in the field of IoT. The reasons of that are new challenges that require new enablers in the DevOps tools ecosystem. The European ENACT project supported under the H2020 programme aims to respond to these challenges by providing new enablers to apply DevOps methodology for IoT application[2]. We present, here, one of these enablers called Action Conflict Management Enabler (ACM enabler) which aims at anticipating and resolving at Devs Time all conflicts[1] and dysfunctions that might result from mismanagement of the IoT system actuators.},
booktitle = {10th International Conference on the Internet of Things Companion},
articleno = {18},
numpages = {4},
keywords = {Actuation Conflict, Internet of things, DevOps},
location = {Malm\"{o}, Sweden},
series = {IoT '20 Companion}
}
@book{10.5555/3153651,
author = {Whitman, Michael E. and Mattord, Herbert J.},
title = {Principles of Information Security},
year = {2017},
isbn = {1337102067},
publisher = {Course Technology Press},
address = {Boston, MA, USA},
edition = {6th},
abstract = {Master the latest technology and developments from the field with the book specifically oriented to the needs of information systems students like you -- PRINCIPLES OF INFORMATION SECURITY, 6E. Taking a managerial approach, this bestseller emphasizes all aspects of information security, rather than just a technical control perspective. You receive a broad overview of the entire field of information security and related elements with the detail to ensure understanding. You review terms used in the field and a history of the discipline as you learn how to manage an information security program. Current and relevant, this edition highlights the latest practices with fresh examples that explore the impact of emerging technologies, such as the Internet of Things, Cloud Computing, and DevOps. Updates address technical security controls, emerging legislative issues, digital forensics, and ethical issues in IS security, making this the ideal IS resource for business decision makers.}
}
@book{10.5555/2339424,
author = {Ambler, Scott W. and Lines, Mark},
title = {Disciplined Agile Delivery: A Practitioner's Guide to Agile Software Delivery in the Enterprise},
year = {2012},
isbn = {0132810131},
publisher = {IBM Press},
edition = {1st},
abstract = {Master IBMs Breakthrough DAD Process Framework for Succeeding with Agile in Large, Complex, Mission-Critical IT Projects It is widely recognized that moving from traditional to agile approaches to build software solutions is a critical source of competitive advantage. Mainstream agile approaches that are indeed suitable for small projects require significant tailoring for larger, complex enterprise projects. In Disciplined Agile Delivery, Scott W. Ambler and Mark Lines introduce IBMs breakthrough Disciplined Agile Delivery (DAD) process framework, which describes how to do this tailoring. DAD applies a more disciplined approach to agile development by acknowledging and dealing with the realities and complexities of a portfolio of interdependent program initiatives. Ambler and Lines show how to extend Scrum with supplementary agile and lean strategies from Agile Modeling (AM), Extreme Programming (XP), Kanban, Unified Process (UP), and other proven methods to provide a hybrid approach that is adaptable to your organizations unique needs. They candidly describe what practices work best, why they work, what the trade-offs are, and when to consider alternatives, all within the context of your situation. Disciplined Agile Delivery addresses agile practices across the entire lifecycle, from requirements, architecture, and development to delivery and governance. The authors show how these best-practice techniques fit together in an end-to-end process for successfully delivering large, complex systems--from project initiation through delivery. Coverage includes Scaling agile for mission-critical enterprise endeavorsAvoiding mistakes that drive poorly run agile projects to chaosEffectively initiating an agile projectTransitioning as an individual to agileIncrementally building consumable solutionsDeploying agile solutions into complex production environmentsLeveraging DevOps, architecture, and other enterprise disciplinesAdapting your governance strategy for agile projects Based on facts, research, and extensive experience, this book will be an indispensable resource for every enterprise software leader and practitioner--whether theyre seeking to optimize their existing agile/Scrum process or improve the agility of an iterative process.}
}
@inproceedings{10.1145/3329379,
author = {Cruz-Filipe, Lu\'{\i}s and Di Nitto, Elisabetta and Mauro, Jacopo},
title = {Session Details: Theme: Distributed Systems: MiDOS - Microservices, DevOps, and Service-Oriented Architecture Track},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3329379},
doi = {10.1145/3329379},
abstract = {Service-oriented architectures have changed our vision of the Web, bringing a paradigmatic shift in the methodologies when designing and implementing distributed systems. Originally, the Web was mainly seen as a means of presenting information to a wide spectrum of people, but service-oriented programming triggered a radical transformation of the Web towards a computational fabric where loosely coupled services interact, can be discovered and then invoked. More recently, the microservices architectural style has been proposed, where applications are developed as a collection of fine-grained services running as independent processes. Distributed applications can then be constructed from independently deployable services taking advantage of the properties of the microservice architecture (e.g., flexibility, maintainability, reusability, compositionality, and scalability) as well as the elasticity of cloud infrastructure. From the practical point of view, the deployment and maintenance of (micro)services architectures are performed using DevOps, i.e., a collection of practices linking software development (Dev) with software operations (Ops). DevOps strongly advocates for automation and monitoring at all steps of software construction, from integration, testing, releasing to deployment and infrastructure management. By using the DevOps methodology, it is possible to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
location = {Limassol, Cyprus},
series = {SAC '19}
}
@inproceedings{10.5555/3291291.3291344,
author = {Kontogiannis, Konstantinos and Brealey, Chris and Giammaria, Alberto and Countryman, Brian and Grigoriou, Marios and Jimenez, Miguel and Fokaefs, Marios and Kassam, Faryaaz and Bordeleau, Francis},
title = {2nd Workshop on DevOps and Software Analytics for Continuous Engineering and Improvement},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {The workshop participants focused and discussed the following areas a) techniques, tools, and schemas to mine software repositories including DevOps environments as well as techniques for denoting information extracted from these repositories. Such information includes not only source code but also deployment scripts, configuration files, build specifications, bug reports, version histories, developers comments and other notes; b) techniques to reconcile software system related data, obtained from such different and diverse DevOps sources (e.g. version control systems, bug reporting systems, collaboration tools and testing frameworks); c) static and dynamic software analysis techniques in order to identify and model direct and indirect dependencies in complex systems, with emphasis on micro-services based systems; and d) software analytics techniques in order to assess deployment risks in order to support continuous maintenance and deployment by providing insights on deploy or no-deploy decision making choices. The workshop topics are related to the IBM DevOps Analytics, IBM DevOps Insights, and IBM DevOps Continuous Delivery (Open Toolchain) frameworks.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {369–370},
numpages = {2},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}
author = {Roche, James},
title = {Adopting DevOps Practices in Quality Assurance: Merging the Art and Science of Software Development},
year = {2013},
issue_date = {September 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {9},
issn = {1542-7730},
url = {https://doi.org/10.1145/2538031.2540984},
doi = {10.1145/2538031.2540984},
abstract = {Software life-cycle management was, for a very long time, a controlled exercise. The duration of product design, development, and support was predictable enough that companies and their employees scheduled their finances, vacations, surgeries, and mergers around product releases. When developers were busy, QA (quality assurance) had it easy. As the coding portion of a release cycle came to a close, QA took over while support ramped up. Then when the product released, the development staff exhaled, rested, and started the loop again while the support staff transitioned to busily supporting the new product.},
journal = {Queue},
month = {sep},
pages = {20–27},
numpages = {8}
}
@inproceedings{10.1145/2693182.2693187,
author = {Gottesheim, Wolfgang},
title = {Challenges, Benefits and Best Practices of Performance Focused DevOps},
year = {2015},
isbn = {9781450333375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2693182.2693187},
doi = {10.1145/2693182.2693187},
abstract = {Did you know that just a handful of root causes are responsible for the majority of application issues like crashes, slow performance or incorrect application behavior? Non-optimized database access, deployment mistakes, memory leaks, or inefficient coding are just some examples. Companies that think Continuous Delivery and DevOps will solve all their problems typically fail as they just run into these problems faster. In this session we take a closer look at the most common problems, how to detect them and how to incorporate performance into your DevOps culture by automatically detecting these top problems.},
booktitle = {Proceedings of the 4th International Workshop on Large-Scale Testing},
pages = {3},
numpages = {1},
keywords = {devops, continuous delivery, testing, performance},
location = {Austin, Texas, USA},
series = {LT '15}
}
@article{10.1145/3331138,
author = {Wiedemann, Anna and Forsgren, Nicole and Wiesche, Manuel and Gewald, Heiko and Krcmar, Helmut},
title = {Research for Practice: The DevOps Phenomenon},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {62},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/3331138},
doi = {10.1145/3331138},
abstract = {An executive crash course.},
journal = {Commun. ACM},
month = {jul},
pages = {44–49},
numpages = {6}
}
@inproceedings{10.1145/3167486.3167556,
author = {Abdelkebir, Sahid and Maleh, Yassine and Belaissaoui, Mustapha},
title = {An Agile Framework for ITS Management In Organizations: A Case Study Based on DevOps},
year = {2017},
isbn = {9781450353069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167486.3167556},
doi = {10.1145/3167486.3167556},
abstract = {Agility means the capability to swiftly and efficiently respond to internal and environmental organization changes. For IT, it is the ability to provide new services and IT solutions to support the innovative business processes. In the ever-changing business world of today, improving agility is the best way to face future challenges. IT service management is the capacity to collect data, analyze, report and implement agile improvements. Successful IT must be efficient and agile to promote the traditional company transformation to a digital enterprise. The propose of this work is a holistic and practical strategic framework to improve ITSM service management processes with the additions of two drivers Agility management based on DevOps, and an agility Process Maturity Framework (APMF). This research will enable decision-makers to improve and measure agility enhancements and hence compare the agility of Information Systems before and after APMF deploying.},
booktitle = {Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems},
articleno = {67},
numpages = {8},
keywords = {Organization, IT Service Management, Agility, DevOps},
location = {Larache, Morocco},
series = {ICCWCS'17}
}
@inproceedings{10.1145/3239235.3240299,
author = {Luz, Welder Pinheiro and Pinto, Gustavo and Bonif\'{a}cio, Rodrigo},
title = {Building a Collaborative Culture: A Grounded Theory of Well Succeeded Devops Adoption in Practice},
year = {2018},
isbn = {9781450358231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239235.3240299},
doi = {10.1145/3239235.3240299},
abstract = {Background. DevOps is a set of practices and cultural values that aims to reduce the barriers between development and operations teams. Due to its increasing interest and imprecise definitions, existing research works have tried to characterize DevOps---mainly using a set of concepts and related practices.Aims. Nevertheless, little is known about the practitioners practitioners' understanding about successful paths for DevOps adoption. The lack of such understanding might hinder institutions to adopt DevOps practices. Therefore, our goal here is to present a theory about DevOps adoption, highlighting the main related concepts that contribute to its adoption in industry.Method. Our work builds upon Classic Grounded Theory. We interviewed practitioners that contributed to DevOps adoption in 15 companies from different domains and across 5 countries. We empirically evaluate our model through a case study, whose goal is to increase the maturity level of DevOps adoption at the Brazilian Federal Court of Accounts, a Brazilian Government institution.Results. This paper presents a model to improve both the understanding and guidance of DevOps adoption. The model increments the existing view of DevOps by explaining the role and motivation of each category (and their relationships) in the DevOps adoption process. We organize this model in terms of DevOps enabler categories and DevOps outcome categories. We provide evidence that collaboration is the core DevOps concern, contrasting with an existing wisdom that implanting specific tools to automate building, deployment, and infrastructure provisioning and management is enough to achieve DevOps.Conclusions. Altogether, our results contribute to (a) generating an adequate understanding of DevOps, from the perspective of practitioners; and (b) assisting other institutions in the migration path towards DevOps adoption.},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {6},
numpages = {10},
keywords = {software operations, devops, grounded theory, software development},
location = {Oulu, Finland},
series = {ESEM '18}
}
@article{10.1016/j.procs.2020.01.032,
author = {Arulkumar, V. and Lathamanju, R.},
title = {Start to Finish Automation Achieve on Cloud with Build Channel: By DevOps Method},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {165},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2020.01.032},
doi = {10.1016/j.procs.2020.01.032},
journal = {Procedia Comput. Sci.},
month = {jan},
pages = {399–405},
numpages = {7},
keywords = {Automation, DevOps, Cloud}
}
@inproceedings{10.1145/3358505.3358522,
author = {Alonso, Juncal and Stefanidis, Kyriakos and Orue-Echevarria, Leire and Blasi, Lorenzo and Walker, Michael and Escalante, Marisa and L\'{o}pez, Mar\'{\i}a Jos\'{e} and Dutkowski, Simon},
title = {DECIDE: An Extended DevOps Framework for Multi-Cloud Applications},
year = {2019},
isbn = {9781450371650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358505.3358522},
doi = {10.1145/3358505.3358522},
abstract = {DevOps represents a model for application development that enables close collaboration between software developers and IT operations with the objective of implementing continuous integration, continuous delivery and continuous development of software applications. This paper proposes an approach for extending the DevOps philosophy with the objective of supporting the development and operation of multi-cloud native applications deployed over heterogeneous cloud resources. The authors present the extended DECIDE DevOps framework and the supporting tool suite developed in the context of the DECIDE H2020 action},
booktitle = {Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing},
pages = {43–48},
numpages = {6},
keywords = {Multi-cloud, Continuous Design, continuous adaptation, DevOps, Cloud Computing, Continuous pre-deployment, continuous monitoring, deployment optimization},
location = {Oxford, United Kingdom},
series = {ICCBDC 2019}
}
@book{10.5555/3317260,
author = {Atkinson, Brandon and Edwards, Dallas},
title = {Generic Pipelines Using Docker: The DevOps Guide to Building Reusable, Platform Agnostic CI/CD Frameworks},
year = {2018},
isbn = {1484236548},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Create generic pipelines to reduce your overall DevOps workload and allow your team to deliver faster. This book helps you get up to speed on the pros and cons of generic pipeline methodology, and learn to combine shell scripts and Docker to build generic pipelines. In todays world of micro-services and agile practices, DevOps teams need to move as fast as feature teams. This can be extremely challenging if youre creating multiple pipelines per application or tech stack. What if your feature teams could utilize a generic pipeline that could build, test, and deploy any application, regardless of tech stack? What if that pipeline was also cloud and platform agnostic? Too good to be true? Well think again! Generic Pipelines Using Dockerexplores the principles and implementations that allow you to do just that. You will learn from real-world examples and reusable code. After reading this book you will have the knowledge to build generic pipelines that any team can use. What You'll Learn Explore the pros and cons of generic pipeline methodology Combine shell scripts and Docker to build a generic pipeline Implement a pipeline across CI/CD platforms Build a pipeline that lends itself well to both centralized and federated DevOps teams Construct a modular pipeline with components that can be added, removed, or replaced as needed Who This Book Is For Professionals who use DevOps or are part of a DevOps team, and are seeking ways to streamline their pipelines and drive more deployments while using less code}
}
@book{10.5555/2935481,
title = {Leading the Transformation: Applying Agile and DevOps Principles at Scale},
year = {2015},
isbn = {1942788010},
publisher = {IT Revolution Press},
abstract = {Software is becoming more and more important across a broad range of industries, yet most technology executives struggle to deliver software improvements their businesses require.Leading-edge companies like Amazon and Google are applying DevOps and Agile principles to deliver large software projects faster than anyone thought possible. But most executives dont understand how to transform their current legacy systems and processes to scale these principles across their organizations.Leading the Transformation is executive guide, providing a clear framework for improving development and delivery. Instead of the traditional Agile and DevOps approaches that focus on improving the effectiveness of teams, this book targets the coordination of work across teams in large organizationsan improvement that executives are uniquely positioned to lead.}
}
@inproceedings{10.1145/2973839.2973845,
author = {de Fran\c{c}a, Breno B. Nicolau and Jeronimo, Helvio and Travassos, Guilherme Horta},
title = {Characterizing DevOps by Hearing Multiple Voices},
year = {2016},
isbn = {9781450342018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2973839.2973845},
doi = {10.1145/2973839.2973845},
abstract = {Recently, DevOps has emerged as an alternative for software organizations inserted into a dynamic market to handle daily software demands. As claimed, it intends to make the software development and operations teams to work collaboratively. However, it is hard to observe a shared understanding of DevOps, what potentially hinders the discussions in the literature and can confound observations when conducting empirical studies. Therefore, we performed a Multivocal Literature Review aiming at characterizing DevOps in multiple perspectives, including data sources from technical and gray literature. Grounded Theory procedures were used to rigorous analyze the collected data. It allowed us to achieve a grounded definition for DevOps, as well as to identify its recurrent principles, practices, required skills, potential benefits, challenges and what motivates the organizations to adopt it. Finally, we understand the DevOps movement has identified relevant issues in the state-of-the-practice. However, we advocate for the scientific investigations concerning the potential benefits and drawbacks as a consequence of adopting the suggested principles and practices.},
booktitle = {Proceedings of the 30th Brazilian Symposium on Software Engineering},
pages = {53–62},
numpages = {10},
keywords = {Grounded Theory, Software Development and Operations, DevOps, Multivocal Literature Review},
location = {Maring\'{a}, Brazil},
series = {SBES '16}
}
@inbook{10.1145/3417990.3420203,
author = {Colantoni, Alessandro and Berardinelli, Luca and Wimmer, Manuel},
title = {DevOpsML: Towards Modeling DevOps Processes and Platforms},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420203},
abstract = {DevOps and Model Driven Engineering (MDE) provide differently skilled IT stakeholders with methodologies and tools for organizing and automating continuous software engineering activities-from development to operations, and using models as key engineering artifacts, respectively. Both DevOps and MDE aim at shortening the development life-cycle, dealing with complexity, and improve software process and product quality.The integration of DevOps and MDE principles and practices in low-code engineering platforms (LCEP) are gaining attention by the research community. However, at the same time, new requirements are upcoming for DevOps and MDE as LCEPs are often used by non-technical users, to deliver fully functional software. This is in particular challenging for current DevOps processes, which are mostly considered on the technological level, and thus, excluding most of the current LCEP users. The systematic use of models and modeling to lowering the learning curve of DevOps processes and platforms seems beneficial to make them also accessible for non-technical users.In this paper, we introduce DevOpsML, a conceptual framework for modeling and combining DevOps processes and platforms. Tools along with their interfaces and capabilities are the building blocks of DevOps platform configurations, which can be mapped to software engineering processes of arbitrary complexity. We show our initial endeavors on DevOpsML and present a research roadmap how to employ the resulting DevOpsML framework for different use cases.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {69},
numpages = {10}
}
@inproceedings{10.1145/3393822.3432340,
author = {Maroukian, Krikor and Gulliver, Stephen R.},
title = {The Link Between Transformational and Servant Leadership in DevOps-Oriented Organizations},
year = {2020},
isbn = {9781450377621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3393822.3432340},
doi = {10.1145/3393822.3432340},
abstract = {DevOps is a set of agile and lean practices and principles in the context of software product development aiming to decrease mean time-to-market and mean time-to-recover-from-failure through a shift in organizational mindset-skillset-toolset. There is literature to suggest that adopting DevOps has been challenging in practice and that a particular leadership style is necessary to lead DevOps adoption. There are studies to suggest that DevOps leadership is mainly related to transformational leadership characteristics. In this research, a mixed methods approach is used. Initially, semi-structured interviews are conducted with 30 EMEA (Europe, Middle-East and Africa) agile and lean practitioners holding more than 10 years of practitioner experience (81%) from the private and public sectors. The contribution also includes an analysis and evaluation of a survey completed by 250 participants of which 93% works in Europe and Middle East and 76% has held previous leadership positions. By looking to recent literature we identified agile, lean and DevOps practices and principles. In addition, we identify benefits and inhibiting factors to DevOps adoption and its leadership. Our results suggest that deep rooted organizational culture and lack of DevOps definition clarity are usually considered impediments to DevOps adoption followed by poor communication and collaboration. Our results also show that certain DevOps adoption leadership characteristics are relevant to transformational leadership and servant leadership. The research results also indicate that the DevOps adoption leadership role is linked to certain metrics.},
booktitle = {Proceedings of the 2020 European Symposium on Software Engineering},
pages = {21–29},
numpages = {9},
keywords = {leadership, DevOps adoption, metrics, practices, principles},
location = {Rome, Italy},
series = {ESSE 2020}
}
@book{10.5555/3235131,
author = {Vadapalli, Sricharan},
title = {DevOps: Continuous Delivery, Integration, and Deployment with DevOps Dive into the Core DevOps Strategies},
year = {2018},
isbn = {1789132991},
publisher = {Packt Publishing},
abstract = {Explore the high-in demand core DevOps strategies with powerful DevOps tools such as Ansible, Jenkins, and ChefKey FeaturesGet acquainted with methodologies and tools of the DevOps frameworkPerform continuous integration, delivery, deployment, and monitoring using DevOps toolsExplore popular tools such as Git, Jenkins, Maven, Gerrit, Nexus, Selenium, and so on Embedded with assessments that will help you revise the concepts you have learned in this book Book Description DevOps is the most widely used software engineering culture and practice that aim sat software development and operation. Continuous integration is a cornerstone technique of DevOps that merges software code updates from developers into a shared central mainline. This book takes a practical approach and covers the tools and strategies of DevOps. It starts with familiarizing you with DevOps framework and then shows how toper form continuous delivery, integration, and deployment with DevOps. You will explore DevOps process maturity frameworks and progression models with checklist templates for each phase of DevOps. You will also be familiar with agile terminology, methodology, and the benefits accrued by an organization by adopting it. You will also get acquainted with popular tools such as Git, Jenkins, Maven, Gerrit, Nexus, Selenium, and so on. You will learn configuration, automation, and the implementation of infrastructure automation (Infrastructure as Code) with tools such as Chef and Ansible. This book is ideal for engineers, architects, and developers, who wish to learn the core strategies of DevOps. This book is embedded with useful assessments that will help you revise the concepts you have learned in this book. This book is repurposed for this specific learning experience from material from Packt's Hands-on DevOps by Sricharan Vadapalli. What you will learnGet familiar with life cycle models, maturity states, progression and best practices of DevOps frameworks Learn to set up Jenkins and integrate it with GitKnow how to build jobs and perform testing with Jenkins Implement infrastructure automation (Infrastructure as Code) with tools such as Chef and Ansible Understand continuous monitoring process with tools such as Splunk and Nagios Learn how Splunk improves the code quality Who This Book Is ForThis book is for engineers, architects, and developers, who wish to learn the core strategies of DevOps.}
}
@article{10.1002/smr.1957,
author = {Jabbari, Ramtin and bin Ali, Nauman and Petersen, Kai and Tanveer, Binish},
title = {Towards a Benefits Dependency Network for DevOps Based on a Systematic Literature Review},
year = {2018},
issue_date = {November 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {30},
number = {11},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.1957},
doi = {10.1002/smr.1957},
abstract = {DevOps as a new way of thinking for software development and operations has received much attention in the industry, while it has not been thoroughly investigated in academia yet. The objective of this study is to characterize DevOps by exploring its central components in terms of principles, practices and their relations to the principles, challenges of DevOps adoption, and benefits reported in the peer‐reviewed literature. As a key objective, we also aim to realize the relations between DevOps practices and benefits in a systematic manner. A systematic literature review was conducted. Also, we used the concept of benefits dependency network to synthesize the findings, in particular, to specify dependencies between DevOps practices and link the practices to benefits. We found that in many cases, DevOps characteristics, ie, principles, practices, benefits, and challenges, were not sufficiently defined in detail in the peer‐reviewed literature. In addition, only a few empirical studies are available, which can be attributed to the nascency of DevOps research. Also, an initial version of the DevOps benefits dependency network has been derived. The definition of DevOps principles and practices should be emphasized given the novelty of the concept. Further empirical studies are needed to improve the benefits dependency network presented in this study.In this paper, we aim to realize the relations between DevOps practices and benefits in a systematic manner. We used the concept of benefits dependency network to synthesize the findings of the literature, in particular, to specify dependencies between DevOps practices and link the practices to benefits. Only a few empirical studies are available that can be attributed to the nascency of DevOps research. An initial version of the DevOps benefits dependency network has been derived. image},
journal = {J. Softw. Evol. Process},
month = {nov},
numpages = {1},
keywords = {benefits and values, systematic literature review, principles and practices, DevOps, challenges, development and operations}
}
@inbook{10.1145/3377812.3390808,
author = {Pang, Candy and Hindle, Abram and Barbosa, Denilson},
title = {Understanding DevOps Education with Grounded Theory},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3390808},
abstract = {DevOps stands for Development-Operations. It arises from the IT industry as a movement aligning development and operations teams. DevOps is broadly recognized as an IT standard, and there is high demand for DevOps practitioners in industry. Therefore, we studied whether undergraduates acquired adequate DevOps skills to fulfill the demand for DevOps practitioners in industry. We employed Grounded Theory (GT), a social science qualitative research methodology, to study DevOps education from academic and industrial perspectives. In academia, academics were not motivated to learn or adopt DevOps, and we did not find strong evidence of academics teaching DevOps. Academics need incentives to adopt DevOps, in order to stimulate interest in teaching DevOps. In industry, DevOps practitioners lack clearly defined roles and responsibilities, for the DevOps topic is diverse and growing too fast. Therefore, practitioners can only learn DevOps through hands-on working experience. As a result, academic institutions should provide fundamental DevOps education (in culture, procedure, and technology) to prepare students for their future DevOps advancement in industry. Based on our findings, we proposed five groups of future studies to advance DevOps education in academia.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {260–261},
numpages = {2}
}
@inproceedings{10.1145/3377814.3381711,
author = {Pang, Candy and Hindle, Abram and Barbosa, Denilson},
title = {Understanding Devops Education with Grounded Theory},
year = {2020},
isbn = {9781450371247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377814.3381711},
doi = {10.1145/3377814.3381711},
abstract = {DevOps stands for Development-Operations. It arises from the IT industry as a movement aligning development and operations teams. DevOps is broadly recognized as an IT standard, and there is high demand for DevOps practitioners in industry. Since ACM &amp; IEEE suggest that undergraduate computer science curricula "must adequately prepare [students] for the workforce", we studied whether undergraduates acquired adequate DevOps skills to fulfill the demand for DevOps practitioners in industry. We employed Grounded Theory (GT), a social science qualitative research methodology, to study DevOps education from academic and industrial perspectives. In academia, academics were not motivated to learn or adopt DevOps, and we did not find strong evidence of academics teaching DevOps. Academics need incentives to adopt DevOps, in order to stimulate interest in teaching DevOps. In industry, DevOps practitioners lack clearly defined roles and responsibilities, for the DevOps topic is diverse and growing too fast. Therefore, practitioners can only learn DevOps through hands-on working experience. As a result, academic institutions should provide fundamental DevOps education (in culture, procedure, and technology) to prepare students for their future DevOps advancement in industry. Based on our findings, we proposed five groups of future studies to advance DevOps education in academia.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training},
pages = {107–118},
numpages = {12},
keywords = {software engineering, grounded theory, education, continuous delivery, devops, continuous integration},
location = {Seoul, South Korea},
series = {ICSE-SEET '20}
}
@book{10.5555/3307128,
author = {Abdoulaye, Philippe A.},
title = {The DevOps Revolution: Disrupting the Status Quo - From IT Modernization to Digital Competitiveness},
year = {2018},
isbn = {1731123027},
publisher = {Independently published},
abstract = {Forget about those DevOps, Cloud Computing, AI, Big Data scattered implementations that solution vendors urge you to proceed to. They remain poor investments as long as they don't guarantee that your company will survive and succeed in markets disrupted by Google, Amazon, Facebook, Apple (GAFA) as well as Walmart and all the innovative tech startups out there. In this very practical guide, fast, and easy to read, Philippe Abdoulaye, featured several times on Forbes, ZDNet, Inc, cited as a major contributor to the future of the CIO job in 2018, tells all about how to properly and rapidly transform your business including IT around these technologies. Building on the failure and success cases in the increasingly raging digital competition Weight Watchers, Fitbit, Toys R Us, Sears he reveals the secrets, techniques, and tips of the very few companies that have been succeeding. Youll learn: (1) Why Amazons irruption in the toy market, kicked Toys R Us out of business (2) How Weight watchers struggled to survive the disrupted diet market (3) How the GAFAs platform business model is expanding the network economy a standard and changing the way we do business (4) Whats the DevOps culture and how to implement it (5) How DevOps when implemented entirely unlocks platform models competitive advantage (6) Why DevOps features agile and lean practices, continuous delivery, Microservices and containers enable the business benefits of platforms (7) How augmenting DevOps with Design Thinking principles makes it a powerful digital service development platform (8) Actionable DevOps-based Platform Architecture businesses can reuse (9) How WellBeing, Inc., took advantage of the BlueBird platform to disrupt the diet market and put leading and historical firms in troubles. Your company or your career success in the digital economy is your dream, one that you want to share with your staff, clients, and stakeholders. The DevOps Revolution is the complete tool you need to make that dream a reality, ignoring it would be a terrible mistake.}
}
@inproceedings{10.1145/3501774.3501783,
author = {Maroukian, Krikor and R. Gulliver, Stephen},
title = {Synthesis of a Leadership Model for DevOps Adoption},
year = {2021},
isbn = {9781450385060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501774.3501783},
doi = {10.1145/3501774.3501783},
abstract = {The first decade of DevOps-orientation in software-intensive organizational environments is often characterized with an emerging set of skills that support DevOps practice adoption, targeting a cross-functional collaborative culture; with an aim of achieving a shift in mindset, skillset, and toolset. We investigate DevOps adoption constructs to facilitate development of a formative measurement model to support leadership throughout the DevOps transitional journey. The model and its constructs are designed and validated with a multi-method approach. Initially an exploratory study of a survey is conducted with 250 respondents 76% of whom possess leadership roles, 93% work in Europe and Middle East, and two-thirds are practicing as DevOps practitioners. Pertinent model indicators are produced and grouped under constructs based on survey results and validated using PLS-SEM. The formative structural model is presented and validated in three separate focus group sessions, comprising of respectively seven (7), five (5), and seven (7) participants all of whom had held leadership positions; from countries including USA, UK, The Netherlands, UAE, Greece, Georgia, Switzerland. Seventeen (17) focus group participants provided additional responses through a focus group in-session survey, which allowed feedback on specific model constructs. Results indicate that a set of practices, a set of skills, a set of metrics, DevOps adoption planning and the existence of the DevOps adoption leader roles, should be part of organizational aspirations in the definition of leadership in a DevOps transition path.},
booktitle = {2021 2nd European Symposium on Software Engineering},
pages = {58–66},
numpages = {9},
keywords = {Survey, Leadership model, Focus group, PLS-SEM, DevOps},
location = {Larissa, Greece},
series = {ESSE 2021}
}
@book{10.5555/3285289,
author = {Hsu, Tony},
title = {Hands-On Security in DevOps: Ensure Continuous Security, Deployment, and Delivery with DevSecOps},
year = {2018},
isbn = {1788995503},
publisher = {Packt Publishing},
abstract = {Protect your organization's security at all levels by introducing the latest strategies for securing DevOps Key Features Integrate security at each layer of the DevOps pipeline Discover security practices to protect your cloud services by detecting fraud and intrusion Explore solutions to infrastructure security using DevOps principles Book Description DevOps has provided speed and quality benefits with continuous development and deployment methods, but it does not guarantee the security of an entire organization. Hands-On Security in DevOps shows you how to adopt DevOps techniques to continuously improve your organizations security at every level, rather than just focusing on protecting your infrastructure. This guide combines DevOps and security to help you to protect cloud services, and teaches you how to use techniques to integrate security directly in your product. You will learn how to implement security at every layer, such as for the web application, cloud infrastructure, communication, and the delivery pipeline layers. With the help of practical examples, youll explore the core security aspects, such as blocking attacks, fraud detection, cloud forensics, and incident response. In the concluding chapters, you will cover topics on extending DevOps security, such as risk assessment, threat modeling, and continuous security. By the end of this book, you will be well-versed in implementing security in all layers of your organization and be confident in monitoring and blocking attacks throughout your cloud services. What you will learn Understand DevSecOps culture and organization Learn security requirements, management, and metrics Secure your architecture design by looking at threat modeling, coding tools and practices Handle most common security issues and explore black and white-box testing tools and practices Work with security monitoring toolkits and online fraud detection rules Explore GDPR and PII handling case studies to understand the DevSecOps lifecycle Who this book is for Hands-On Security in DevOps is for system administrators, security consultants, and DevOps engineers who want to secure their entire organization. Basic understanding of Cloud computing, automation frameworks, and programming is necessary.}
}
@book{10.5555/3294362,
author = {Vehent, Julien},
title = {Securing DevOps: Security in the Cloud},
year = {2018},
isbn = {1617294136},
publisher = {Manning Publications Co.},
address = {USA},
edition = {1st},
abstract = {Summary Securing DevOps explores how the techniques of DevOps and security should be applied together to make cloud services safer. This introductory book reviews the latest practices used in securing web applications and their infrastructure and teaches you techniques to integrate security directly into your product. You'll also learn the core concepts of DevOps, such as continuous integration, continuous delivery, and infrastructure as a service. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Technology An application running in the cloud can benefit from incredible efficiencies, but they come with unique security threats too. A DevOps team's highest priority is understanding those risks and hardening the system against them. About the Book Securing DevOps teaches you the essential techniques to secure your cloud services. Using compelling case studies, it shows you how to build security into automated testing, continuous delivery, and other core DevOps processes. This experience-rich book is filled with mission-critical strategies to protect web applications against attacks, deter fraud attempts, and make your services safer when operating at scale. You'll also learn to identify, assess, and secure the unique vulnerabilities posed by cloud deployments and automation tools commonly used in modern infrastructures. What's inside An approach to continuous security Implementing test-driven security in DevOps Security techniques for cloud services Watching for fraud and responding to incidents Security testing and risk assessment About the Reader Readers should be comfortable with Linux and standard DevOps practices like CI, CD, and unit testing. About the Author Julien Vehent is a security architect and DevOps advocate. He leads the Firefox Operations Security team at Mozilla, and is responsible for the security of Firefox's high-traffic cloud services and public websites.}
}
@inbook{10.1109/ICSE-Companion52605.2021.00124,
author = {de Aguiar Monteiro, Luciano},
title = {A Proposal to Systematize Introducing DevOps into the Software Development Process},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00124},
abstract = {The software development industry has been evolving with new development standards and service delivery models. Agile methodologies have reached their completion with DevOps, thereby increasing the quality of the software and creating greater speed in delivery. However, a gap regarding the formalization of its adoption and implementation doubts became relevant. My hypothesis is that, by systematizing the introduction of DevOps into the software development process and defining the function of the members of the DevOps team members, may well make it quicker to implement this process, thus reducing conflicts between the teams. As part of the investigation of this hypothesis, the result of the research will be applied in practical development environments i.e. in a Technology Agency of the State of the Brazilian Government and also at the Brazilian Company Neurotech in order to evaluate its effectiveness from metrics appropriate for DevOps environments.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {269–271},
numpages = {3}
}
@article{10.1109/MCOM.2017.1500803CM,
author = {John, Wolfgang and Marchetto, Guido and Nemeth, Felician and Skoldstrom, Pontus and Steinert, Rebecca and Meirosu, Catalin and Papafili, Ioanna and Pentikousis, Kostas},
title = {Service Provider DevOps},
year = {2017},
issue_date = {January 2017},
publisher = {IEEE Press},
volume = {55},
number = {1},
issn = {0163-6804},
url = {https://doi.org/10.1109/MCOM.2017.1500803CM},
doi = {10.1109/MCOM.2017.1500803CM},
abstract = {Although there is consensus that software defined networking and network functions virtualization overhaul service provisioning and deployment, the community still lacks a definite answer on how carrier-grade operations praxis needs to evolve. This article presents what lies beyond the first evolutionary steps in network management, identifies the challenges in service verification, observability, and troubleshooting, and explains how to address them using our Service Provider DevOps (SP-DevOps) framework. We compendiously cover the entire process from design goals to tool realization and employ an elastic version of an industry-standard use case to show how on-the-fly verification, software-defined monitoring, and automated troubleshooting of services reduce the cost of fault management actions. We assess SP-DevOps with respect to key attributes of software-defined telecommunication infrastructures both qualitatively and quantitatively, and demonstrate that SP-DevOps paves the way toward carrier-grade operations and management in the network virtualization era.},
journal = {Comm. Mag.},
month = {jan},
pages = {204–211},
numpages = {8}
}
@inbook{10.1109/MODELS-C.2019.00094,
author = {Meyers, Bart and Gadeyne, Klaas and Oakes, Bentley James and Bernaerts, Matthias and Vangheluwe, Hans and Denil, Joachim},
title = {A Model-Driven Engineering Framework to Support the Functional Safety Process},
year = {2019},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00094},
abstract = {The design of safety-related systems traditionally has long and costly development cycles due to the highly manual safety engineering process, which is guided by industry standards. In this paper, we present a modelling framework that supports DevOps principles of continuous testing and fast development iterations for the design of safety-critical systems. We show how modelling can help introducing DevOps in the context of functional safety analysis, and we also report how DevOps was used during the development of the framework.},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {619–623},
numpages = {5}
}
@book{10.5555/3153111,
author = {Senthilvel, Ganesan and Khan, Ovais Mehboob Ahmed and Qureshi, Habib Ahmed},
title = {Enterprise Application Architecture with .NET Core},
year = {2017},
isbn = {1786468883},
publisher = {Packt Publishing},
abstract = {Architect and design highly scalable, robust, clean and highly performant applications in .NET CoreAbout This BookIncorporate architectural soft-skills such as DevOps and Agile methodologies to enhance program-level objectives Gain knowledge of architectural approaches on the likes of SOA architecture and microservices to provide traceability and rationale for architectural decisions Explore a variety of practical use cases and code examples to implement the tools and techniques described in the book Who This Book Is ForThis book is for experienced .NET developers who are aspiring to become architects of enterprise-grade applications, as well as software architects who would like to leverage .NET to create effective blueprints of applications. What You Will LearnGrasp the important aspects and best practices of application lifecycle management Leverage the popular ALM tools, application insights, and their usage to monitor performance, testability, and optimization tools in an enterprise Explore various authentication models such as social media-based authentication, 2FA and OpenID Connect, learn authorization techniques Explore Azure with various solution approaches for Microservices and Serverless architecture along with Docker containers Gain knowledge about the recent market trends and practices and how they can be achieved with .NET Core and Microsoft tools and technologies In Detail If you want to design and develop enterprise applications using .NET Core as the development framework and learn about industry-wide best practices and guidelines, then this book is for you. The book starts with a brief introduction to enterprise architecture, which will help you to understand what enterprise architecture is and what the key components are. It will then teach you about the types of patterns and the principles of software development, and explain the various aspects of distributed computing to keep your applications effective and scalable. These chapters act as a catalyst to start the practical implementation, and design and develop applications using different architectural approaches, such as layered architecture, service oriented architecture, microservices and cloud-specific solutions. Gradually, you will learn about the different approaches and models of the Security framework and explore various authentication models and authorization techniques, such as social media-based authentication and safe storage using app secrets. By the end of the book, you will get to know the concepts and usage of the emerging fields, such as DevOps, BigData, architectural practices, and Artificial Intelligence. Style and approach Filled with examples and use cases, this guide takes a no-nonsense approach to show you the best tools and techniques required to become a successful software architect.}
}
@inproceedings{10.1109/SCC.2015.87,
author = {McCarthy, Matthew A. and Herger, Lorraine M. and Khan, Shakil M. and Belgodere, Brian M.},
title = {Composable DevOps: Automated Ontology Based DevOps Maturity Analysis},
year = {2015},
isbn = {9781467372817},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SCC.2015.87},
doi = {10.1109/SCC.2015.87},
abstract = {In this era of the emerging digitized, mobilized, and cloudified enterprises, the concept of the "compos able business" is the most critical piece which ties everything together. The digital enterprise is here, and its prime characteristic is that is essentially detaches and segregates existing businesses and reassembles them according to market demands. Every industry, from transportation to eyewear is up for disruption, and developers are in the forefront of this movement. In turn, these developers are under intense pressure to accelerate time to market. The compos able enterprise approach requires a reconsideration of traditional models of the entire IT organization. These organization and their processes need to be broken up into components that follow certain key design principles such as The Minimal Functions with least Dependencies, portability, Shared Knowledge, Predictable Contracts and Maximized Human Value. The last three bullet points encapsulate the very definition of DevOps [3]. The concept of better integration between Development and Operations is a valuable objective. The goal is to foster measurable incremental cultural change to derive most overall value out of the union of people, process and technology. But the cultural issues, reward models, and risk allocation create obvious barriers in attaining those goals. The common industry belief is to use the compos able enterprise framework to build a platform using the right tools and you will have attained DevOps nirvana. In this paper we will explore valuable lessons learned from our mistakes in tool centric adoption of IT Infrastructure Library (ITIL) [8]. We will also show how we applied those lessons to develop a lightweight compos able/contextual DevOps framework that learns and measure itself to avoid those cultural pitfalls.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Services Computing},
pages = {600–607},
numpages = {8},
keywords = {maturity, itil, deontic, semantic, ontology, devops},
series = {SCC '15}
}
@inproceedings{10.1145/3468264.3468575,
author = {Sokolowski, Daniel and Weisenburger, Pascal and Salvaneschi, Guido},
title = {Automating Serverless Deployments for DevOps Organizations},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468575},
doi = {10.1145/3468264.3468575},
abstract = {DevOps unifies software development and operations in cross-functional teams to improve software delivery and operations (SDO) performance. Ideally, cross-functional DevOps teams independently deploy their services, but the correct operation of a service often demands other services, requiring coordination to ensure the correct deployment order. This issue is currently solved either with a central deployment or manual out-of-band communication across teams, e.g., via phone, chat, or email. Unfortunately, both contradict the independence of teams, hindering SDO performance—the reason why DevOps is adopted in the first place. In this work, we conduct a study on 73 IT professionals, showing that, in practice, they resort to manual coordination for correct deployments even if they expect better SDO performance with fully automated approaches. To address this issue, we propose µs ([mju:z] “muse”), a novel IaC system automating deployment coordination in a fully decentralized fashion, still retaining compatibility with DevOps practice—in contrast to today’s solutions. We implement µs, demonstrate that it effectively enables automated coordination, introduces negligible definition overhead, has no performance overhead, and is broadly applicable, as shown by the migration of 64 third-party IaC projects.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {57–69},
numpages = {13},
keywords = {Serverless Computing, Cloud, Infrastructure as Code, DevOps},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}
@inproceedings{10.1145/3302333.3302339,
author = {Meixner, Kristof and Winkler, Dietmar and Biffl, Stefan},
title = {Towards Combined Process &amp; Tool Variability Management in Software Testing},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302339},
doi = {10.1145/3302333.3302339},
abstract = {Context. Modern software engineering approaches that rely on continuous and automated testing, like Agile Software Engineering and the late DevOps movement, require integrated and fully functional testing tool chain environment, to efficiently identify defects in software artifacts. Such an environment includes the implementation of established testing processes that are utilized by the development teams. However, in practice, different testing tool chains and processes are implemented depending on particular project requirements such as programming language, selected testing tool, or system architecture. This variety of required technologies and processes frequently results in an environment of isolated test automation solutions. Thus, there is a need for a managed and controllable set of testing tool chain variants that consider structured methods to integrate variability. Goal. In this paper, we show ongoing work, as part of a flexible Test Automation Framework (TAF), with focus on requirements for the variability of testing tool chains, established testing processes, and candidate solution approaches. Method. We build on best practices from software and systems testing and variability management to implement variability in the TAF. Results. First results showed that several Test Automation (TA) solutions exist, which support variability in a limited manner and, therefore, increase the need for modeling variability in a flexible TAF. Conclusion. In the context of Software Test Automation, a combination of Variability Modeling (VM) methods for testing architectures, business processes, and a definition of common interface definitions is promising towards a TAF that enables a flexible tool and process integration.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {5},
numpages = {6},
keywords = {Test Architecture, Process Variability, Test automation, Testing Tool Chain, Software Testing, Variability Modeling},
location = {Leuven, Belgium},
series = {VAMOS '19}
}
@article{10.1007/s00450-016-0338-z,
author = {Wettinger, Johannes and Breitenb\"{u}cher, Uwe and Falkenthal, Michael and Leymann, Frank},
title = {Collaborative Gathering and Continuous Delivery of DevOps Solutions through Repositories},
year = {2017},
issue_date = {July      2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {3–4},
issn = {1865-2034},
url = {https://doi.org/10.1007/s00450-016-0338-z},
doi = {10.1007/s00450-016-0338-z},
abstract = {Collaboration is a key aspect for establishing DevOps-oriented processes because diverse experts such as developers and operations personnel need to efficiently work together to deliver applications. For this purpose, highly automated continuous delivery pipelines are established, consisting of several stages and their corresponding application environments (development, test, production, etc.). The DevOps community provides a huge variety of tools and reusable artifacts (i.e. DevOps solutions such as deployment engines, configuration definitions, container images, etc.) to implement such application environments. This paper presents the concept of collaborative solution repositories, which are based on established software engineering practices. This helps to systematically maintain and link diverse solutions. We further discuss how discovery and capturing of such solutions can be automated. To utilize this knowledge (made of linked DevOps solutions), we apply continuous delivery principles to create diverse knowledge base instances through corresponding pipelines. Finally, an integrated architecture is outlined and validated using a prototype implementation.},
journal = {Comput. Sci.},
month = {jul},
pages = {281–290},
numpages = {10},
keywords = {Continuous delivery, Solution repository, Knowledge, DevOps}
}
@inproceedings{10.1145/2962695.2962706,
author = {Rana, Rakesh and Staron, Miroslaw},
title = {First International Workshop on Emerging Trends in DevOps and Infrastructure},
year = {2016},
isbn = {9781450341349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2962695.2962706},
doi = {10.1145/2962695.2962706},
abstract = {In this paper, we describe the proceedings of first international Workshop on Emerging Trends in DevOps and Infrastructure held at XP-2016. The workshop was conceived and administered to provide a platform for researchers and industrial practitioners researching or working within DevOps environments to come together and discuss issues around the idea of DevOps.The workshop proceeded with research presentations and discussion on the basics of DevOps such as how to define them to more detailed technical challenges and opportunities of working with DevOps practices within an organizational setting.},
booktitle = {Proceedings of the Scientific Workshop Proceedings of XP2016},
articleno = {11},
numpages = {3},
keywords = {Decision Support, Continuous software development, Continuous Experimentation, DevOps, Emerging trends, Development, Continuous Delivery, Operations},
location = {Edinburgh, Scotland, UK},
series = {XP '16 Workshops}
}
@inproceedings{10.1109/SESoS/WDES.2019.00010,
author = {Caraturan, Sara B. O. Gennari and Goya, Denise Hideko},
title = {Major Challenges of Systems-of-Systems with Cloud and DevOps: A Financial Experience Report},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SESoS/WDES.2019.00010},
doi = {10.1109/SESoS/WDES.2019.00010},
abstract = {The term Systems-of-Systems (SoS) refers to a complex system that comprises other systems (the constituent systems), which have operational and managerial independence, geographical distribution, emergent behavior, and evolutionary development processes. DevSecOps (or SecDevOps) offers an approach to guide the implementation of IT Processes, which in turn may support the integration of a cloud environment to a systems-of-systems environment, incorporating information security practices, as well as fostering collaboration between both development and operation teams. It also aims to promote automation of IT processes so that the development of applications and / or services is fast and secure. However, there is a lack of detail in the process definitions to guide the implementation and use of DevSecOps in a Systems-of-Systems environment, especially when it is intended to merge cloud computing into pre-existing conventional infrastructures. In this context, this paper aims at describe the main actions, concerns and lessons learned, during planning and implementation phases, about IT Processes and IT Governance Model to transform an IT traditional environment into Systems-of-Systems environment, considering DevSecOps standards in a large Brazilian financial institution. It will show how IT Processes and IT Governance Model should be changed for incorporating a Cloud environment to a SoS. For doing so, we proposed the use of DevOps techniques as a means to reduce development time without to affect the quality and information security.},
booktitle = {Proceedings of the 7th International Workshop on Software Engineering for Systems-of-Systems and 13th Workshop on Distributed Software Development, Software Ecosystems and Systems-of-Systems},
pages = {10–17},
numpages = {8},
keywords = {DevSecOps, IT governance, cloud, IT processes, financial institution, systems-of-systems},
location = {Montreal, Quebec, Canada},
series = {SESoS-WDES '19}
}
@article{10.1016/j.jss.2018.06.073,
author = {Tuma, K. and Calikli, G. and Scandariato, R.},
title = {Threat Analysis of Software Systems: A Systematic Literature Review},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.06.073},
doi = {10.1016/j.jss.2018.06.073},
journal = {J. Syst. Softw.},
month = {oct},
pages = {275–294},
numpages = {20},
keywords = {Risk assessment, Software systems, Systematic literature review (SLR), Threat analysis (modeling), Security-by-design}
}
@book{10.5555/3044729,
author = {Kim, Gene and Debois, Patrick and Willis, John and Humble, Jez},
title = {The DevOps Handbook: How to Create World-Class Agility, Reliability, and Security in Technology Organizations},
year = {2016},
isbn = {1942788002},
publisher = {IT Revolution Press},
abstract = {Increase profitability, elevate work culture, and exceed productivity goals through DevOps practices. More than ever, the effective management of technology is critical for business competitiveness. For decades, technology leaders have struggled to balance agility, reliability, and security. The consequences of failure have never been greaterwhether it's the healthcare.gov debacle, cardholder data breaches, or missing the boat with Big Data in the cloud. And yet, high performers using DevOps principles, such as Google, Amazon, Facebook, Etsy, and Netflix, are routinely and reliably deploying code into production hundreds, or even thousands, of times per day. Following in the footsteps of The Phoenix Project, The DevOps Handbook shows leaders how to replicate these incredible outcomes, by showing how to integrate Product Management, Development, QA, IT Operations, and Information Security to elevate your company and win in the marketplace. Take the DORA DevOps X-ray Assessment and see where you stand! Visit devops-survey.com with your access code to take the DevOps X-ray Assessment.}
}
@inproceedings{10.1007/978-3-030-39306-9_1,
author = {Bobrov, Evgeny and Bucchiarone, Antonio and Capozucca, Alfredo and Guelfi, Nicolas and Mazzara, Manuel and Masyagin, Sergey},
title = {Teaching DevOps in Academia and Industry: Reflections and Vision},
year = {2019},
isbn = {978-3-030-39305-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39306-9_1},
doi = {10.1007/978-3-030-39306-9_1},
abstract = {The new century brought us a kind of renaissance in software development methods. The advent of the Agile manifesto has led to greater appreciation of methodologies aimed at producing valuable software through continuous incremental cycles. More recently, a new set of practices enclosed under the term DevOps has appeared to attain manifesto’s objectives in more efficient manner. The software development community has already noticed the benefits brought by DevOps. Thus, the necessity of education in the field becomes more and more important, both from the technical and organisational point of view. This paper describes parallel experiences of teaching both undergraduate and graduate students at the university, and junior professional developers in industry, compares the two approaches and sums up the lessons learnt. A vision driven by the DevOps practices aimed at implementing a shift in the Software Engineering Higher Education curricula to takeover its current limitations is also reported at the end of the paper.},
booktitle = {Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Ch\^{a}teau de Villebrumier, France, May 6–8, 2019, Revised Selected Papers},
pages = {1–14},
numpages = {14},
location = {Villebrumier, France}
}
@article{10.5555/3007225.3007250,
author = {Chung, Sam and Bang, Soon},
title = {Identifying Knowledge, Skills, and Abilities (KSA) for Devops-Aware Server Side Web Application with the Grounded Theory},
year = {2016},
issue_date = {October 2016},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {32},
number = {1},
issn = {1937-4771},
abstract = {The purpose of this research is to propose what fundamental Knowledge (K), Skills (S), and Abilities (A) should be taught in web development courses, which can support not only development but also operations, namely DevOps. Instead of focusing on client side web application development using standard web technologies, we focus on server side web application development which holds many challenges due to a diversity of languages and emerging technologies. The advent of cloud computing reduced the gap between web application development and deployment/operation. Also, it brought an emerging concept, DevOps, to the web application development community. We identify what KSAs are needed to support DevOps and attempt to include them in web development courses. When the KSAs are included in web application development courses, students are well prepared for the emerging practice and computing paradigm of DevOps.},
journal = {J. Comput. Sci. Coll.},
month = {oct},
pages = {110–116},
numpages = {7}
}
@book{10.5555/3137326,
author = {Kantsev, Veselin},
title = {Implementing DevOps on AWS},
year = {2017},
isbn = {1786460149},
publisher = {Packt Publishing},
abstract = {Key FeaturesWork through practical examples and gain DevOps best practices to successfully deploy applications on AWSSuccessfully provision and operate distributed application systems and your AWS infrastructure using DevOps Perform Continuous Integration and deployment and fine-tune the way you deliver on AWS Book Description Knowing how to adopt DevOps in your organization is becoming an increasingly important skill for developers, whether you work for a start-up, an SMB, or an enterprise. This book will help you to drastically reduce the amount of time spent on development and increase the reliability of your software deployments on AWS using popular DevOps methods of automation. To start, you will get familiar with the concept of IaC and will learn to design, deploy, and maintain AWS infrastructure. Further on, youll see how to design and deploy a Continuous Integration platform on AWS using either open source or AWS provided tools/services. Following on from the delivery part of the process, you will learn how to deploy a newly created, tested, and verified artefact to the AWS infrastructure without manual intervention. You will then find out what to consider in order to make the implementation of Configuration Management easier and more effective. Toward the end of the book, you will learn some tricks and tips to optimize and secure your AWS environment. By the end of the book, you will have mastered the art of implementing DevOps practices onto AWS. What you will learn Design and deploy infrastructure as code within your AWS Virtual Private Cloud Implement Continuous Integration using AWS Services Configure EC2 instances using Salt Stack Implement Continuous Deployment using Jenkins and the AWS CLI Collect important metrics and log data to gain more insight into infrastructure and applications Troubleshooting popular issues with some less known techniques using the AWS platform About the Author Veselin Kantsev is a DevOps professional and a Linux enthusiast who lives in London, UK. His introduction to Linux was as a System Administrator back in 2006. His focus for the past few years has been mostly on cloud technologies and the transition of the community from an Ops to a DevOps culture. He has worked with companies in various sectors such as Design, Media, and Finance, specializing in the migration of infrastructure onto AWS and the promotion of DevOps principles and practices}
}
@article{10.5555/3447307.3447319,
author = {Bennett, Brian T.},
title = {Shifting Traditional Undergraduate Software Engineering Instruction to a DevOps Focus},
year = {2021},
issue_date = {January 2021},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {36},
number = {5},
issn = {1937-4771},
abstract = {Classical Software Engineering education often includes traditional methodologies that do not adequately describe today's industry practice. DevOps is a culture that promotes fast delivery, continuous feedback, and an environment of learning. Its non-linear path requires a shift in software engineering pedagogy. This case study describes the redevelopment of a second-semester course in software engineering to focus on DevOps principles. The study evaluates student performance using formative and summative assessment through a team project tracked throughout the semester and final exam results. Results indicated that students developed DevOps skills during the course, but may have needed more reinforcement of some traditional Software Engineering topics.},
journal = {J. Comput. Sci. Coll.},
month = {jan},
pages = {129–138},
numpages = {10}
}
@book{10.5555/3202631,
author = {Ratan, Abhishek},
title = {Practical Network Automation: Leverage the Power of Python and Ansible to Optimize Your Network},
year = {2017},
isbn = {1788299469},
publisher = {Packt Publishing},
abstract = {Key FeaturesGet started with network automation (and different automation tasks) with relevant use casesApply software design principles such as Continuous Integration and DevOps to your network toolkitGuides you through some best practices in automationBook DescriptionNetwork automation is the use of IT controls to supervise and carry out every-day network management functions. It plays a key role in network virtualization technologies and network functions. The book starts by providing an introduction to network automation, SDN, and its applications, which include integrating DevOps tools to automate the network efficiently. It then guides you through different network automation tasks and covers various data digging and reporting methodologies such as IPv6 migration, DC relocations, and interface parsing, all the while retaining security and improving data center robustness. The book then moves on to the use of Python and the management of SSH keys for machine-to-machine (M2M) communication, all followed by practical use cases. The book also covers the importance of Ansible for network automation including best practices in automation, ways to test automated networks using different tools, and other important techniques. By the end of the book, you will be well acquainted with the various aspects of network automation. What you will learnGet the detailed analysis of Network automation Trigger automations through available data factors Improve data center robustness and security through specific access and data digging Get an Access to APIs from Excel for dynamic reporting Set up a communication with SSH-based devices using netmiko Make full use of practical use cases and best practices to get accustomed with the various aspects of network automationAbout the Author Abhishek Ratan has around 15 years of technical experience in networking, automation, and various ITIL processes, and has worked in various roles in different organizations. As a network engineer, security engineer, automation engineer, TAC engineer, tech lead, and content writer, he has gained a wealth of experience during the 15 years of his career. Abhishek also has a deep interest in strategy game playing, and if he is not working on technical stuff, he is busy spending time on his strategy games. He is currently working as a Sr Automation Engineer at Service Now, learning, and expanding his automation skills in the ServiceNow platform. His earlier experience includes working for companies such as Microsoft, Symantec, and Navisite,which has given him exposure to various environments.}
}
@article{10.1109/MS.2016.66,
author = {Callanan, Matt and Spillane, Alexandra},
title = {DevOps: Making It Easy to Do the Right Thing},
year = {2016},
issue_date = {May 2016},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {33},
number = {3},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2016.66},
doi = {10.1109/MS.2016.66},
abstract = {Wotif Group used DevOps principles to recover from the downward spiral of manual release activity that many IT departments face. Its approach involved the idea of "making it easy to do the right thing." By defining the right thing (deployment standards) for development and operations teams and making it easy to adopt, Wotif drastically improved the average release cycle time. This article is part of a theme issue on DevOps.},
journal = {IEEE Softw.},
month = {may},
pages = {53–59},
numpages = {7}
}
@phdthesis{10.5555/AAI28992066,
author = {Barros, R\'{u}ben dos Santos and Nuno, Silva,},
advisor = {\^{A}ngelo, Martins, and Boldt, Sousa, Tiago},
title = {DevOps Technologies for Tomorrow},
year = {2016},
isbn = {9798209808459},
publisher = {Instituto Politecnico do Porto (Portugal)},
abstract = {DevOps (short for development and operations) is an approach based on lean and agile principles in which the departments of development, quality assurance, and operations collaborate to deliver software in a continuous manner that enables the business to seize market opportunities faster and reduce the time to include customer feedback.Users and customers of today's Web applications and mobile apps running in the Cloud expect that fast feedback and features to their issues and requests respectively. Thus, it is a critical competitive advantage to be able to respond as quickly as possible. To achieve that, besides the necessary cultural and organizational changes, we need to use new tools to implement automations for the software workflow. Automation is the key to eficiente collaboration and tight integration between development and operations. The DevOps community is constantly pushing new approaches, tools, and open-source artifacts to implemente such automated processes. However, as all these proprietary and heterogeneous DevOps automation approaches differ from each other, it is hard to integrate and combine them to deploy applications in the Cloud.With the recognition of the importance of DevOps, an explosion of technologies that address the subject was evident. However, a problem emerges; such diversity made it non-trivial for software teams to evaluate the wide range of existing tools and identify the best approach for them to practice DevOps.In this dissertation, we thoroughly research DevOps, its concepts, and some of the most widely used tools, and gather the most relevant information as our defined goals. Consequently, we present a document with structured information regarding DevOps as well as a reliable DevOps Knowledge Map.Throughout this document, we show that a DevOps approach brings many benefits to a wide range of different users and organizations, as it automates several processes while increasing the team's confidence and quality of life.},
note = {AAI28992066}
}
@book{10.5555/3086889,
author = {Cuppett, Michael S.},
title = {DevOps, DBAs, and DBaaS: Managing Data Platforms to Support Continuous Integration},
year = {2016},
isbn = {1484222075},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Learn how DBAs in a DevOps environment manage data platforms and change requests to support and optimize continuous integration, delivery, testing, and deployment in the application development life cycle. On the Dev side, DBAs evaluate change requests to ensure compliance with organizational best practices and guard against degradation of database performance and the validity of dependent objects. On the Ops side, DBAs perform release and troubleshooting activities in support of the application, manage the data platforms access and security, and monitor and maintain performance of the databases that they have designed and provisioned. DevOps, DBAs, and DBaaS investigates the complex intersection between DBA functions and DevOps processes. DevOps teams traditionally viewed DBAs as process outliers who disrupt and retard SDLC timelines. At each touch point, veteran DBA Mike Cuppett shows how DBAs can most effectively contribute to decreasing release cycle times and improving product resiliency by applying automation, orchestration, and DBaaS solutions to database administration in ways that dovetail with DevOps requirements and metrics. At a high level, Cuppett demonstrates the importance of leveling silo walls in the IT supply chain and of measuring application performance holistically by reference to satisfaction of customer requirements and end-user experience. At a technical level, he drills into topics and case studies on diagnosing and resolving problems commonly encountered by DBAs and DevOps teams when meshing database management with application delivery. What You Will Learn:Understand techniques and best practices at all points of collaboration between DBAs and DevOps teams in product developmentUse tools for measuring DBA inputs to DevOps processes by holistic criteria of end-user experience and business requirementIntegrate open source database technologies with DevOpsKnow when to decouple application and database layers and move to DBaaS modelsOvercome language and mindset barriers between DBAs and DevOps teamsWho This Book Is For:DBAs who are leaning toward or already involved with DevOps and DevOps engineers, team leaders, developers and product managers who are already working with DBAs or planning to integrate DBAs in DevOps teams. The secondary readership is executives and managers in companies that practice DevOps.}
}
@book{10.5555/2685407,
author = {Limoncelli, Thomas A. and Chalup, Strata R. and Hogan, Christina J.},
title = {The Practice of Cloud System Administration: Designing and Operating Large Distributed Systems, Volume 2},
year = {2014},
isbn = {032194318X},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {Theres an incredible amount of depth and thinking in the practicesdescribed here, and its impressive to see it all in one place. Win Treese, coauthor of Designing Systems for Internet Commerce The Practice of Cloud System Administration, Volume 2, focuses on distributed or cloud computing and brings a DevOps/SRE sensibility to the practice of system administration. Unsatisfied with books that cover either design or operations in isolation, the authors created this authoritative reference centered on a comprehensive approach. Case studies and examples from Google, Etsy, Twitter, Facebook, Netflix, Amazon, and other industry giants are explained in practical ways that are useful to all enterprises. The new companion to the best-selling first volume, The Practice of System and Network Administration, Second Edition, this guide offers expert coverage of the following and many other crucial topics: Designing and building modern web and distributed systems Fundamentals of large system design Understand the new software engineering implications of cloud administration Make systems that are resilient to failure and grow and scale dynamically Implement DevOps principles and cultural changes IaaS/PaaS/SaaS and virtual platform selection Operating and running systems using the latest DevOps/SRE strategies Upgrade production systems with zero down-time What and how to automate; how to decide what not to automate On-call best practices that improve uptime Why distributed systems require fundamentally different system administration techniques Identify and resolve resiliency problems before they surprise you Assessingand evaluating your teams operational effectiveness Manage thescientific process of continuous improvement A forty-page, pain-free assessment system you can start using today}
}
@book{10.5555/2810087,
author = {Bass, Len and Weber, Ingo and Zhu, Liming},
title = {DevOps: A Software Architect's Perspective},
year = {2015},
isbn = {0134049845},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {The First Complete Guide to DevOps for Software Architects DevOps promises to accelerate the release of new software features and improve monitoring of systems in production, but its crucial implications for software architects and architecture are often ignored. In DevOps: A Software Architects Perspective, three leading architects address these issues head-on. The authors review decisions software architects must make in order to achieve DevOps goals and clarify how other DevOps participants are likely to impact the architects work. They also provide the organizational, technical, and operational context needed to deploy DevOps more efficiently, and review DevOps impact on each development phase. The authors address cross-cutting concerns that link multiple functions, offering practical insights into compliance, performance, reliability, repeatability, and security. This guide demonstrates the authors ideas in action with three real-world case studies: datacenter replication for business continuity, management of a continuous deployment pipeline, and migration to a microservice architecture. Comprehensive coverage includes Why DevOps can require major changes in both system architecture and IT roles How virtualization and the cloud can enable DevOps practices Integrating operations and its service lifecycle into DevOps Designing new systems to work well with DevOps practices Integrating DevOps with agile methods and TDD Handling failure detection, upgrade planning, and other key issues Managing consistency issues arising from DevOps independent deployment models Integrating security controls, roles, and audits into DevOps Preparing a business plan for DevOps adoption, rollout, and measurement}
}
@book{10.5555/3299453,
author = {Dive, Priyanka and Gornalli, Nagraj},
title = {DevOps for Salesforce: Build, Test, and Streamline Data Pipelines to Simplify Development in Salesforce},
year = {2018},
isbn = {1788833341},
publisher = {Packt Publishing},
abstract = {Implement DevOps for Salesforce and explore its features Key Features Learn DevOps principles and techniques for enterprise operations in Salesforce Implement Continuous Integration and Continuous Delivery using tools such as Jenkins and Ant script Use the Force.com Migration Tool and Git to achieve versioning in Salesforce Book Description Salesforce is one of the top CRM tools used these days, and with its immense functionalities and features, it eases the functioning of an enterprise in various areas of sales, marketing, and finance, among others. Deploying Salesforce applications is a tricky event, and it can get quite taxing for admins and consultants. This book addresses all the problems that you might encounter while trying to deploy your applications and shows you how to resort to DevOps to take these challenges head on. Beginning with an overview of the development and delivery process of a Salesforce app, DevOps for Salesforce covers various types of sandboxing and helps you understand when to choose which type. You will then see how different it is to deploy with Salesforce as compared to deploying with another app. You will learn how to leverage a migration tool and automate deployment using the latest and most popular tools in the ecosystem. This book explores topics such as version control and DevOps techniques such as Continuous Integration, Continuous Delivery, and testing. Finally, the book will conclude by showing you how to track bugs in your application changes using monitoring tools and how to quantify your productivity and ROI. By the end of the book, you will have acquired skills to create, test, and effectively deploy your applications by leveraging the features of DevOps. What you will learn Implement DevOps for Salesforce and understand the benefits it offers Abstract the features of Force.com MigrationTool to migrate and retrieve metadata Develop your own CI/CD Pipeline for Salesforce project Use Qualitia to perform scriptless automation for Continuous Testing Track application changes using Bugzilla Apply Salesforce best practices to implement DevOps Who this book is for If you are a Salesforce developer, consultant, or manager who wants to learn DevOps tools and set up pipelines for small as well as large Salesforce projects, this book is for you.}
}
@inproceedings{10.1145/3190619.3190642,
author = {Zheng, Erkang and Gates-Idem, Phil and Lavin, Matt},
title = {Building a Virtually Air-Gapped Secure Environment in AWS: With Principles of Devops Security Program and Secure Software Delivery},
year = {2018},
isbn = {9781450364553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3190619.3190642},
doi = {10.1145/3190619.3190642},
abstract = {This paper presents the development and configuration of a virtually air-gapped cloud environment in AWS, to secure the production software workloads and patient data (ePHI) and to achieve HIPAA compliance.},
booktitle = {Proceedings of the 5th Annual Symposium and Bootcamp on Hot Topics in the Science of Security},
articleno = {11},
numpages = {8},
keywords = {trust, cloud, risk management, devops, security, AWS, cybersecurity},
location = {Raleigh, North Carolina},
series = {HoTSoS '18}
}
@inproceedings{10.1145/3349266.3351360,
author = {Border, Charles},
title = {Development of a Configuration Management Course for Operations Students},
year = {2019},
isbn = {9781450369213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349266.3351360},
doi = {10.1145/3349266.3351360},
abstract = {In the recent past only a few of the "Unicorn" companies such as Facebook, Amazon, and Google were concerned about being able to deploy software into production on distributed computing architectures multiple times per day. To facilitate their ability to do this they developed a series of practices such as Continuous Integration/Continuous Deployment (CI/CD), Test Driven Development, Agile Development and DevOps. The goal of these techniques was to be able to get the work of their thousands of developers into production as quickly, safely, reliably and consistently as possible. Most other large-scale companies have since adopted as least some of these practices and they are considered standard procedure for most large organizations.The Operations side of deploying a modern computing application necessarily involves multiple groups working in concert to develop and test the application and the server side configuration that will support that application. This lightning talk reports on initial efforts to develop a course that encourages students to dig into issues related to configuration management, security policy development, application auditing, business control issues, and most importantly, team work. While the course is entitled "Configuration Management" it is much more about students creating a process for secure iterative application deployment that borrows extensively from the DevOps movement.},
booktitle = {Proceedings of the 20th Annual SIG Conference on Information Technology Education},
pages = {41},
numpages = {1},
keywords = {devops, operations, configuration management, security},
location = {Tacoma, WA, USA},
series = {SIGITE '19}
}
@inproceedings{10.1145/3393822.3432330,
author = {Daoudagh, Said and Lonetti, Francesca and Marchetti, Eda},
title = {Continuous Development and Testing of Access and Usage Control: A Systematic Literature Review},
year = {2020},
isbn = {9781450377621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3393822.3432330},
doi = {10.1145/3393822.3432330},
abstract = {Context: Development and testing of access/usage control systems is a growing research area. With new trends in software development such as DevOps, the development of access/usage control also has to evolve. Objective: The main aim of this paper is to provide an overview of research proposals in the area of continuous development and testing of access and usage control systems. Method: The paper uses a Systematic Literature Review as a research method to define the research questions and answer them following a systematic approach. With the specified search string, 210 studies were retrieved. After applying the inclusion and exclusion criteria in two phases, a final set of 20 primary studies was selected for this review. Results: Results show that primary studies are mostly published in security venues followed by software engineering venues. Furthermore, most of the studies are based on the standard XACML access control language. In addition, a significant portion of the proposals for development and testing is automated with test assessment and generation the most targeted areas. Some general guidelines for leveraging continuous developing and testing of the usage and access control systems inside the DevOps process are also provided.},
booktitle = {Proceedings of the 2020 European Symposium on Software Engineering},
pages = {51–59},
numpages = {9},
keywords = {Access Control, Systematic Literature Review, XACML, Testing, DevOps},
location = {Rome, Italy},
series = {ESSE 2020}
}
@article{10.1007/s10009-019-00546-y,
author = {Couto, Luis Diogo and Tran-J\o{}rgensen, Peter W. V. and Nilsson, Ren\'{e} S. and Larsen, Peter Gorm},
title = {Enabling Continuous Integration in a Formal Methods Setting},
year = {2020},
issue_date = {Dec 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {6},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-019-00546-y},
doi = {10.1007/s10009-019-00546-y},
abstract = {In modern software development, the practices of continuous integration and DevOps are widely used to increase delivery speed and reduce the time it takes to deploy software changes to production. If formal method tools cannot be efficiently integrated in a DevOps paradigm, then their impact on software development will be reduced. In this paper, we present work addressing this issue through a series of extensions for the Overture tool supporting the Vienna Development Method. These extensions enable Overture to be used in a DevOps setting, through continuous integration and validation of models and generated code via integration with the Jenkins automation server. We frame the integration of formal methods and DevOps in a series of principles, demonstrate the value of this integration through a case study, and reflect on our experiences using formal methods and DevOps in an industrial setting. We hope that this work can help other formal method practitioners integrate their tools with DevOps.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = {dec},
pages = {667–683},
numpages = {17},
keywords = {Continuous integration, Test automation, Simulation, Code generation, VDM, Modelling, DevOps}
}
@book{10.5555/2380958,
author = {Httermann, Michael},
title = {DevOps for Developers},
year = {2012},
isbn = {1430245697},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {DevOps for Developers delivers a practical, thorough introduction to approaches, processes and tools to foster collaboration between software development and operations. Efforts of Agile software development often end at the transition phase from development to operations. This book covers the delivery of software, this means the last mile, with lean practices for shipping the software to production and making it available to the end users, together with the integration of operations with earlier project phases (elaboration, construction, transition). DevOps for Developers describes how to streamline the software delivery process and improve the cycle time (that is the time from inception to delivery). It will enable you to deliver software faster, in better quality and more aligned with individual requirements and basic conditions. And above all, work that is aligned with the DevOps approach makes even more fun! Provides patterns and toolchains to integrate software development and operations Delivers an one-stop shop for kick-starting with DevOps Provides guidance how to streamline the software delivery process What youll learn Know what DevOps is and how it can result in better and faster delivered software Apply patterns to improve collaboration between development and operations Introduce unified processes and incentives to support shared goals Start with or extend a tool infrastructure that spans projects roles and phases Address pain points in your individual environment with appropriate recipes Break down existing walls that make up an unnecessarily sluggish delivery process Who this book is for DevOps for Developers is for motivated software engineers, particularly programmers, testers, QA, system admins, database admins, both beginners and experts, who want to improve their software delivery process. Its the perfect choice for engineers who want to go the next step by integrating their approaches for development and delivery of software. This book is for engineers who want to shape their processes and decide on and integrate open source tools and seek for guidance how to integrate standard tools in advanced real world use cases. Table of Contents Beginning DevOps for Developers Introducing DevOps Building Blocks of DevOps Quality and Testing Introduce Shared Incentives Gain Fast Feedback Unified and Holistic Approach Automatic Releasing Infrastructure as Code Specification by Example}
}
@inproceedings{10.1145/2983990.2984000,
author = {Hanappi, Oliver and Hummer, Waldemar and Dustdar, Schahram},
title = {Asserting Reliable Convergence for Configuration Management Scripts},
year = {2016},
isbn = {9781450344449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983990.2984000},
doi = {10.1145/2983990.2984000},
abstract = {The rise of elastically scaling applications that frequently deploy new machines has led to the adoption of DevOps practices across the cloud engineering stack. So-called configuration management tools utilize scripts that are based on declarative resource descriptions and make the system converge to the desired state. It is crucial for convergent configurations to be able to gracefully handle transient faults, e.g., network outages when downloading and installing software packages. In this paper we introduce a conceptual framework for asserting reliable convergence in configuration management. Based on a formal definition of configuration scripts and their resources, we utilize state transition graphs to test whether a script makes the system converge to the desired state under different conditions. In our generalized model, configuration actions are partially ordered, often resulting in prohibitively many possible execution orders. To reduce this problem space, we define and analyze a property called preservation, and we show that if preservation holds for all pairs of resources, then convergence holds for the entire configuration. Our implementation builds on Puppet, but the approach is equally applicable to other frameworks like Chef, Ansible, etc. We perform a comprehensive evaluation based on real world Puppet scripts and show the effectiveness of the approach. Our tool is able to detect all idempotence and convergence related issues in a set of existing Puppet scripts with known issues as well as some hitherto undiscovered bugs in a large random sample of scripts.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {328–343},
numpages = {16},
keywords = {Puppet, DevOps, Configuration Management, System Configuration Scripts, Idempotence, Convergence, Testing, Declarative Language},
location = {Amsterdam, Netherlands},
series = {OOPSLA 2016}
}
@article{10.1145/3022671.2984000,
author = {Hanappi, Oliver and Hummer, Waldemar and Dustdar, Schahram},
title = {Asserting Reliable Convergence for Configuration Management Scripts},
year = {2016},
issue_date = {October 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/3022671.2984000},
doi = {10.1145/3022671.2984000},
abstract = {The rise of elastically scaling applications that frequently deploy new machines has led to the adoption of DevOps practices across the cloud engineering stack. So-called configuration management tools utilize scripts that are based on declarative resource descriptions and make the system converge to the desired state. It is crucial for convergent configurations to be able to gracefully handle transient faults, e.g., network outages when downloading and installing software packages. In this paper we introduce a conceptual framework for asserting reliable convergence in configuration management. Based on a formal definition of configuration scripts and their resources, we utilize state transition graphs to test whether a script makes the system converge to the desired state under different conditions. In our generalized model, configuration actions are partially ordered, often resulting in prohibitively many possible execution orders. To reduce this problem space, we define and analyze a property called preservation, and we show that if preservation holds for all pairs of resources, then convergence holds for the entire configuration. Our implementation builds on Puppet, but the approach is equally applicable to other frameworks like Chef, Ansible, etc. We perform a comprehensive evaluation based on real world Puppet scripts and show the effectiveness of the approach. Our tool is able to detect all idempotence and convergence related issues in a set of existing Puppet scripts with known issues as well as some hitherto undiscovered bugs in a large random sample of scripts.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {328–343},
numpages = {16},
keywords = {Puppet, Convergence, System Configuration Scripts, Declarative Language, DevOps, Testing, Idempotence, Configuration Management}
}
@article{10.1145/2927299.2945077,
author = {Limoncelli, Thomas A.},
title = {The Small Batches Principle: Reducing Waste, Encouraging Experimentation, and Making Everyone Happy},
year = {2016},
issue_date = {March-April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/2927299.2945077},
doi = {10.1145/2927299.2945077},
abstract = {The small batches principle is part of the DevOps methodology. It comes from the lean manufacturing movement, which is often called just-in-time manufacturing. It can be applied to just about any kind of process. It also enables the MVP (minimum viable product) methodology, which involves launching a small version of a service to get early feedback that informs the decisions made later in the project.},
journal = {Queue},
month = {apr},
pages = {24–41},
numpages = {18}
}
author = {Capozucca, Alfredo and Guelfi, Nicolas},
title = {Analysing the SWECOM Standard for Designing a DevOps Education Programme},
year = {2019},
isbn = {978-3-030-57662-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-57663-9_10},
doi = {10.1007/978-3-030-57663-9_10},
abstract = {Developing academic education programmes for software engineers is a difficult task mainly due to three main factors: (1) ever-changing information and communication technologies produced by the industry and meant for citizens living in digital disruptions age, (2) lack of official or de-facto standards for the software engineering domain, (3) slow pace of the standardisation bodies and of the academia for deploying standard competence frameworks or education programmes. This applies more especially to DevOps which regroups a set of skills being the most demanded today by the job market. This paper is a first attempt to introduce a standard based development process to derive a DevOps education programme for graduate education. It is introduced as a generic process mainly based on the SWECOM standard. This process is applied to generate a proposal for a significant DevOps graduate academic programme definition in a comprehensive and, most importantly, in a skill oriented manner.},
booktitle = {Frontiers in Software Engineering Education: First International Workshop, FISEE 2019, Villebrumier, France, November 11–13, 2019, Invited Papers},
pages = {133–150},
numpages = {18},
location = {Villebrumier, France}
}
@inproceedings{10.1145/3234152.3234199,
author = {D\'{\i}az, Jessica and Almaraz, Rub\'{e}n and P\'{e}rez, Jennifer and Garbajosa, Juan},
title = {DevOps in Practice: An Exploratory Case Study},
year = {2018},
isbn = {9781450364225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234152.3234199},
doi = {10.1145/3234152.3234199},
abstract = {DevOps is a cultural movement and technical solution that plays a fundamental role for software-intensive organizations whose business greatly depends on how efficient development and operation are. DevOps is relatively recent, and thus little is known about best practices and the real value and barriers associated with DevOps in industry. To conduct an analysis on practicing DevOps in various software development companies in order to provide patterns of DevOps practices and identify their benefits and barriers. An exploratory case study based on the interviews to relevant stakeholders of 11 (multinational) software-intensive companies. The study is currently ongoing. This study aims to help practitioners and researchers to better understand some DevOps improvement practices as well as real DevOps projects and the contexts where the practices worked, and benefits and barriers appeared. This, hopefully, will contribute to strengthening the evidence regarding DevOps and supporting practitioners in making better informed decisions about the ROI of introducing DevOps.},
booktitle = {Proceedings of the 19th International Conference on Agile Software Development: Companion},
articleno = {1},
numpages = {3},
keywords = {exploratory case study, DevOps, empirical software engineering},
location = {Porto, Portugal},
series = {XP '18}
}
@article{10.1016/j.infsof.2019.06.010,
author = {Lwakatare, Lucy Ellen and Kilamo, Terhi and Karvonen, Teemu and Sauvola, Tanja and Heikkil\"{a}, Ville and Itkonen, Juha and Kuvaja, Pasi and Mikkonen, Tommi and Oivo, Markku and Lassenius, Casper},
title = {DevOps in Practice: A Multiple Case Study of Five Companies},
year = {2019},
issue_date = {Oct 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {114},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.06.010},
doi = {10.1016/j.infsof.2019.06.010},
journal = {Inf. Softw. Technol.},
month = {oct},
pages = {217–230},
numpages = {14},
keywords = {Development, DevOps, Continuous deployment, Agile, Operations}
}
@inproceedings{10.1109/RELENG.2015.10,
author = {Dyck, Andrej and Penners, Ralf and Lichter, Horst},
title = {Towards Definitions for Release Engineering and DevOps},
year = {2015},
isbn = {9781467370707},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/RELENG.2015.10},
doi = {10.1109/RELENG.2015.10},
abstract = {Delivering software fast, reliable, and predictable is essential for software development organizations. Yet, they often struggle to implement proper approaches and practices like release engineering and DevOps. One reason is the lack of consistent definitions for both of these terms, making it difficult to grasp the meaning and adding further confusion. To the best of our knowledge, there are no uniform definitions for both terms, and thus, many inadequate or even wrong interpretations exist. Consequently, these terms are often confused, misinterpreted, or used as synonyms. In this paper, we propose definitions for release engineering and DevOps to tell both apart.},
booktitle = {Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering},
pages = {3},
keywords = {definition, devops, release engineering},
series = {RELENG '15}
}
@inproceedings{10.5555/2820690.2820694,
author = {Dyck, Andrej and Penners, Ralf and Lichter, Horst},
title = {Towards Definitions for Release Engineering and DevOps},
year = {2015},
publisher = {IEEE Press},
abstract = {Delivering software fast, reliable, and predictable is essential for software development organizations. Yet, they often struggle to implement proper approaches and practices like release engineering and DevOps. One reason is the lack of consistent definitions for both of these terms, making it difficult to grasp the meaning and adding further confusion.To the best of our knowledge, there are no uniform definitions for both terms, and thus, many inadequate or even wrong interpretations exist. Consequently, these terms are often confused, misinterpreted, or used as synonyms. In this paper, we propose definitions for release engineering and DevOps to tell both apart.},
booktitle = {Proceedings of the Third International Workshop on Release Engineering},
pages = {3},
numpages = {1},
location = {Florence, Italy},
series = {RELENG '15}
}
@book{10.5555/3286540,
author = {Farooqui, Shamayel M.},
title = {Enterprise DevOps Framework: Transforming IT Operations},
year = {2018},
isbn = {1484236114},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Transform your IT organization from one weighed down by set practices to one with a DevOps culture and a cloud-first strategy that is optimized by automation and other lean practices. In this engaging read, you will discover the opportunities, challenges, lessons, and rewards that CA Technologies encountered when making their agile and DevOps transformation. In Enterprise DevOps Framework author Shamayel Farooqui shows you how agile adoption will enable your organization to stay ahead in an ever-changing business environment and meet your customers needs. He includes detailed references to key concepts such as agile, hybrid and cloud technology, infrastructure management, and process automation. What Youll Learn Establish the focus areas for your IT organization Prepare for the challenges of transforming your enterprise to a DevOps, agile organization Know the key steps for executing an enterprise DevOps strategy Build a strong team of DevOps individuals focused on improving the efficiency of your organization through Agile methodologies, automation, cloud adoption, and infrastructure as code practices Who This Book Is For IT administrators, operational personnel, cloud professionals, DevOps professionals, human resources professionals, managers, and C-level staff}
}
@inproceedings{10.1145/3297662.3365827,
author = {Anisetti, Marco and Ardagna, Claudio A. and Gaudenzi, Filippo and Damiani, Ernesto},
title = {A Continuous Certification Methodology for DevOps},
year = {2019},
isbn = {9781450362382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297662.3365827},
doi = {10.1145/3297662.3365827},
abstract = {The cloud paradigm has revolutionized the way in which software systems are designed, managed, and maintained. With the advent of the microservice architecture, this trend was brought to the extreme, pushing the whole software development process towards unification of software development (Dev) and software operation (Ops). This rapid evolution has not immediately found counterparts in assurance techniques, where the evaluation of the non-functional behavior of a software system and of the software development process are completely decoupled. In this paper, we put forward the idea that next-generation assurance techniques, and more specifically certification techniques, must evaluate a software system throughout the whole development process. To this aim, we define a continuous certification scheme for DevOps that evaluates the software artifacts produced at each stage of the development process. We then present the assurance framework managing our certification scheme and experimentally evaluate the continuous certification scheme in a real DevOps scenario.},
booktitle = {Proceedings of the 11th International Conference on Management of Digital EcoSystems},
pages = {205–212},
numpages = {8},
keywords = {DevOps, Certification, Assurance},
location = {Limassol, Cyprus},
series = {MEDES '19}
}
@inproceedings{10.1007/978-3-030-64148-1_27,
author = {Moy\'{o}n, Fabiola and Soares, Rafael and Pinto-Albuquerque, Maria and Mendez, Daniel and Beckers, Kristian},
title = {Integration of Security Standards in DevOps Pipelines: An Industry Case Study},
year = {2020},
isbn = {978-3-030-64147-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64148-1_27},
doi = {10.1007/978-3-030-64148-1_27},
abstract = {In the last decade, companies adopted DevOps as a fast path to deliver software products according to customer expectations, with well aligned teams and in continuous cycles. As a basic practice, DevOps relies on pipelines that simulate factory swim-lanes. The more automation in the pipeline, the shorter a lead time is supposed to be. However, applying DevOps is challenging, particularly for industrial control systems (ICS) that support critical infrastructures and that must obey to rigorous requirements from security regulations and standards. Current research on security compliant DevOps presents open gaps for this particular domain and in general for systematic application of security standards. In this paper, we present a systematic approach to integrate standard-based security activities into DevOps pipelines and highlight their automation potential. Our intention is to share our experiences and help practitioners to overcome the trade-off between adding security activities into the development process and keeping a short lead time. We conducted an evaluation of our approach at a large industrial company considering the IEC 62443-4-1 security standard that regulates ICS. The results strengthen our confidence in the usefulness of our approach and artefacts, and in that they can support practitioners to achieve security compliance while preserving agility including short lead times.},
booktitle = {Product-Focused Software Process Improvement: 21st International Conference, PROFES 2020, Turin, Italy, November 25–27, 2020, Proceedings},
pages = {434–452},
numpages = {19},
keywords = {Agile software engineering, DevSecOps, Secure software engineering, DevOps pipeline, Industrial control systems, Security standards},
location = {Turin, Italy}
}
@article{10.5555/3015063.3015077,
author = {Sjodin, Rob and Barnes, Stephen},
title = {Teaching Agile Methodologies and DevOps/CI/CD in the Classroom: Concepts, Techniques, Modalities: Panel Discussion},
year = {2016},
issue_date = {December 2016},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {32},
number = {2},
issn = {1937-4771},
abstract = {This panel will address various techniques for teaching agile and DevOps/Continuous Integration/Continuous Deployment methodologies in the classroom. Both online and in-class modalities are addressed.},
journal = {J. Comput. Sci. Coll.},
month = {dec},
pages = {90–91},
numpages = {2}
}
@inproceedings{10.1109/UCC.2014.14,
author = {Wettinger, Johannes and Breitenb\"{u}cher, Uwe and Leymann, Frank},
title = {Standards-Based DevOps Automation and Integration Using TOSCA},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.14},
doi = {10.1109/UCC.2014.14},
abstract = {DevOps is an emerging paradigm to tightly integrate developers with operations personnel. This is required to enable fast and frequent releases in the sense of continuously delivering software. Users and customers of today's Web applications and mobile apps running in the Cloud expect fast feedback to problems and feature requests. Thus, it is a critical competitive advantage to be able to respond quickly. Beside cultural and organizational changes that are necessary to implement DevOps in practice, tooling is required to implement end-to-end automation of deployment processes. Automation is the key to efficient collaboration and tight integration between development and operations. The DevOps community is constantly pushing new approaches, tools, and open-source artifacts to implement such automated processes. However, as all these proprietary and heterogeneous DevOps automation approaches differ from each other, it is hard to integrate and combine them to deploy applications in the Cloud. In this paper we present a systematic classification of DevOps artifacts and show how different kinds of artifacts can be transformed toward TOSCA, an emerging standard in this field. This enables the seamless and interoperable orchestration of arbitrary artifacts to model and deploy application topologies. We validate the presented approach by a prototype implementation, show its practical feasibility by a detailed case study, and evaluate its performance.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {59–68},
numpages = {10},
keywords = {Juju, DevOps, Cloud Computing, Transformation, TOSCA, Chef, Deployment Automation, Cloud Standards},
series = {UCC '14}
}
@inproceedings{10.1145/3241815.3241818,
author = {Olagunju, Amos O.},
title = {Revamping the IT Curriculum with Agile and DevOps Methodology},
year = {2018},
isbn = {9781450359542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241815.3241818},
doi = {10.1145/3241815.3241818},
abstract = {Information technology students need to learn the concepts and tools for Agile and DevOps methodology. What are the principles of Agile and DevOps? How is Agile different from DevOps? What set of Agile and DevOps skills should student learn and how? What kinds of case-based projects should be designed to promote learning of Agile and DevOps skills? This enlightening talk discusses these and other questions. The presentation provides scripts for automating the setup of DevOps tools.},
booktitle = {Proceedings of the 19th Annual SIG Conference on Information Technology Education},
pages = {86},
numpages = {1},
keywords = {devops, it curriculum, agile},
location = {Fort Lauderdale, Florida, USA},
series = {SIGITE '18}
}
@inbook{10.1109/ICSE-SEET52601.2021.00024,
author = {Alves, Isaque and Rocha, Carla},
title = {Qualifying Software Engineers Undergraduates in DevOps - Challenges of Introducing Technical and Non-Technical Concepts in a Project-Oriented Course},
year = {2021},
isbn = {9780738133201},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEET52601.2021.00024},
abstract = {The constant changes in the software industry, practices, and methodologies impose challenges to teaching and learning current software engineering concepts and skills. DevOps is particularly challenging because it covers technical concepts, such as pipeline automation, and non-technical ones, such as team roles and project management. The present study investigates a course setup to introduce these concepts to software engineering undergraduates. We designed the course by employing coding to associate DevOps concepts to Agile, Lean, and Open source practices and tools. We present the main aspects of this project-oriented DevOps course, with 240 students enrolled it since its first offering in 2016. We conducted an empirical study, with both a quantitative and qualitative analysis, to evaluate this project-oriented course setup. We collected the data from the projects repository and students' perceptions from a questionnaire. We mined 148 repositories (corresponding to 72 projects) and obtained 86 valid responses to the questionnaire. We also mapped the concepts which are more challenging to students learn from experience. The results evidence that first-hand experience facilitates the comprehension of DevOps concepts and enriches classes discussions. we present a set of lessons learned, which may help professors better design and conduct project-oriented courses to cover DevOps concepts.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training},
pages = {144–153},
numpages = {10}
}
@inproceedings{10.1109/FIE43999.2019.9028598,
author = {Jennings, Rachel A. Kaczka and Gannod, Gerald},
title = {DevOps - Preparing Students for Professional Practice},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/FIE43999.2019.9028598},
doi = {10.1109/FIE43999.2019.9028598},
abstract = {This work in progress paper presents a course on DevOps which is a combination of software development skills and software operations skills. This new course is for sophomores and juniors in the computer science program who want to be prepared for professional software engineering careers. Introduction to DevOps Is a hands-on laboratory course that brings students through Git for source code management, Capybara for automated testing, AWS, Docker, and Ansible for automated virtual machine provisioning and configuration, and Jenkins for Continuous Integration. Unlike our current course offerings which primarily focus on the single developer context in a localized environment, this course prepares students for highly collaborative, team-based projects that use cloud resources to facilitate management of the software deployment pipeline. We developed this course based on feedback from our external advisory board and under consultation from a number of industrial partners. This is complementary to our current offerings in software engineering which focus on Agile software practices. In this paper we describe the core concepts, the design, learning experiences, technologies, and lessons learned through developing and conducting this course. In future work we hope to present student perceptions of learning and provide data collected through direct assessment of student outcomes.},
booktitle = {2019 IEEE Frontiers in Education Conference (FIE)},
pages = {1–5},
numpages = {5},
location = {Covington, KY, USA}
}
@article{10.1002/smr.1885,
author = {Erich, F. M. A. and Amrit, C. and Daneva, M.},
title = {A Qualitative Study of DevOps Usage in Practice},
year = {2017},
issue_date = {June 2017},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {29},
number = {6},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.1885},
doi = {10.1002/smr.1885},
abstract = {Organizations are introducing agile and lean software development techniques in operations to increase the pace of their software development process and to improve the quality of their software. They use the term DevOps, a portmanteau of development and operations, as an umbrella term to describe their efforts. In this paper, we describe the ways in which organizations implement DevOps and the outcomes they experience. We first summarize the results of a systematic literature review that we performed to discover what researchers have written about DevOps. We then describe the results of an exploratory interview-based study involving 6 organizations of various sizes that are active in various industries. As part of our findings, we observed that all organizations were positive about their experiences and only minor problems were encountered while adopting DevOps.},
journal = {J. Softw. Evol. Process},
month = {jun},
pages = {n/a},
keywords = {software development life cycle, DevOps, qualitative interviews, systematic literature review, empirical study, agile software development}
}
@inproceedings{10.1145/2945408.2945411,
author = {Di Nitto, Elisabetta and Jamshidi, Pooyan and Guerriero, Michele and Spais, Ilias and Tamburri, Damian A.},
title = {A Software Architecture Framework for Quality-Aware DevOps},
year = {2016},
isbn = {9781450344111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2945408.2945411},
doi = {10.1145/2945408.2945411},
abstract = {DevOps is an emerging software engineering strategy entailing the joined efforts of development and operations people, their concerns and best practices with the purpose of realising a coherent working group for increased software development and operations speed. To allow software architecture practitioners to enrich and properly elaborate their architecture specifications in a manner which is consistent with DevOps, we surveyed a number of DevOps stakeholders. We studied concerns and challenges to be tackled with respect to preparing a software architecture which is DevOps-ready, i.e., described in all details needed to enact DevOps scenarios. Subsequently, we introduce SQUID, that stands for Specification Quality In DevOps. SQUID is a software architecture framework that supports the model-based documentation of software architectures and their quality properties in DevOps scenarios with the goal of providing DevOps-ready software architecture descriptions. We illustrate our framework in a case-study in the Big Data domain.},
booktitle = {Proceedings of the 2nd International Workshop on Quality-Aware DevOps},
pages = {12–17},
numpages = {6},
keywords = {QoD, Model-Driven Design, Architecture Frameworks, QoS},
location = {Saarbr\"{u}cken, Germany},
series = {QUDOS 2016}
}
@inproceedings{10.1007/978-3-030-55583-2_19,
author = {Selgert, Franklin},
title = {Cynefin Framework, DevOps and Secure IoT: Understanding the Nature of IoT Systems and Exploring Where in the DevOps Cycle Easy Gains Can Be Made to Increase Their Security},
year = {2020},
isbn = {978-3-030-55582-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55583-2_19},
doi = {10.1007/978-3-030-55583-2_19},
abstract = {In the relatively new domain of the Internet of Things (IoT), startups and small companies thrive in and stride in bringing new products to the market. Many of them experience problems and fail to profit from their IoT innovation. A lot of those problems are security related. In IoT development, security issues are often overlooked or underestimated.This article explores, from a holistic viewpoint, how security in IoT systems can be prevented or mitigated with a minimal effort. Concepts examined are: The Cynefin framework, Business DevOps, and the role of constraints and requirements in the design phase.},
booktitle = {Computer Safety, Reliability, and Security. SAFECOMP 2020 Workshops: DECSoS 2020, DepDevOps 2020, USDAI 2020, and WAISE 2020, Lisbon, Portugal, September 15, 2020, Proceedings},
pages = {255–265},
numpages = {11},
keywords = {DevOps, SCRATCh, IoT, Cynefin, Security},
location = {Lisbon, Portugal}
}
@article{10.4018/IJSSSP.2018010102,
author = {Morales, Jose Andre and Yasar, Hasan and Volkmann, Aaron},
title = {Weaving Security into DevOps Practices in Highly Regulated Environments},
year = {2018},
issue_date = {Jan 2018},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {1},
issn = {2640-4265},
url = {https://doi.org/10.4018/IJSSSP.2018010102},
doi = {10.4018/IJSSSP.2018010102},
abstract = {In this article, the authors discuss enhancing a DevOps implementation in a highly regulated environment (HRE) with security principles. DevOps has become a standard option for entities seeking to streamline and increase participation by all stakeholders in their Software Development Lifecycle (SDLC). For a large portion of industry, academia, and government, applying DevOps is a straight forward process. There is, however, a subset of entities in these three sectors where applying DevOps can be very challenging. These are entities mandated by security policies to conduct all, or a portion, of their SDLC activities in an HRE. Often, the reason for an HRE is protection of intellectual property and proprietary tools, methods, and techniques. Even if an entity is functioning in a highly regulated environment, its SDLC can still benefit from implementing DevOps as long as the implementation conforms to all imposed policies. A benefit of an HRE is the existence of security policies that belong in a secure DevOps implementation. Layering an existing DevOps implementation with security will benefit the HRE as a whole. This work is based on the authors extensive experience in assessing and implementing DevOps across a diverse set of HREs. First, they extensively discuss the process of performing a DevOps assessment and implementation in an HRE. They follow this with a discussion of the needed security principles a DevOps enhanced SDLC should include. For each security principle, the authors discuss their importance to the SDLC and their appropriate placement within a DevOps implementation. They refer to a security enhanced DevOps implementation in an HRE as HRE-DevSecOps.},
journal = {International Journal of Systems and Software Security and Protection},
month = {jan},
pages = {18–46},
numpages = {29},
keywords = {Highly Regulated Environment, SDLC, DevOps, DevOps Assessment, Secure DevOps}
}
@inproceedings{10.1145/2898375.2898383,
author = {Ur Rahman, Akond Ashfaque and Williams, Laurie},
title = {Security Practices in DevOps},
year = {2016},
isbn = {9781450342773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2898375.2898383},
doi = {10.1145/2898375.2898383},
abstract = {DevOps focuses on collaboration between different teams in an organization to achieve rapid deployment of software and services to end-users by automating the software delivery infrastructure. According to Dyck et al. [1] DevOps is a software process that emphasizes collaboration within and between different teams involved in software development. According to a study from CA Technologies [5], 88% of 1425 organization executives stated that they have adopted DevOps, or are planning to adopt DevOps in the next five years. According to Puppet Labs' 2015 State of DevOps Report [2], organizations that have adopted DevOps experienced 60 times fewer failures and deploy 30 times more frequently than organizations that have not adopted DevOps. Despite the popularity, security aspects of DevOps remain a concern for organizations that want to adopt DevOps [5]. In organizations that use DevOps practices, developers can commit and deploy their software changes at a rapid rate using an automated pipeline. At such a rapid rate, if the security team operates in isolation without close collaboration with the development and operations teams, then the rapidly deployed software changes might not undergo the adequate security reviews, potentially leading to vulnerable software. Bringing security principles within the DevOps process can help the organization in achieving better quality of software by integrating security checks into the phases of development, testing, and deployment.},
booktitle = {Proceedings of the Symposium and Bootcamp on the Science of Security},
pages = {109–111},
numpages = {3},
location = {Pittsburgh, Pennsylvania},
series = {HotSos '16}
}
@inproceedings{10.1145/2962695.2962707,
author = {Jabbari, Ramtin and bin Ali, Nauman and Petersen, Kai and Tanveer, Binish},
title = {What is DevOps? A Systematic Mapping Study on Definitions and Practices},
year = {2016},
isbn = {9781450341349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2962695.2962707},
doi = {10.1145/2962695.2962707},
abstract = {Context: DevOps, the combination of Development and Operations, is a new way of thinking in the software engineering domain that recently received much attention. Given that DevOps is a new term and novel concept recently introduced, no common understanding of what it entails has been achieved yet. Consequently, definitions of DevOps often only represent a part that is relevant to the concept.Objective:This study aims to characterize DevOps by exploring central components of DevOps definitions reported in the literature, specifying practices explicitly proposed for DevOps and investigating the similarities and differences between DevOps and other existing methods in software engineering.Method: A systematic mapping study was conducted that used six electronic databases: IEEE, ACM, Inspec, Scopus, Wiley Online Library and Web of Science.Result: 44 studies have been selected that report a definition of DevOps, 15 studies explicitly stating DevOps practices, and 15 studies stating how DevOps is related to other existing methods. Papers in some cases stated a combination of a definition, practices, and relations to other methods, the total number of primary studies was 49.Conclusion: We proposed a definition for DevOps which may overcome inconsistencies over the various existing definitions of individual research studies. In addition, the practices explicitly proposed for DevOps have been presented as well as the relation to other software development methods.},
booktitle = {Proceedings of the Scientific Workshop Proceedings of XP2016},
articleno = {12},
numpages = {11},
keywords = {DevOps practice, Software development method, DevOps definition},
location = {Edinburgh, Scotland, UK},
series = {XP '16 Workshops}
}
@book{10.5555/3299702,
author = {Bangera, Shashikant},
title = {DevOps for Serverless Applications: Design, Deploy, and Monitor Your Serverless Applications Using DevOps Practices},
year = {2018},
isbn = {1788623444},
publisher = {Packt Publishing},
abstract = {Set up complete CI and CD pipelines for your serverless applications using DevOps principles Key Features Understand various services for designing serverless architecture Build CD pipelines using various cloud providers for your serverless applications Implement DevOps best practices when building serverless applications Book Description Serverless applications are becoming very popular among developers and are generating a buzz in the tech market. Many organizations struggle with the effective implementation of DevOps with serverless applications. DevOps for Serverless Applications takes you through different DevOps-related scenarios to give you a solid foundation in serverless deployment. You will start by understanding the concepts of serverless architecture and development, and why they are important. Then, you will get to grips with the DevOps ideology and gain an understanding of how it fits into the Serverless Framework. You'll cover deployment framework building and deployment with CI and CD pipelines for serverless applications. You will also explore log management and issue reporting in the serverless environment. In the concluding chapters, you will learn important security tips and best practices for secure pipeline management. By the end of this book, you will be in a position to effectively build a complete CI and CD delivery pipeline with log management for serverless applications. What you will learn Explore serverless fundamentals and effectively combine them with DevOps Set up CI and CD with AWS Lambda and other popular Serverless service providers with the help of the Serverless Framework Perform monitoring and logging with serverless applications Set up a dynamic dashboard for different service providers Discover best practices for applying DevOps to serverless architecture Understand use cases for different serverless architectures Who this book is for DevOps for Serverless Applications is for DevOps engineers, architects, or anyone interested in understanding the DevOps ideology in the serverless world. You will learn to use DevOps with serverless and apply continuous integration, continuous delivery, testing, logging, and monitoring with serverless.}
}
@inproceedings{10.1145/3383219.3383285,
author = {Rafi, Saima and Yu, Wu and Akbar, Muhammad Azeem},
title = {Towards a Hypothetical Framework to Secure DevOps Adoption: Grounded Theory Approach},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383285},
doi = {10.1145/3383219.3383285},
abstract = {Security in DevOps is a challenging feature because traditional existing methods of security are not fulfilling the exact requirements of DevOps. To make DevOps activities successful for organizations this study will help to identify concerns about DevOps security in real world by interviewing the practitioners having DevOps working experience. The Classical grounded theory approach has been used to build our theory. We interviewed 13 practitioners working across five companies from different regions. We contributed to identify security concerns in DevOps and try to present a theoretical model to improve understanding and guidance of DevOps adoption. The security concerns were marked as functional and nonfunctional based upon the interviews concepts to help practitioners having understanding about particular concerns. Therefore, this theory will highlight security concerns that are hindering the adoption of DevOps successfully.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {457–462},
numpages = {6},
keywords = {Classical grounded theory, Security concerns, hypothetical framework},
location = {Trondheim, Norway},
series = {EASE '20}
}
@article{10.1504/IJCSE.2012.049753,
author = {Hosono, Shigeru},
title = {A DevOps Framework to Shorten Delivery Time for Cloud Applications},
year = {2012},
issue_date = {October 2012},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {7},
number = {4},
issn = {1742-7185},
url = {https://doi.org/10.1504/IJCSE.2012.049753},
doi = {10.1504/IJCSE.2012.049753},
abstract = {This paper proposes DevOps platforms for cloud applications, integrating both the development and operation environment seamlessly. It consists of the client-side integrated development environment (IDE), and the server-side service portfolio and cloud controller. The IDE has requirement definition, architecture design and application prototyping tools, and it can simulate execution of large-scale applications in developers' PCs. The service portfolio incorporates data from these tools and enables automatic data sharing between them, thereby avoiding setback and redundancy. To deploy the applications in the cloud, the cloud controller utilises the resource structures designed in the IDE and generates virtual machines (VMs) from templates, in which a verified OS and middleware for large-scale data processing are packaged. The behaviour of applications and VMs will be automatically monitored and catalogued as feedbacks for the developers. With these comprehensive approaches, the system integration methods can be streamlined and the acceleration of development can be easily demonstrated.},
journal = {Int. J. Comput. Sci. Eng.},
month = {oct},
pages = {329–344},
numpages = {16}
}
@inproceedings{10.1007/978-3-030-39306-9_10,
author = {Bordeleau, Francis and Cabot, Jordi and Dingel, Juergen and Rabil, Bassem S. and Renaud, Patrick},
title = {Towards Modeling Framework for DevOps: Requirements Derived from Industry Use Case},
year = {2019},
isbn = {978-3-030-39305-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39306-9_10},
doi = {10.1007/978-3-030-39306-9_10},
abstract = {To succeed with the development, deployment, and operation of the new generation of complex systems, organizations need the agility to adapt to constantly evolving environments. In this context, DevOps has emerged as an evolution of the agile approaches. It focuses on optimizing the flow of activities involved in the creation of end-user value, from idea to deployed functionality and operating systems. However, in spite of its popularity, DevOps still lacks proper engineering frameworks to support continuous improvement. One of our key objectives is to contribute to the development of a DevOps engineering framework composed of process, methods, and tools. A core part of this framework relates to the modeling of the different aspects of the DevOps system. To better understand the requirements of modeling in a DevOps context, we focus on a Product Build use case provided by an industry partner.},
booktitle = {Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Ch\^{a}teau de Villebrumier, France, May 6–8, 2019, Revised Selected Papers},
pages = {139–151},
numpages = {13},
keywords = {Modeling, Process, DevOps},
location = {Villebrumier, France}
}
@inproceedings{10.1145/3234152.3234188,
author = {Morales, Jose Andre and Yasar, Hasan and Volkman, Aaron},
title = {Implementing DevOps Practices in Highly Regulated Environments},
year = {2018},
isbn = {9781450364225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234152.3234188},
doi = {10.1145/3234152.3234188},
abstract = {In this paper, we discuss implementing DevOps practices in highly regulated environments (HREs). DevOps has become a standard option for entities seeking to streamline and increase participation by all stakeholders in their Software Development Lifecycle (SDLC). For a large portion of industry, academia, and government, applying DevOps is a straight forward process. There is, however, a subset of entities in these three sectors where applying DevOps can be very challenging. These are entities mandated by policies to conduct all or a portion of their SDLC activities in HREs. Often, the reason for an HRE is general security and protection of intellectual property. Even if an entity is functioning in a highly regulated environment, its SDLC can still benefit from implementing DevOps as long as the implementation conforms to all imposed policies. In this paper, we discuss the process of performing a DevOps assessment and implementation in an HRE which we refer to as HRE-DevOps.},
booktitle = {Proceedings of the 19th International Conference on Agile Software Development: Companion},
articleno = {4},
numpages = {9},
keywords = {highly regulated environment, DevOps assessment, secure DevOps, SDLC, DevOps},
location = {Porto, Portugal},
series = {XP '18}
}
@article{10.1016/j.future.2015.07.017,
author = {Wettinger, Johannes and Breitenb\"{u}cher, Uwe and Kopp, Oliver and Leymann, Frank},
title = {Streamlining DevOps Automation for Cloud Applications Using TOSCA as Standardized Metamodel},
year = {2016},
issue_date = {March 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {56},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2015.07.017},
doi = {10.1016/j.future.2015.07.017},
abstract = {DevOps as an emerging paradigm aims to tightly integrate developers with operations personnel. This enables fast and frequent releases in the sense of continuously delivering new iterations of a particular application. Users and customers of today's Web applications and mobile apps running in the Cloud expect fast feedback to problems and feature requests. Thus, it is a critical competitive advantage to be able to respond quickly. Besides cultural and organizational changes that are necessary to apply DevOps in practice, tooling is required to implement end-to-end automation of deployment processes. Automation is the key to efficient collaboration and tight integration between development and operations. The DevOps community is constantly pushing new approaches, tools, and open-source artifacts to implement such automated processes. However, as all these proprietary and heterogeneous DevOps automation approaches differ from each other, it is hard to integrate and combine them to deploy applications in the Cloud using an automated deployment process. In this paper we present a systematic classification of DevOps artifacts and show how different kinds of artifacts can be discovered and transformed toward TOSCA, which is an emerging standard. We present an integrated modeling and runtime framework to enable the seamless and interoperable integration of different approaches to model and deploy application topologies. The framework is implemented by an open-source, end-to-end toolchain. Moreover, we validate and evaluate the presented approach to show its practical feasibility based on a detailed case study, in particular considering the performance of the transformation toward TOSCA. Classification of DevOps artifacts and their usage.Integrated, standards-driven modeling &amp; runtime framework based on TOSCA.Discovery, transformation, and APIfication of DevOps artifacts.Enrichment and deployment of application topologies.Evaluation of artifact transformation and comprehensive case study.},
journal = {Future Gener. Comput. Syst.},
month = {mar},
pages = {317–332},
numpages = {16},
keywords = {Cloud standards, Cloud computing, DevOps, Transformation, Deployment automation, TOSCA}
}
@inproceedings{10.1109/SYNASC.2015.60,
author = {Guerriero, Michele and Ciavotta, Michele and Gibilisco, Giovanni Paolo and Ardagna, Danilo},
title = {A Model-Driven DevOps Framework for QoS-Aware Cloud Applications},
year = {2015},
isbn = {9781509004614},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SYNASC.2015.60},
doi = {10.1109/SYNASC.2015.60},
abstract = {Recently we witnessed a deep transformation in the the design, development and management of modern applications, which have grown in scope and size becoming distributed and service-oriented. A big part in this metamorphosis is played by the Cloud with the availability of almost-infinite resources, high availability and outsourced maintenance. This has led to the emergence of new software development methodologies to effectively deal with this paradigm shift in the field of software engineering. DevOps is one of them, it advocates for a greater level of collaboration and convergence between developers and other IT professionals. Consequently, new tools, purposely designed to ease this process, are required. In this scenario, we present SPACE4Cloud, a DevOps integrated environment for model-driven design-time quality of service assessment and optimization, and runtime capacity allocation of Cloud applications.},
booktitle = {Proceedings of the 2015 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)},
pages = {345–351},
numpages = {7},
series = {SYNASC '15}
}
@inproceedings{10.1145/3210459.3210465,
author = {Senapathi, Mali and Buchan, Jim and Osman, Hady},
title = {DevOps Capabilities, Practices, and Challenges: Insights from a Case Study},
year = {2018},
isbn = {9781450364034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210459.3210465},
doi = {10.1145/3210459.3210465},
abstract = {DevOps is a set of principles and practices to improve collaboration between development and IT Operations. Against the backdrop of the growing adoption of DevOps in a variety of software development domains, this paper describes empirical research into factors influencing its implementation. It presents findings of an in-depth exploratory case study that explored DevOps implementation in a New Zealand product development organisation. The study involved interviewing six experienced software engineers who continuously monitored and reflected on the gradual implementation of DevOps principles and practices. For this case study the use of DevOps practices led to significant benefits, including increase in deployment frequency from about 30 releases a month to an average of 120 releases per month, as well as improved natural communication and collaboration between IT development and operations personnel. We found that the support of a number of technological enablers, such as implementing an automation pipeline and cross functional organisational structures, were critical to delivering the expected benefits of DevOps.},
booktitle = {Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018},
pages = {57–67},
numpages = {11},
keywords = {DevOps benefits and challenges, DevOps enablers and practices},
location = {Christchurch, New Zealand},
series = {EASE'18}
}
@inproceedings{10.1109/NOMS.2018.8406139,
author = {Soenen, Thomas and Van Rossem, Steven and Tavernier, Wouter and Vicens, Felipe and Valocchi, Dario and Trakadas, Panos and Karkazis, Panos and Xilouris, George and Eardley, Philip and Kolometsos, Stavros and Kourtis, Michail-Alexandros and Guija, Daniel and Siddiqui, Shuaib and Hasselmeyer, Peer and Bonnet, Jos\`{e} and Lopez, Diego},
title = {Insights from SONATA: Implementing and Integrating a Microservice-Based NFV Service Platform with a DevOps Methodology},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/NOMS.2018.8406139},
doi = {10.1109/NOMS.2018.8406139},
abstract = {In pursuit of a flexible, resource efficient and high- performant 5G infrastructure, many operators, vendors and research consortia are currently developing, testing and inte­grating their NFV platform with associated management and orchestration (MANO) functionality. The SONATA NFV platform follows a micro-service design, which involves a tight coupling between an SDK, monitoring and MANO functionality, targeting a secure and stable software foundation. This experience paper gives a thorough overview on the encountered challenges, insights and resulting learnings when implementing and integrating the SONATA Service Platform using a continuous integration and delivery DevOps methodology. This is the result of a strong cooperation between prominent equipment vendors, network operators, software companies and universities, providing a set of constructive recommendations in hope of catalysing the development and deployment of NFV platforms.},
booktitle = {NOMS 2018 - 2018 IEEE/IFIP Network Operations and Management Symposium},
pages = {1–6},
numpages = {6},
location = {Taipei, Taiwan}
}
@inproceedings{10.1145/3427921.3450235,
author = {Rouf, Yar and Mukherjee, Joydeep and Litoiu, Marin and Wigglesworth, Joe and Mateescu, Radu},
title = {A Framework for Developing DevOps Operation Automation in Clouds Using Components-off-the-Shelf},
year = {2021},
isbn = {9781450381949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427921.3450235},
doi = {10.1145/3427921.3450235},
abstract = {DevOps is an emerging paradigm that integrates the development and operations teams to enable fast and efficient continuous delivery of software. Applications and services deployed on cloud platforms can benefit from implementing the DevOps practice. This involves using different tools for enabling end-to-end automation to ensure continuous deployment and maintain good Quality-of-Service. Self-Adaptive systems can support the DevOps process by automating service deployment and maintenance without manual intervention by employing a MAPE-K (Monitoring, Analysis, Planning, Execution- Knowledge) framework. While industrial MAPE-K tools are robust and built for production environments, they lack the flexibility to adapt large applications on multi-cloud environments. Academic models are more flexible and can be used to perform sophisticated self-adaption, but can lack the robustness to be used in production environments. In this paper, we present a MAPE-K framework that is built with existing Components-off-the-Shelf (COTS) that interacts with each other to perform self-adaptive actions on multi-cloud environments. By integrating existing COTS, we are able to deploy a MAPE-K framework efficiently to support DevOps for applications running on a multi-cloud environment. We validate our framework with a prototype implementation and demonstrate its practical feasibility by a detailed case study done on a real industrial platform.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {265–276},
numpages = {12},
keywords = {self-adaptive, components-off-the-shelf, DevOps, hybrid cloud, autonomous systems, multicloud, cloud},
location = {Virtual Event, France},
series = {ICPE '21}
}
@book{10.5555/2431374,
author = {Rankin, Kyle},
title = {DevOps Troubleshooting: Linux Server Best Practices},
year = {2012},
isbn = {0321832043},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {If youre a developer trying to figure out why your application is not responding at 3 am, you need this book! This is now my go-to book when diagnosing production issues. It has saved me hours in troubleshooting complicated operations problems. Trotter Cashion, cofounder, Mashion DevOps can help developers, QAs, and admins work together to solve Linux server problems far more rapidly, significantly improving IT performance, availability, and efficiency. To gain these benefits, however, team members need common troubleshooting skills and practices. In DevOps Troubleshooting: Linux Server Best Practices , award-winning Linux expert Kyle Rankin brings together all the standardized, repeatable techniques your team needs to stop finger-pointing, collaborate effectively, and quickly solve virtually any Linux server problem. Rankin walks you through using DevOps techniques to troubleshoot everything from boot failures and corrupt disks to lost email and downed websites. Youll master indispensable skills for diagnosing high-load systems and network problems in production environments. Rankin shows how to Master DevOps approach to troubleshooting and proven Linux server problem-solving principles Diagnose slow servers and applications by identifying CPU, RAM, and Disk I/O bottlenecks Understand healthy boots, so you can identify failure points and fix them Solve full or corrupt disk issues that prevent disk writes Track down the sources of network problems Troubleshoot DNS, email, and other network services Isolate and diagnose Apache and Nginx Web server failures and slowdowns Solve problems with MySQL and Postgres database servers and queries Identify hardware failureseven notoriously elusive intermittent failures}
}
@article{10.4018/IJSSE.2016100103,
author = {Yasar, Hasan and Kontostathis, Kiriakos},
title = {Where to Integrate Security Practices on DevOps Platform},
year = {2016},
issue_date = {October 2016},
publisher = {IGI Global},
address = {USA},
volume = {7},
number = {4},
issn = {1947-3036},
url = {https://doi.org/10.4018/IJSSE.2016100103},
doi = {10.4018/IJSSE.2016100103},
abstract = {"Software security" often evokes negative feelings amongst software developers because this term is associated with additional programming effort, uncertainty and road blocker activity on rapid development and release cycles. The Secure DevOps movement attempts to combat the toxic environment surrounding software security by shifting the paradigm from following rules and guidelines to creatively determining solutions for tough security problems Taschner, 2015. Secure software should be focused on a proactive approach that limits the attack surface and produces reliable software. Secure DevOps developers want their software to bend but not break, which means the software absorbs attacks and continues to function. The burgeoning concepts of DevOps include a number of concepts that can be applied to increase the security of developed applications. Applying these and other DevOps principles can have a big impact on creating an environment that is resilient and secure. Specifically, this paper clearly explains how to address security concerns in the early stages of the development lifecycle and leverage that knowledge throughout the SDLC.},
journal = {Int. J. Secur. Softw. Eng.},
month = {oct},
pages = {39–50},
numpages = {12},
keywords = {Software Security, Secure Software Development Life Cycle, Software Development Life Cycle, Secure DevOps}
}
@inproceedings{10.1007/978-3-030-33702-5_12,
author = {Johng, Haan and Kalia, Anup K. and Xiao, Jin and Vukovi\'{c}, Maja and Chung, Lawrence},
title = {Harmonia: A Continuous Service Monitoring Framework Using DevOps and Service Mesh in a Complementary Manner},
year = {2019},
isbn = {978-3-030-33701-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33702-5_12},
doi = {10.1007/978-3-030-33702-5_12},
abstract = {Software teams today are required to deliver new or updated services frequently, rapidly and independently. Adopting DevOps and Microservices support the rapid service delivery model but leads to pushing code or service infrastructure changes across inter-dependent teams that are not collectively assessed, verified, or notified. In this paper, we propose Harmonia - a continuous service monitoring framework utilizing DevOps and Service Mesh in a complementary manner to improve coordination and change management among independent teams. Harmonia can automatically detect changes in services, including changes that violate performance SLAs and user experience, notify the changes to affected teams, and help them resolve the changes quickly. We applied Harmonia to a standard application in describing Microservice management to assist with an initial understanding and strengths of Harmonia. During the demonstration, we deployed faulty and normal services alternatively and captured changes from Jenkins, Github, Istio, and Kubernetes logs to form an application-centric cohesive view of the change and its impact and notify the affected teams.},
booktitle = {Service-Oriented Computing: 17th International Conference, ICSOC 2019, Toulouse, France, October 28–31, 2019, Proceedings},
pages = {151–168},
numpages = {18},
keywords = {Microservice, Monitoring, DevOps, Service Mesh, Enterprise Cloud Management},
location = {Toulouse, France}
}
@article{10.5555/2502864.2502869,
author = {Ragan, Tracy},
title = {21st-Century DevOps--an End to the 20th-Century Practice of Writing Static Build and Deploy Scripts},
year = {2013},
issue_date = {June 2013},
publisher = {Belltown Media},
address = {Houston, TX},
volume = {2013},
number = {230},
issn = {1075-3583},
abstract = {Embracing 21st-century DevOps means letting go of 20th-century practices.},
journal = {Linux J.},
month = {jun},
articleno = {5}
}
@inbook{10.1145/3484399.3484401,
author = {Meedeniya, Dulani and Thennakoon, Harshanika},
title = {Impact Factors and Best Practices to Improve Effort Estimation Strategies and Practices in DevOps},
year = {2021},
isbn = {9781450390194},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3484399.3484401},
abstract = {Effort estimation plays an important role in the software development process by supporting the decision-making process for the stakeholders. DevOps has become a widely used software engineering practice with the collaboration of the development and operational teams. This paper addresses the factors that affect the effort estimation strategies and practices in DevOps based software development in Sri Lanka. This study explains the research approach, generation of the conceptual model and the quantitative data analysis process in detail. A survey is conducted among the software professionals who are working in DevOps-based software development in the Sri Lanka IT industry and a detailed data analysis is performed using statistical techniques to identify the reliability, correlation and significance of the considered factors. With an extensive analysis the independent variables namely, exploration, communication, and technology stack are identified as highly impacted factors to the effort estimation in DevOps-based software development. We also provide recommendations for the effort estimation strategies and practices; hence the managerial decision can be made for the improvements of the development process.},
booktitle = {2021 The 11th International Conference on Information Communication and Management},
pages = {11–17},
numpages = {7}
}
@inproceedings{10.1109/ICSE-Companion.2019.00080,
author = {Chen, Boyuan},
title = {Improving the Software Logging Practices in DevOps},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion.2019.00080},
doi = {10.1109/ICSE-Companion.2019.00080},
abstract = {DevOps refers to a set of practices dedicated to accelerating modern software engineering process. It breaks the barriers between software development and IT operations and aims to produce and maintain high quality software systems. Software logging is widely used in DevOps. However, there are few guidelines and tool support for composing high quality logging code and current application context of log analysis is very limited with respect to feedback for developers and correlations among other telemetry data. This thesis proposes automated approaches to improving software logging practices in DevOps by leveraging various types of software repositories (e.g., historical, communication, bug, and runtime repositories). We aim to support the software development side by providing guidelines and tools on developing and maintaining high quality logging code. We aim to support the IT operation side by enriching the log analysis context through systematic estimating code coverage via executing logs and in-depth problem diagnosis by correlating logs with other telemetry data (e.g., traces and APM data). Case studies show that our approaches can provide useful software logging suggestions to both developers and operators in open source and commercial systems.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings},
pages = {194–197},
numpages = {4},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}
@inproceedings{10.1145/3194760.3194763,
author = {D\"{u}llmann, Thomas F. and Paule, Christina and van Hoorn, Andr\'{e}},
title = {Exploiting Devops Practices for Dependable and Secure Continuous Delivery Pipelines},
year = {2018},
isbn = {9781450357456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194760.3194763},
doi = {10.1145/3194760.3194763},
abstract = {Continuous delivery (CD) pipelines recently gained wide adoption. They provide means for short and high-frequent development cycles in DevOps by automating many steps after a commit has been issued and bringing it into production. CD pipelines have become essential for development and delivery. Hence, they are crucial and business-critical assets that need to be protected from harm in terms of dependability and security. DevOps practices like canary releasing and A/B testing aim to improve the quality of the software that is built by CD pipelines while keeping a high pace of development. Although CD is a part of DevOps, the DevOps practices have primarily been applied to the artifacts that are processed but not on the pipelines themselves. We outline our vision of using these DevOps practices to improve the dependability and security of CD pipelines. The goal is to detect, diagnose, and resolve dependability and security issues in the CD pipeline behavior. In this paper, we outline our envisioned roadmap and preliminary results from an ongoing industrial case study.},
booktitle = {Proceedings of the 4th International Workshop on Rapid Continuous Software Engineering},
pages = {27–30},
numpages = {4},
location = {Gothenburg, Sweden},
series = {RCoSE '18}
}
@inproceedings{10.5555/3291291.3291319,
author = {Beigi-Mohammadi, Nasim and Litoiu, Marin and Emami-Taba, Mahsa and Tahvildari, Ladan and Fokaefs, Marios and Merlo, Ettore and Onut, Iosif Viorel},
title = {A DevOps Framework for Quality-Driven Self-Protection in Web Software Systems},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {Modern software is developed, deployed and operates continuously. At the same time, cyberattacks are on the rise. The continuity of development and operations and the constant threat of attacks requires novel approaches to identify, analyze and address potential security vulnerabilities. In this continuous and volatile execution environment, factors like security, performance, cost and functionality may not be able to be guaranteed in the same degree at the same time. In this work, we propose a DevOps framework for security adaptation that enables the development and operations teams to collaborate and address security vulnerabilities. The proposed framework spans across the different phases of software (development, operations, maintenance) and considers all other factors (performance, cost, functionality), when deciding for security adaptations. We demonstrate the approach on a prototype tool that shows how teams work together to tackle security concerns.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {270–274},
numpages = {5},
keywords = {self-adaptive systems, self-protection, security, devops, web software, software defined infrastructure},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}
@book{10.5555/3035845,
author = {Rangel, Derek},
title = {DevOps: Learn One of the Most Powerful Software Development Methodologies FAST AND EASY!},
year = {2016},
isbn = {1532738048},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
abstract = {DevOps Learn One of the Most Powerful Software Development Methodologies FAST AND EASY! This book is an exploration of DevOps (Developer Operations). It begins by explaining what DevOps is, how it is used, and why it was introduced. The next step is a guide on how one can set up TomEE from Puppet. The Puppet and Packer immutable servers are also explored, and thus you will know how to work with them after reading this book. The book will guide you on how to set up a modern web stack in Ubuntu, which is a distribution of the Linux operating system. With the advancement in technology, users now liketo use databases which are more advanced for their applications. Note that each of the web applications developed has a database. With DynamoDB, the administration overhead is greatly reduced. This book will guide you on how to shift your database from MongoDB to DynamoDB. The process of performing operations on tree structures in MongoDB is also discussed in detail, enabling you to operate on different types of tree structures. You will also learn how to configure your Apache for multiple domains. Reverse cache proxy, which is a very nice feature in Nginx is presented in detail, instructing you on how to work with it. The process of using Nginx in a web application is further explored. Here is a preview of what you'll learn: Definition Installation of TomEE from Puppet Puppet and Packer Immutable Servers How to set up a modern web stack in Ubuntu Migration of MongoDB to DynamoDB MongoDB and Tree Structures Configuration of Apache for Multiple Domains Reverse Cache Proxy in Nginx Setting Up LAMP on Ubuntu hosted on AWS Using Nginx with a Web Application Download your copy of " DevOps " by scrolling up and clicking "Buy Now With 1-Click" button.}
}
@article{10.5555/3282588.3282614,
author = {Bennett, Brian T. and Barrett, Martin L.},
title = {Incorporating Devops into Undergraduate Software Engineering Courses: A Suggested Framework},
year = {2018},
issue_date = {December 2018},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {34},
number = {2},
issn = {1937-4771},
abstract = {DevOps is a current trend for application development and delivery in the industry. Teaching about DevOps in an undergraduate software engineering course is difficult because the number of new concepts involved is high, and most students lack experience with them. This paper presents our initial experience integrating DevOps into undergraduate software engineering coursework. It discusses DevOps itself and introduces a basic framework for introducing DevOps into a software engineering sequence. Finally, we discuss how we currently approach DevOps instruction and where we need to go to fit within the suggested framework.},
journal = {J. Comput. Sci. Coll.},
month = {dec},
pages = {180–187},
numpages = {8}
}
@book{10.5555/3383485,
author = {Davis, Andrew},
title = {Mastering Salesforce DevOps: A Practical Guide to Building Trust While Delivering Innovation},
year = {2019},
isbn = {1484254724},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {This practical guide brings DevOps principles to Salesforce development. It fits together two major movements within the IT world: the movement to Software/Platform as a Service (SaaS/PaaS), and the DevOps movement. While SaaS and PaaS allow companies to invest in their core competencies rather than maintain their own infrastructure, the goal of DevOps is to optimize the process of delivering software innovation and value. The release of Salesforce DX in late 2017 unlocks the possibility of a true DevOps workflow on Salesforce. But DevOps is new to the Salesforce world and there is not a widespread understanding of its goals and methods, and so adoption of Salesforce DX is still in the early stages. Mastering Salesforce DevOps explains how to build a powerful and comprehensive DevOps workflow for Salesforce-allowing you to finally deploy the world's most innovative platform using the world's most effective and efficient techniques. It addresses the need for a comprehensive guide to DevOps for Salesforce, allowing teams to bring proven practices from the IT world to resolve the hardest problems facing Salesforce developers today. What You Will Learn Improve company performance and software delivery performance using Salesforce DX Translate DevOps concepts into the unique language and practices of Salesforce Understand why and how you can implement Salesforce DX to achieve greater productivity and innovation Enable continuous delivery on Salesforce Build packages and architect code so it can be deployed easily Allow admins to participate in what has traditionally been a developer workflow Know the techniques for reducing the stress and risk of deployment Apply the full range of automated tests that can be used on Salesforce Who This Book Is for Salesforce developers, release managers, and those managing Salesforce development teams who need a guide to DevOps, and DevOps specialists who need to apply familiar concepts to Salesforce}
}
@book{10.5555/3317223,
author = {Kaiser, Abhinav Krishna},
title = {Reinventing ITIL in the Age of DevOps: Innovative Techniques to Make Processes Agile and Relevant},
year = {2018},
isbn = {148423975X},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Delve into the principles of ITIL and DevOps and examine the similarities and differences. This book re-engineers the ITIL framework to work in DevOps projects without changing its meaning and its original objectives, making it fit for purpose for use in DevOps projects. Reinventing ITILin the Age of DevOpsshows you the relevance of ITIL since the emergence of DevOps and puts a unique spin on the ITIL service management framework. Along the way you will see that ITIL is a mature service management framework and years of maturity will be lost if its made invalid. The ideas, recommendations, and solutions provided in Reinventing ITIL in the Age of DevOps can be leveraged in order to readily develop solutions or create proposals for clients. The ideas in this book can be further expanded to deliver seamless services to DevOps projects. What You Will Learn Discover the basics of ITIL and DevOps Compare ITIL and DevOps Understand the structure of a DevOps organization and adapt the ITIL roles to this structure Re-engineer ITIL for DevOps projects Implement major processes such as incident management, configuration management, and change management processes in DevOps projects Automate activities within processes Who This Book Is For Consultants, business analysts, administrators, and project managers who are looking for more information about Dynamics 365.}
}
@inproceedings{10.1145/2993318.2993351,
author = {Meissner, Roy and Junghanns, Kurt},
title = {Using DevOps Principles to Continuously Monitor RDF Data Quality},
year = {2016},
isbn = {9781450347525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993318.2993351},
doi = {10.1145/2993318.2993351},
abstract = {One approach to continuously achieve a certain data quality level is to use an integration pipeline that continuously checks and monitors the quality of a data set according to defined metrics. This approach is inspired by Continuous Integration pipelines, that have been introduced in the area of software development and DevOps to perform continuous source code checks. By investigating in possible tools to use and discussing the specific requirements for RDF data sets, an integration pipeline is derived that joins current approaches of the areas of software-development and semantic-web as well as reuses existing tools. As these tools have not been built explicitly for CI usage, we evaluate their usability and propose possible workarounds and improvements. Furthermore, a real-world usage scenario is discussed, outlining the benefit of the usage of such a pipeline.},
booktitle = {Proceedings of the 12th International Conference on Semantic Systems},
pages = {189–192},
numpages = {4},
keywords = {Continuous Integration, Data Quality, Data Integration, Quality Monitoring, DevOps, RDF, Instant Feedback},
location = {Leipzig, Germany},
series = {SEMANTiCS 2016}
}
@inproceedings{10.1145/3236024.3275528,
author = {Debroy, Vidroha and Miller, Senecca and Brimble, Lance},
title = {Building Lean Continuous Integration and Delivery Pipelines by Applying DevOps Principles: A Case Study at Varidesk},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3275528},
doi = {10.1145/3236024.3275528},
abstract = {Continuous Integration (CI) and Continuous Delivery (CD) are widely considered to be best practices in software development. Studies have shown however, that adopting these practices can be challenging and there are many barriers that engineers may face, such as – overly long build times, lack of support for desired workflows, issues with configuration, etc. At Varidesk, we recently began shifting our primary web application (from a monolithic) to a micro-services-based architecture and also adapted our software development practices to aim for more effective CI/CD. In doing so, we also ran into some of the same afore-mentioned barriers. In this paper we focus on two specific challenges that we faced – long wait times for builds/releases to be queued and completed, and the lack of support for tooling, especially from a cross-cloud perspective. We then present the solutions that we came up with, which involved re-thinking DevOps as it applied to us, and re-building our own CI/CD pipelines based on DevOps-supporting approaches such as containerization, infrastructure-as-code, and orchestration. Our re-designed pipelines have led us to see speed increases, in terms of total build/release time, in the range of 330x-1110x and have enabled us to seamlessly move from a single-cloud to a multi- cloud environment, with no architectural changes to any apps.},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {851–856},
numpages = {6},
keywords = {Software Build, Software Release, Continuous Delivery, Continuous Deployment, Continuous Integration, DevOps},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}
@inproceedings{10.1007/978-3-030-50578-3_34,
author = {Kousa, Jami and Ihantola, Petri and Hellas, Arto and Luukkainen, Matti},
title = {Teaching Container-Based DevOps Practices},
year = {2020},
isbn = {978-3-030-50577-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-50578-3_34},
doi = {10.1007/978-3-030-50578-3_34},
abstract = {We present the design of a online course that focuses on container-based virtualization as part of the DevOps toolchain. In addition, we outline the professional background of participants taking the course, and describe how this affects perceived previous knowledge of DevOps. We found out that the self-evaluated conceptual understanding of DevOps topics is nearly equal regardless of the participants professional identity (e.g., student or developer). However, there are significant differences in how much participants have used tools like Docker before. We conclude that there is a clear need for lifelong learning among software engineering professionals as (future) developers often struggle in operations related skills such as command line or networking.},
booktitle = {Web Engineering: 20th International Conference, ICWE 2020, Helsinki, Finland, June 9–12, 2020, Proceedings},
pages = {494–502},
numpages = {9},
keywords = {Education, Lifelong learning, DevOps},
location = {Helsinki, Finland}
}
@inproceedings{10.1145/2896941.2896946,
author = {Ur Rahman, Akond Ashfaque and Williams, Laurie},
title = {Software Security in DevOps: Synthesizing Practitioners' Perceptions and Practices},
year = {2016},
isbn = {9781450341578},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896941.2896946},
doi = {10.1145/2896941.2896946},
abstract = {In organizations that use DevOps practices, software changes can be deployed as fast as 500 times or more per day. Without adequate involvement of the security team, rapidly deployed software changes are more likely to contain vulnerabilities due to lack of adequate reviews. The goal of this paper is to aid software practitioners in integrating security and DevOps by summarizing experiences in utilizing security practices in a DevOps environment. We analyzed a selected set of Internet artifacts and surveyed representatives of nine organizations that are using DevOps to systematically explore experiences in utilizing security practices. We observe that the majority of the software practitioners have expressed the potential of common DevOps activities, such as automated monitoring, to improve the security of a system. Furthermore, organizations that integrate DevOps and security utilize additional security activities, such as security requirements analysis and performing security configurations. Additionally, these teams also have established collaboration between the security team and the development and operations teams.},
booktitle = {Proceedings of the International Workshop on Continuous Software Evolution and Delivery},
pages = {70–76},
numpages = {7},
keywords = {survey, DevOps, security, software practices},
location = {Austin, Texas},
series = {CSED '16}
}
@book{10.5555/3239984,
author = {Hering, Mirco},
title = {DevOps For The Modern Enterprise: Winning Practices to Transform Legacy IT Organizations},
year = {2018},
isbn = {1942788193},
publisher = {IT Revolution Press},
edition = {1st},
abstract = {Many organizations are facing the uphill battle of modernizing their legacy IT infrastructure. Most have evolved over the years by taking lessons from traditional or legacy manufacturing: creating a production process that puts the emphasis on the process instead of the people performing the tasks, allowing the organization to treat people like resources to try to achieve high-quality outcomes. But those practices and ideas are failing modern IT, where collaboration and creativeness are required to achieve high-performing, high-quality success. Mirco Hering, a thought leader in managing IT within legacy organizations, lays out a roadmap to success for IT managers, showing them how to create the right ecosystem, how to empower people to bring their best to work every day, and how to put the right technology in the driver's seat to propel their organization to success. But just having the right methods and tools will not magically transform an organization; the cultural change that is the hardest is also the most impactful. Using principles from Agile, Lean, and DevOps as well as first-hand examples from the enterprise world, Hering addresses the different challenges that legacy organizations face as they transform into modern IT departments.}
}
@article{10.1145/2524713.2524721,
author = {Roche, James},
title = {Adopting DevOps Practices in Quality Assurance},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/2524713.2524721},
doi = {10.1145/2524713.2524721},
abstract = {Merging the art and science of software development.},
journal = {Commun. ACM},
month = {nov},
pages = {38–43},
numpages = {6}
}
@inproceedings{10.1109/EWSDN.2015.62,
author = {John, Wolfgang and Meirosu, Catalin and Pechenot, Bertrand and Sk\"{o}ldstr\"{o}m, Pontus and Kreuger, Per and Steinert, Rebecca},
title = {Scalable Software Defined Monitoring for Service Provider DevOps},
year = {2015},
isbn = {9781509001804},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/EWSDN.2015.62},
doi = {10.1109/EWSDN.2015.62},
abstract = {Technology trends such as Cloud, SDN, and NFV are transforming the telecommunications business, promising higher service flexibility and faster deployment times. They also allow for increased programmability of the infrastructure layers. We propose to split selected monitoring control functionality onto node-local control planes, thereby taking advantage of processing capabilities on programmable nodes. Our software defined monitoring approach provides telecom operators with a way to handle the trade off between high-granular monitoring information versus network and computation loads at central control and management layers. To illustrate the concept, a link rate monitoring function is implemented using node-local control plane components. Furthermore, we introduce a messaging bus for simple and flexible communication between monitoring function components as well as control and management systems. We investigate scalability gains with a numerical analysis, demonstrating that our approach would generate thousand fold less monitoring traffic while providing similar information granularity as a naive SNMP implementation or an Open Flow approach.},
booktitle = {Proceedings of the 2015 Fourth European Workshop on Software Defined Networks},
pages = {61–66},
numpages = {6},
keywords = {management, scalability, SDN, monitoring, NFV},
series = {EWSDN '15}
}
@inproceedings{10.1007/978-3-030-55583-2_20,
author = {Duque Anton, Simon D. and Fraunholz, Daniel and Krohmer, Daniel and Reti, Daniel and Schotten, Hans D. and Selgert, Franklin and Marosv\"{o}lgyi, Marcell and Larsen, Morten and Sudhakar, Krishna and Koch, Tobias and Witt, Till and Bassem, C\'{e}dric},
title = {Creating It from SCRATCh: A Practical Approach for Enhancing the Security of IoT-Systems in a DevOps-Enabled Software Development Environment},
year = {2020},
isbn = {978-3-030-55582-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55583-2_20},
doi = {10.1007/978-3-030-55583-2_20},
abstract = {DevOps describes a method to reorganize the way different disciplines in software engineering work together to speed up software delivery. However, the introduction of DevOps-methods to organisations is a complex task. A successful introduction results in a set of structured process descriptions. Despite the structure, this process leaves margin for error: Especially security issues are addressed in individual stages, without consideration of the interdependence. Furthermore, applying DevOps-methods to distributed entities, such as the Internet of Things (IoT) is difficult as the architecture is tailormade for desktop and cloud resources. In this work, an overview of tooling employed in the stages of DevOps processes is introduced. Gaps in terms of security or applicability to the IoT are derived. Based on these gaps, solutions that are being developed in the course of the research project SCRATCh are presented and discussed in terms of benefit to DevOps-environments.},
booktitle = {Computer Safety, Reliability, and Security. SAFECOMP 2020 Workshops: DECSoS 2020, DepDevOps 2020, USDAI 2020, and WAISE 2020, Lisbon, Portugal, September 15, 2020, Proceedings},
pages = {266–281},
numpages = {16},
keywords = {Cyber security, IoT, DevOps},
location = {Lisbon, Portugal}
}
@inproceedings{10.1109/MILCOM.2014.54,
author = {Farroha, B. S. and Farroha, D. L.},
title = {A Framework for Managing Mission Needs, Compliance, and Trust in the DevOps Environment},
year = {2014},
isbn = {9781479967704},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MILCOM.2014.54},
doi = {10.1109/MILCOM.2014.54},
abstract = {The expanding pace of business competitiveness and increasing demand velocity for developing and deploying updated Operational and Security capabilities has created an environment where development and operations needed to work even closer together. The need was further enhanced due to the fact that all capabilities are being developed in a shared platform with no formal requirement processes, and no analysis of the overall enterprise capabilities and architecture. On the surface, the process lacks the usual discipline that most engineers are used to, but operationally it has the potential of bringing capabilities to operations at a quicker rate. The goal of providing continuously updated services should make sure that the overall enterprise performance and security posture are not compromised while the quick turnaround capability deployment is achieved. The proposed framework focuses on ensuring the continuity of strategic posturing while allowing maximum flexibility to tactical enhancements to meet emerging demands.},
booktitle = {Proceedings of the 2014 IEEE Military Communications Conference},
pages = {288–293},
numpages = {6},
series = {MILCOM '14}
}
author = {Helmke, Matthew},
title = {Ubuntu Unleashed 2015 Edition: Covering 14.10 and 15.04},
year = {2014},
isbn = {0672338378},
publisher = {Sams publishing},
edition = {10th},
abstract = {Ubuntu Unleashed 2015 Edition is filled with unique and advanced information for everyone who wants to make the most of the Linux-based Ubuntu operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 14.10 while including tons of information that will continue to apply to future editions. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 14.10 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find new or improved coverage of Ubuntus Unity interface, various types of servers, software repositories, database options, virtualization and cloud services, development tools, monitoring, troubleshooting, Ubuntus push into mobile and other touch screen devices, and much more. Detailed information on how to Configure and customize the Unity desktop Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, DNS, and HTTP servers (Apache, Nginx, or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust Learn about Ubuntus work toward usability on touch-screen and phone devices Ubuntu 14.10 on DVD DVD includes the full Ubuntu 14.10 distribution for 64 bit computers (most desktop and notebooks systems today) as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Kick Start Chapter! Purchase this book and receive a free Ubuntu 15.04 Kick Start chapter after Ubuntu 15.04 is released. See inside back cover for details}
}
@book{10.5555/3235404,
author = {Forsgren, Nicole and Humble, Jez and Kim, Gene},
title = {Accelerate: The Science of Lean Software and DevOps Building and Scaling High Performing Technology Organizations},
year = {2018},
isbn = {1942788339},
publisher = {IT Revolution Press},
edition = {1st},
abstract = {Accelerate your organization to win in the marketplace. How can we apply technology to drive business value? For years, we've been told that the performance of software delivery teams doesn't matterthat it can't provide a competitive advantage to our companies. Through four years of groundbreaking research to include data collected from the State of DevOps reports conducted with Puppet, Dr. Nicole Forsgren, Jez Humble, and Gene Kim set out to find a way to measure software delivery performanceand what drives itusing rigorous statistical methods. This book presents both the findings and the science behind that research, making the information accessible for readers to apply in their own organizations. Readers will discover how to measure the performance of their teams, and what capabilities they should invest in to drive higher performance. This book is ideal for management at every level.}
}
@book{10.5555/2898956,
author = {Helmke, Matthew},
title = {Ubuntu Unleashed 2016 Edition: Covering 15.10 and 16.04},
year = {2015},
isbn = {0134268113},
publisher = {Sams publishing},
edition = {11th},
abstract = {Ubuntu Unleashed 2016 Edition is filled with unique and advanced information for everyone who wants to make the most of the Linux-based Ubuntu operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 15.10 while including tons of information that will continue to apply to future editions. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 15.10 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find new or improved coverage of Ubuntus Unity interface, various types of servers, software repositories, database options, virtualization and cloud services, development tools, monitoring, troubleshooting, Ubuntus push into mobile and other touch screen devices, and much more. Configure and customize the Unity desktop Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, DNS, and HTTP servers (Apache, Nginx, or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust Learn about Ubuntus work toward usability on touchscreen and phone devices Ubuntu 15.10 on DVD DVD includes the full Ubuntu 15.10 distribution for 64 bit computers (most desktop and notebooks systems today) as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Upgrade! Purchase this book and receive a free Ubuntu 16.04 Kick Start chapter after Ubuntu 16.04 is released. See inside back cover for details.}
}
@book{10.5555/3158744,
author = {McKendrick, Russ and Raj, Pethuru and Chelladhurai, Jeeva S. and Singh, Vinod},
title = {Docker Bootcamp},
year = {2017},
isbn = {1787286983},
publisher = {Packt Publishing},
abstract = {Fast, intensive, and effective Docker learning About This BookGet well-versed with Docker in 7 days Identify and resolve common problems faced by users while working with Docker A fast-paced guide that will focus on all the core Docker functionalities Who This Book Is ForThis book targets developers, IT professionals and DevOps engineers who like to gain intensive, hands-on knowledge and skills with Docker without spending hours and hours in learning. If you have been struggling to find the time to gain proficiency and confidence with Docker containers and everyday Docker tasks, you have come to the right place! What You Will Learn Use Docker Compose to make multi-container applications easier to launchLaunch Docker hosts in various public clouds Deploy and configure a Docker Swarm cluster. Work with third-party plugins to extend core Docker functionality Monitor containers and hosts and explore commands to troubleshoot DockerIn Detail Docker allows you to create a robust and resilient environment to generate portable, composable, scalable, and stable application containers. The book starts by installing the core Docker Engine on MacOS, Windows 10 and Linux desktops. We will then define multi-container applications and understand the advantages of using containers locally. Once this is done, we will deploy containers on a single Docker host which is publicly accessible. Furthermore, we will learn how to deploy and configure a Docker Swarm cluster and explore networking and storage third-party plugins to extend the core Docker functionality. Towards the end, the book will demonstrate how to monitor and troubleshoot day-to-day problems in addition to various real world examples of container deployments. Style and approach This book is all about fast and intensive learning. Thaxt means we don't waste time in helping readers get started. The content is about filling in with highly-effective examples to build new things, show solving problems in newer and unseen ways, and solve real-world examples.}
}
@book{10.5555/2132833,
author = {Helmke, Matthew},
title = {Ubuntu Unleashed 2012 Edition: Covering 11.10 and 12.04},
year = {2012},
isbn = {0672335786},
publisher = {SAMS},
address = {USA},
edition = {7th},
abstract = {Ubuntu Unleashed is filled with unique and advanced information for everyone who wants to make the most of the Ubuntu Linux operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 11.10 (Oneiric Ocelot) and the forthcoming Ubuntu 12.04. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 11.10/12.04 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find brand-new coverage of the new Unity desktop, new NoSQL database support and Android mobile development tools, and many other Ubuntu 11.10/12.04 innovations. Whether youre new to Ubuntu or already a power user, youll turn to this book constantly: for new techniques, new solutions, and new ways to do even more with Ubuntu! Matthew Helmke served from 2006 to 2011 on the Ubuntu Forum Council, providing leadership and oversight of the Ubuntu Forums, and spent two years on the Ubuntu regional membership approval board for Europe, the Middle East, and Africa. He has written about Ubuntu for several magazines and websites, is a lead author of The Official Ubuntu Book. He works for The iPlant Collaborative, which is funded by the National Science Foundation and is building cyberinfrastructure for the biological sciences to support the growing use of massive amounts of data and computationally intensive forms of research. Quickly install Ubuntu, configure it, and get your hardware running right Configure and customize the new Unity desktop (or alternatives such as GNOME) Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and use Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access Manage kernels and modules Administer file, print, email, proxy, LDAP, and database services (both SQL and NoSQL) Use both Apache and alternative HTTP servers Support and use virtualization Use Ubuntu in cloud environments Learn the basics about popular programming languages including Python, PHP, and Perl, and how to use Ubuntu to develop in them Learn how to get started developing Android mobile devices Ubuntu 11.10 on DVD DVD includes the full Ubuntu 11.10 distribution for Intel x86 computers as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Upgrade! Purchase this book anytime in 2012 and receive a free Ubuntu 12.04 Upgrade Kit by mail (U.S. or Canada only) after Ubuntu 12.04 is released. See inside back cover for details.}
}
@book{10.5555/3294413,
author = {Cochrane, Ken and Chelladhurai, Jeeva S. and Khare, Neependra K.},
title = {Docker Cookbook: Over 100 Practical and Insightful Recipes to Build Distributed Applications with Docker, 2nd Edition},
year = {2018},
isbn = {1788626869},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Leverage Docker to deploying software at scale Key Features Leverage practical examples to manage containers efficientlyIntegrate with orchestration tools such as Kubernetes for controlled deploymentsLearn to implement best practices on improving efficiency and security of containersBook DescriptionDocker is an open source platform for building, shipping, managing, and securing containers. Docker has become the tool of choice for people willing to work with containers. Since the market is moving toward containerization, Docker will definitely have a big role to play in the future tech market. This book starts with setting up Docker in different environment, and helps you learn how to work with Docker images. Then, you will take a deep dive into network and data management for containers. The book explores the RESTful APIs provided by Docker to perform different actions, such as image/container operations. The book then explores logs and troubleshooting Docker to solve issues and bottlenecks. You will gain an understanding of Docker use cases, orchestration, security, ecosystems, and hosting platforms to make your applications easy to deploy, build, and collaborate on. The book covers the new features of Docker 18.xx (or later), such as working with AWS and Azure, Docker Engine, Docker Swarm, Docker Compose, and so on. By the end of this book, you will have gained hands-on experience of finding quick solutions to different problems encountered while working with Docker. What you will learn Install Docker on various platforms Work with Docker images and containers Container networking and data sharing Docker APIs and language bindings Various PaaS solutions for Docker Implement container orchestration using Docker Swarm and Kubernetes Container security Docker on various clouds Who this book is for Book is targeted towards developers, system administrators, and DevOps engineers who want to use Docker in his/her development, QA, or production environments. It is expected that the reader has basic Linux/Unix skills such as installing packages, editing files, managing services, and so on. Any experience in virtualization technologies such as KVM, XEN, and VMware will be an added advantage.}
}
@book{10.5555/3275629,
author = {Scheaffer, Jeffrey and Ravichandran, Aruna and Martins, Alex},
title = {The Kitty Hawk Venture: A Novel About Continuous Testing in DevOps to Support Continuous Delivery and Business Success},
year = {2018},
isbn = {1484236602},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {An airline is supposed to make the experience of booking a flight easy, trouble free, and reliable. But when scheduling software breaks down and flights get canceled, customers will walk, and heads will roll. Thats what Leigh Freemark faces the day she and her team launch a software upgrade that fails spectacularly and hits the media immediately. As Senior Director of Quality Assurance, her job is to make sure that code is market ready. And shes the one who must face the music when it doesnt. Tasked by senior management to find and fix the source of the failure, Leigh discovers just how essential it has become to radically improve the process of software development by introducing a concept called continuous testing. She must quickly learn what it means, how it works, and how to build it into her companys legacy system. But she soon discovers that managing change is much more difficult than it first appears. The airline business is changing fast, yet old traditions and loyalties still dominate. As she fights to convince her team to change or perish, she discovers that obstructions and opportunities come in surprising forms.***In The Kitty Hawk Venture, the authors deliver a sound lesson in the importance of continuous testing while taking the reader inside the world of commercial aviation. Each chapter delivers distinct and vital learning opportunities wrapped inside a fast-moving narrative complete with interesting characters, intriguing situations, and even some humor. The book concludes with a Flight Plan for Continuous Testing that stands on its own as a valuable resource guide for digital leaders in their continuous testing journey. The story is immediately relatable to anyone who has worked in software development or for the companies that rely on it. Who This Book Is For C-level executives, VPs of apps and quality, VPs of DevOps, architecture and strategy managers, and SMB and enterprise professionals}
}
@book{10.5555/3169220,
author = {Nemeth, Evi and Snyder, Garth and Hein, Trent R. and Whaley, Ben and Mackin, Dan},
title = {UNIX and Linux System Administration Handbook (5th Edition)},
year = {2017},
isbn = {0134277554},
publisher = {Addison-Wesley Professional},
edition = {5th},
abstract = {As an author, editor, and publisher, I never paid much attention to the competitionexcept in a few cases. This is one of those cases. The UNIX System Administration Handbook is one of the few books we ever measured ourselves against. Tim OReilly, founder of OReilly Media This edition is for those whose systems live in the cloud or in virtualized data centers; those whose administrative work largely takes the form of automation and configuration source code; those who collaborate closely with developers, network engineers, compliance officers, and all the other worker bees who inhabit the modern hive. Paul Vixie, Internet Hall of Fame-recognized innovator and founder of ISC and Farsight Security This book is fun and functional as a desktop reference. If you use UNIX and Linux systems, you need this book in your short-reach library. It covers a bit of the systems history but doesnt bloviate. Its just straight-forward information delivered in a colorful and memorable fashion. Jason A. Nunnelley UNIX and Linux System Administration Handbook, Fifth Edition, is todays definitive guide to installing, configuring, and maintaining any UNIX or Linux system, including systems that supply core Internet and cloud infrastructure. Updated for new distributions and cloud environments, this comprehensive guide covers best practices for every facet of system administration, including storage management, network design and administration, security, web hosting, automation, configuration management, performance analysis, virtualization, DNS, security, and the management of IT service organizations. The authorsworld-class, hands-on technologistsoffer indispensable new coverage of cloud platforms, the DevOps philosophy, continuous deployment, containerization, monitoring, and many other essential topics. Whatever your role in running systems and networks built on UNIX or Linux, this conversational, well-written guide will improve your efficiency and help solve your knottiest problems.}
}
@book{10.5555/3169276,
author = {Waghmare, Ramesh},
title = {AWS Tools for PowerShell 6},
year = {2017},
isbn = {1785884077},
publisher = {Packt Publishing},
abstract = {Leverage the power of PowerShell to bring the best out of your AWS infrastructureAbout This BookA collection of real-world-tested Powershell scripts that can be used to manage your Windows server efficientlyFollow step-by-step processes to solve your problems with Windows servers using AWS tools Design examples that work in the Amazon free usage tier, which lets you run the Windows platform on cloud Who This Book Is ForThis book will be useful for (but not limited to) Windows System administrators, cloud engineers, architects, DevOps engineers, and all those who want to accomplish tasks on the AWS Public Cloud using PowerShell. What You Will Learn Install the AWS Tools for PowerShell 6 Understand key services provided by Amazon Web services (AWS) Understand the Virtual Private CloudUse PowerShell 6 for AWS Identity and Access Management (IAM) Use PowerShell 6 for AWS Elastic Compute Cloud (EC2)Use PowerShell 6 for AWS Simple Storage Service (S3)Use PowerShell 6 for AWS Relational Database Service (RDS) Build fault-tolerant and highly-available applications using PowerShell 6 In Detail AWS Tools for PowerShell 6 shows you exactly how to automate all the aspects of AWS. You can take advantage of the amazing power of the cloud, yet add powerful scripts and mechanisms to perform common tasks faster than ever before. This book expands on the Amazon documentation with real-world, useful examples and production-ready scripts to automate all the aspects of your new cloud platform. It will cover topics such as managing Windows with PowerShell, setting up security services, administering database services, and deploying and managing networking. You will also explore advanced topics such as PowerShell authoring techniques, and configuring and managing storage and content delivery. By the end of this book, you will be able to use Amazon Web Services to automate and manage Windows servers. You will also have gained a good understanding of automating the AWS infrastructure using simple coding. Style and approach This step-by-step guide starts with simple examples then expands to full-blown administrative tasks leading to the efficient management of Windows servers. Each topic covers a section related to Amazon Web Services products, and the examples are built on one another to deliver a comprehensive library of scripts for administrators.}
}
@inproceedings{10.5555/3124362.3124380,
author = {Leite, Alessandro Ferreira and Penciuc, Diana},
title = {A Computing Environment Configuration Management Pattern Based on a Software Product Line Engineering Method},
year = {2016},
publisher = {The Hillside Group},
address = {USA},
abstract = {This paper describes a pattern to configure computing environments based on a software product line engineering (SPLE) method. Configuring computing environment represents a challenging and time-consuming activity, even for skilled DevOps engineers. The challenges these users usually face include: (a) choosing a configuration management tool to write their configuration management scripts, (b) ensuring that their computing environments are correctly configured, (c) keeping configuration scripts' dependencies and relationships up-to-date, and (d) ensuring that their scripts are both reproducible and idempotent. Furthermore, configuration management tools offer different levels of abstraction to describe the tasks. Hence, they demand knowledge on various programming languages. Therefore, configuring a computing environment follows a pattern. The pattern is: (a) describe a target state for the computing environment, (b) identify the software packages and their required configuration files, (c) create the scripts with the commands to achieve the desired state, and then, (d) execute the scripts. Thus, a software product line (SPL) based strategy is ideal for this domain, as the products have common characteristics and variable parts. As a result, this approach demands much less time and effort than the traditional one.},
booktitle = {Proceedings of the 11th Latin-American Conference on Pattern Languages of Programming},
articleno = {15},
numpages = {9},
keywords = {pattern for computing environment configuration, DevOps, software product line (SPL), infrastructure as code},
location = {Buenos Aires, Argentina},
series = {SugarLoafPLoP '16}
}
@book{10.5555/2787872,
author = {van Wyk, Kenneth R. and Graff, Mark G. and Peters, Dan S. and Burley, Diana L.},
title = {Enterprise Software Security: A Confluence of Disciplines},
year = {2014},
isbn = {0321604113},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {STRENGTHEN SOFTWARE SECURITY BY HELPING DEVELOPERS AND SECURITY EXPERTS WORK TOGETHER Traditional approaches to securing software are inadequate. The solution: Bring software engineering and network security teams together in a new, holistic approach to protecting the entire enterprise. Now, four highly respected security experts explain why this confluence is so crucial, and show how to implement it in your organization. Writing for all software and security practitioners and leaders, they show how software can play a vital, active role in protecting your organization. Youll learn how to construct software that actively safeguards sensitive data and business processes and contributes to intrusion detection/response in sophisticated new ways. The authors cover the entire development lifecycle, including project inception, design, implementation, testing, deployment, operation, and maintenance. They also provide a full chapter of advice specifically for Chief Information Security Officers and other enterprise security executives. Whatever your software security responsibilities, Enterprise Software Security delivers indispensable big-picture guidanceand specific, high-value recommendations you can apply right now. COVERAGE INCLUDES: Overcoming common obstacles to collaboration between developers and IT security professionals Helping programmers design, write, deploy, and operate more secure software Helping network security engineers use application output more effectively Organizing a software security team before youve even created requirements Avoiding the unmanageable complexity and inherent flaws of layered security Implementing positive software design practices and identifying security defects in existing designs Teaming to improve code reviews, clarify attack scenarios associated with vulnerable code, and validate positive compliance Moving beyond pentesting toward more comprehensive security testing Integrating your new application with your existing security infrastructure Ruggedizing DevOps by adding infosec to the relationship between development and operations Protecting application security during maintenance}
}
@inproceedings{10.1109/ICSE-SEET.2019.00011,
author = {Kuusinen, Kati and Albertsen, Sofus},
title = {Industry-Academy Collaboration in Teaching DevOps and Continuous Delivery to Software Engineering Students: Towards Improved Industrial Relevance in Higher Education},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEET.2019.00011},
doi = {10.1109/ICSE-SEET.2019.00011},
abstract = {Global industrial demand for highly skilled professional software engineers is increasing. Many countries already experience shortage of developer workforce and it is predicted that the industrial need for software engineers will grow on a higher rate than educational institutes are able to train new workforce. The main reasons for this deficit are in the education system's inability to adapt to current market needs and in difficulties in matching available skills with existing jobs. Therefore, increasing the industrial and market relevance of the education can be a key solution. Another significant contributor is teaching more efficient working methods such as automating repetitive parts of developer work to help to concentrate on tasks that directly create customer and business value. This paper presents the design and execution of a Continuous Delivery and DevOps course organized in company-university collaboration. The objective is to investigate how university courses requiring multidisciplinary lecturer skills and complex execution architectures can be organized in industry-academia collaboration to improve the industrial relevance of higher education.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training},
pages = {23–27},
numpages = {5},
keywords = {education courses, engineering education, agile software development},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEET '19}
}
@book{10.5555/3279289,
author = {Aly, Bassem},
title = {Hands-On Enterprise Automation with Python: Automate Common Administrative and Security Tasks with Python},
year = {2018},
isbn = {1788998510},
publisher = {Packt Publishing},
abstract = {Invent your own Python scripts to automate your infrastructure Key Features Make the most of Python libraries and modules to automate your infrastructure Leverage Python programming to automate server configurations and administration tasks Efficiently develop your Python skill set Book Description Hands-On Enterprise Automation with Python starts by covering the set up of a Python environment to perform automation tasks, as well as the modules, libraries, and tools you will be using. We'll explore examples of network automation tasks using simple Python programs and Ansible. Next, we will walk you through automating administration tasks with Python Fabric, where you will learn to perform server configuration and administration, along with system administration tasks such as user management, database management, and process management. As you progress through this book, you'll automate several testing services with Python scripts and perform automation tasks on virtual machines and cloud infrastructure with Python. In the concluding chapters, you will cover Python-based offensive security tools and learn how to automate your security tasks. By the end of this book, you will have mastered the skills of automating several system administration tasks with Python. What you will learn Understand common automation modules used in Python Develop Python scripts to manage network devices Automate common Linux administration tasks with Ansible and Fabric Managing Linux processes Administrate VMware, Open Stack, and AWS instances with Python Security automation and sharing code on GitHub Who This Book Is For Hands-On Enterprise Automation with Python is for system administrators and DevOps engineers who are looking for an alternative to major automation frameworks such as Puppet and Chef. Basic programming knowledge with Python and Linux shell scripting is necessary.}
}
@inproceedings{10.1007/978-3-319-34096-8_2,
author = {Ghezzi, Carlo},
title = {Dependability of Adaptable and Evolvable Distributed Systems},
year = {2016},
isbn = {9783319340951},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-34096-8_2},
doi = {10.1007/978-3-319-34096-8_2},
abstract = {This article is a tutorial on how to achieve software evolution and adaptation in a dependable manner, by systematically applying formal modelling and verification. It shows how software can be designed upfront to tolerate different sources of uncertainty that cause continuous future changes. If possible changes can be predicted, and their occurrence can be detected, it is possible to design the software to be self-adaptable. Otherwise, continuous evolution has to be supported and continuous flow into operation has to be ensured. In cases where systems are designed to be continuously running, it is necessary to support safe continuous software deployment that guarantees correct operation in the presence of dynamic reconfigurations. The approaches we survey here have been mainly developed in the context of the SMScom project, funded by the European Commission ---Programme IDEAS-ERC http://erc-smscom.dei.polimi.it/. --- and lead by the author. It is argued that these approaches fit well the current agile methods for development and operations that are popularized as DevOps.},
booktitle = {Advanced Lectures of the 16th International School on Formal Methods for the Quantitative Evaluation of Collective Adaptive Systems - Volume 9700},
pages = {36–60},
numpages = {25},
keywords = {Environment uncertainty, Requirements, Software evolution, pervasive systems, ubiquitous, Cyber-physical systems, Distributed, Dynamic reconfiguration}
}
@book{10.5555/3217530,
author = {Patawari, Aditya and Aggarwal, Vikas},
title = {Ansible 2 Cloud Automation Cookbook: Write Ansible Playbooks for AWS, Google Cloud, Microsoft Azure, and OpenStack},
year = {2018},
isbn = {178829582X},
publisher = {Packt Publishing},
abstract = {Orchestrate your cloud infrastructure Key Features Recipe-based approach to install and configure cloud resources using AnsibleCovers various cloud-related modules and their functionalitiesIncludes deployment of a sample application to the cloud resources that we create Learn the best possible way to manage and automate your cloud infrastructure Book Description Ansible has a large collection of inbuilt modules to manage various cloud resources. The book begins with the concepts needed to safeguard your credentials and explain how you interact with cloud providers to manage resources. Each chapter begins with an introduction and prerequisites to use the right modules to manage a given cloud provider. Learn about Amazon Web Services, Google Cloud, Microsoft Azure, and other providers. Each chapter shows you how to create basic computing resources, which you can then use to deploy an application. Finally, you will be able to deploy a sample application to demonstrate various usage patterns and utilities of resources. What you will learn Use Ansible Vault to protect secrets Understand how Ansible modules interact with cloud providers to manage resources Build cloud-based resources for your applicationCreate resources beyond simple virtual machines Write tasks that can be reused to create resources multiple times Work with self-hosted clouds such as Open Stack and Docker Deploy a multi-tier application on various cloud providers Who This Book Is ForIf you are a system administrator, infrastructure engineer, or a DevOps engineer who wants to obtain practical knowledge about Ansible and its cloud deliverables, then this book is for you. Recipes in this book are designed for people who would like to manage their cloud infrastructures efficiently using Ansible, which is regarded as one of the best tools for cloud management and automation.}
}
@book{10.5555/3158682,
author = {Klaffenbach, Florian and Damaschke, Jan-Henrik and Michalski, Oliver},
title = {Implementing Azure Solutions: Eliminate the Pain Point of Implementation},
year = {2017},
isbn = {1786467852},
publisher = {Packt Publishing},
abstract = {A practical guide that enhances your skills in implementing Azure solutions for your organization About This Book Confidently configure, deploy, and manage cloud services and virtual machines Implement a highly-secured environment and respond to threats with increased visibility This comprehensive guide is packed with exciting practical scenarios that enable you to implement Azure solutions with ease Who This Book Is For This book is for IT architects, system and network admins, and DevOps engineers who are aware of Azure solutions and want to implement them for their organization. What You Will Learn Implement virtual networks, network gateways, Site-to-Site VPN, Express Route, routing, and network devices Understand the working of different storage accounts in AzurePlan, deploy, and secure virtual machines Deploy and manage Azure Containers Get familiar with some common Azure usage scenarios In Detail Microsoft Azure has numerous effective solutions that shape the future of any business. However, the major challenge that architects and administrators face are implementing these solutions appropriately. Our book focuses on various implementation scenarios that will help overcome the challenge of implementing Azure's solutions in a very efficient manner and will also help you to prepare for Microsoft Architect exam. You will not only learn how to secure a newly deployed Azure Active Directory but also get to know how Azure Active Directory Synchronization could be implemented. To maintain an isolated and secure environment so that you can run your virtual machines and applications, you will implement Azure networking services. Also to manage, access, and secure your confidential data, you will implement storage solutions. Toward the end, you will explore tips and tricks to secure your environment. By the end, you will be able to implement Azure solutions such as networking, storage, and cloud effectively. Style and approach This step-by-step guide focuses on implementing various Azure solutions for your organization. The motive is to provide a comprehensive exposure and ensure they can implement these solutions with ease.}
}
@book{10.5555/3386343,
author = {Jakobczyk, Michal Tomasz},
title = {Practical Oracle Cloud Infrastructure: Infrastructure as a Service, Autonomous Database, Managed Kubernetes, and Serverless},
year = {2020},
isbn = {1484255054},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Use this fast-paced and comprehensive guide to build cloud-based solutions on Oracle Cloud Infrastructure. You will understand cloud infrastructure, and learn how to launch new applications and move existing applications to Oracle Cloud. Emerging trends in software architecture are covered such as autonomous platforms, infrastructure as code, containerized applications, cloud-based container orchestration with managed Kubernetes, and running serverless workloads using open-source tools. Practical examples are provided. This book teaches you how to self-provision the cloud resources you require to run and scale your custom cloud-based applications using a convenient web console and programmable APIs, and you will learn how to manage your infrastructure as code with Terraform. You will be able to plan, design, implement, deploy, run, and monitor your production-grade and fault-tolerant cloud software solutions in Oracle's data centers across the world, paying only for the resources you actually use. Oracle Cloud Infrastructure is part of Oracle's new generation cloud that delivers a complete and well-integrated set of Infrastructure as a Service (IaaS) capabilities (compute, storage, networking), edge services (DNS, web application firewall), and Platform as a Service (PaaS) capabilities (such as Oracle Autonomous Database which supports both transactional and analytical workloads, the certified and fully managed Oracle Kubernetes Engine, and a serverless platform based on an open-source Fn Project). Oracle Autonomous Database which supports both transactional and analytical workloads), and Oracle's certified and managed Container Engine for Kubernetes. What You Will Learn, Build software solutions on Oracle Cloud; Automate cloud infrastructure with CLI and Terraform; Follow best practices for architecting on Oracle Cloud; Employ Oracle Autonomous Database to obtain valuable data insights; Run containerized applications on Oracle's Container Engine for Kubernetes; Understand the emerging Cloud Native ecosystem; Who This Book Is For, Cloud architects, developers, DevOps engineers, and technology students and others who want to learn how to build cloud-based systems on Oracle Cloud Infrastructure (OCI) leveraging a broad range of OCI Infrastructure as a Service (IAAS) capabilities, Oracle Autonomous Database, and Oracle's Container Engine for Kubernetes. Readers should have a working knowledge of Linux, exposure to programming, and a basic understanding of networking concepts. All exercises in the book can be done at no cost with a 30-day Oracle Cloud trial.}
}
@book{10.5555/2588302,
author = {Neeraj, Nishant},
title = {Mastering Apache Cassandra},
year = {2013},
isbn = {1782162682},
publisher = {Packt Publishing},
abstract = {Get comfortable with the fastest NoSQL database, its architecture, key programming patterns, infrastructure management, and more! Overview Complete coverage of all aspects of Cassandra Discusses prominent patterns, pros and cons, and use cases Contains briefs on integration with other software In Detail Apache Cassandra is the perfect choice for building fault tolerant and scalable databases. Implementing Cassandra will enable you to take advantage of its features which include replication of data across multiple datacenters with lower latency rates. This book details these features that will guide you towards mastering the art of building high performing databases without compromising on performance. Mastering Apache Cassandra aims to give enough knowledge to enable you to program pragmatically and help you understand the limitations of Cassandra. You will also learn how to deploy a production setup and monitor it, understand what happens under the hood, and how to optimize and integrate it with other software. Mastering Apache Cassandra begins with a discussion on understanding Cassandras philosophy and design decisions while helping you understand how you can implement it to resolve business issues and run complex applications simultaneously. You will also get to know about how various components of Cassandra work with each other to give a robust distributed system. The different mechanisms that it provides to solve old problems in new ways are not as twisted as they seem; Cassandra is all about simplicity. Learn how to set up a cluster that can face a tornado of data reads and writes without wincing. If you are a beginner, you can use the examples to help you play around with Cassandra and test the water. If you are at an intermediate level, you may prefer to use this guide to help you dive into the architecture. To a DevOp, this book will help you manage and optimize your infrastructure. To a CTO, this book will help you unleash the power of Cassandra and discover the resources that it requires. What you will learn from this book Write programs using Cassandras features more efficiently Learn how to get the most out of a given infrastructure and Improve performance, tweak JVM Manage clusters and perform housekeeping activities Keep an eye on Cassandra processes and machines that hold the data store get to know simple monitoring mechanisms, such as open sourced and proprietary ones Squeeze the value of the data that you hold in Cassandra Learn CQL 3 quickly and use Cassandra with Java, Python, NodeJS, Scala, and PHP Approach Mastering Apache Cassandra is a practical, hands-on guide with step-by-step instructions. The smooth and easy tutorial approach focuses on showing people how to utilize Cassandra to its full potential. Who this book is written for This book is aimed at intermediate Cassandra users. It is best suited for startups where developers have to wear multiple hats: programmer, DevOps, release manager, convincing clients, and handling failures. No prior knowledge of Cassandra is required.}
}
@book{10.5555/3235366,
author = {Wadia, Yohan},
title = {AWS Administration - The Definitive Guide - Second Edition: Design, Build, and Manage Your Infrastructure on Amazon Web Services},
year = {2018},
isbn = {1788478797},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Leverage this step-by-step guide to build a highly secure, fault-tolerant, and scalable Cloud environment Key Features Learn how to leverage various Amazon Web Services (AWS) components and services to build a secure, reliable, and robust environment to host your applications on. Delve into core AWS service offerings with hands-on tutorials, real-world use case scenarios, and best practices. A self-paced, systematic, and step-by-step guide to learning and implementing AWS in your own environment. Book Description Many businesses are moving from traditional data centers to AWS because of its reliability, vast service offerings, lower costs, and high rate of innovation. AWS can be used to accomplish a variety of both simple and tedious tasks. Whether you are a seasoned system admin or a rookie, this book will help you to learn all the skills you need to work with the AWS cloud. This book guides you through some of the most popular AWS services, such as EC2, Elastic Beanstalk, EFS, CloudTrail, Redshift, EMR, Data Pipeline, and IoT using a simple, real-world, application-hosting example. This book will also enhance your application delivery skills with the latest AWS services, such as CodeCommit, CodeDeploy, and CodePipeline, to provide continuous delivery and deployment, while also securing and monitoring your environment's workflow. Each chapter is designed to provide you with maximal information about each AWS service, coupled with easy to follow, hands-on steps, best practices, tips, and recommendations. By the end of the book, you will be able to create a highly secure, fault-tolerant, and scalable environment for your applications to run on. What you will learnTake an in-depth look at what's new with AWS, along with how to effectively manage and automate your EC2 infrastructure with AWS Systems Manager Deploy and scale your applications with ease using AWS Elastic Beanstalk and Amazon Elastic File System Secure and govern your environments using AWS CloudTrail, AWS Config, and AWS Shield Learn the DevOps way using a combination of AWS Code Commit, AWS Code Deploy, and AWS Code PipelineRun big data analytics and workloads using Amazon EMR and Amazon Redshift Learn to back up and safeguard your data using AWS Data Pipeline Get started with the Internet of Things using AWS IoT and AWS Greengrass Who This Book Is ForThis book is for those who want to learn and leverage the rich plethora of services provided by AWS. Although no prior experience with AWS is required, it is recommended that you have some hands-on experience of Linux, Web Services, and basic networking.}
}
@book{10.5555/2717077,
author = {Ryan, Mike},
title = {AWS System Administration: Best Practices for Sysadmins in the Amazon Cloud},
year = {2015},
isbn = {1449342574},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Building and deploying infrastructure with Amazon Web Services is simply not the same as dealing with static servers. With tools that let you automatically replace instances and scale up and down in response to demand, its actually more like programming than traditional system administrationand ideal for a DevOps environment. This comprehensive guide shows developers and system administrators alike how to configure and manage AWS services, such as Cloud Formation, OpsWorks, Elastic Load Balancing, and Route 53. System administrators will learn how to integrate their favorite tools and processes, while developers will pick up enough system administration knowledge to build a robust and resilient AWS application infrastructure. Launch instances with EC2 or Cloud Formation Apply AWS security tools at the beginning of your project Learn configuration management with OpsWorks and Puppet Deploy applications with Auto Scaling and Elastic Load Balancing Explore methods to deploy application and infrastructure updates Reuse resources to save time on development and operations Learn strategies for managing log files in AWSConfigure a cloud-aware DNS service with Route 53Use Cloud Watch or traditional tools to monitor your application}
}
@book{10.5555/3158810,
author = {Baier, Jonathan},
title = {Getting Started with Kubernetes: Orchestrate and Manage Large-Scale Docker Deployments, 2nd Edition},
year = {2017},
isbn = {1787283364},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Learn how to schedule and run application containers using Kubernetes. About This Book Get well-versed with the fundamentals of Kubernetes and get it production-ready for deploymentsConfidently manage your container clusters and networks using Kubernetes This practical guide will show you container application examples throughout to illustrate the concepts and features of Kubernetes Who This Book Is For This book is for developers, sys admins, and DevOps engineers who want to automate the deployment process and scale their applications. You do not need any knowledge about Kubernetes. What You Will Learn Download, install, and configure the Kubernetes codebase Understand the core concepts of a Kubernetes cluster Be able to set up and access monitoring and logging for Kubernetes clusters Set up external access to applications running in the cluster Understand how CoreOS and Kubernetes can help you achieve greater performance and container implementation agility Run multiple clusters and manage from a single control plane Explore container security as well as securing Kubernetes clusters Work with third-party extensions and tools In Detail Kubernetes has continued to grow and achieve broad adoption across various industries, helping you to orchestrate and automate container deployments on a massive scale. This book will give you a complete understanding of Kubernetes and how to get a cluster up and running. You will develop an understanding of the installation and configuration process. The book will then focus on the core Kubernetes constructs such as pods, services, replica sets, replication controllers, and labels. You will also understand how cluster level networking is done in Kubernetes. The book will also show you how to manage deployments and perform updates with minimal downtime. Additionally, you will learn about operational aspects of Kubernetes such as monitoring and logging. Advanced concepts such as container security and cluster federation will also be covered. Finally, you will learn about the wider Kubernetes ecosystem with OCP, CoreOS, and Tectonic and explore the third-party extensions and tools that can be used with Kubernetes. By the end of the book, you will have a complete understanding of the Kubernetes platform and will start deploying applications on it. Style and approach This straightforward guide will help you understand how to move your container applications into production through best practices and a step-by-step walkthrough tied to real-world operational strategies.}
}
@book{10.5555/3299133,
author = {Soni, Mitesh and Gilchrist, Wayde},
title = {Designing AWS Environments: Architect Large-Scale Cloud Infrastructures with AWS},
year = {2018},
isbn = {1789535549},
publisher = {Packt Publishing},
abstract = {Design and create robust and resilient distributed solutions with AWS Key Features Design and secure virtual private network environments on the AWS cloud Deploy appropriate instance types and sizes based on performance and cost requirements Gain proficiency and confidence when designing virtual cloud environments Book Description Amazon Web Services (AWS) provides trusted,cloud-based solutions to help you meet your business needs. Running your solutions in the AWS Cloud can help you get your applications up and running faster while providing the security to meet your compliance requirements. This book begins by familiarizing you with the key capabilities to architect and host applications, websites, and services on AWS. We explain the available options for AWS free tier with virtual instances and demonstrate how you can launch and connect them. Using practical examples, you'll be able to design and deploy networking and hosting solutions for large deployments. Finally, the book focuses on security and important elements of scalability and high availability using AWS VPC, Elastic Load Balancing, and Auto scaling. By the end of this book, you will have handson experience of working with AWS instances, VPC, Elastic Load Balancing, and Auto scalingrelated tasks on Amazon Web Services. What you will learn Establish how to launch EC2 instances and log in Work with Linux and Windows instances Understand Amazon VPC networking creation with and without a wizard Design, create, and secure a Virtual Private Cloud Autoscale instances based on the increase and decrease in traffic Deploy applications in a highly available and fault-tolerant manner Load balance the requests with Elastic Load Balancing Make your applications highly available through load balancing, multi-AZ deployments, and auto scaling Who this book is for This book is for new and aspiring individuals who are preparing or gearing up for a solutions architect role. You'll also find this useful if you're an IT professional such as beginners, cloud architects, and cloud solution providers, or DevOps engineer who is preparing to design and deploy large solutions on AWS. No experience with AWS is required.}
}
@book{10.5555/2530409,
author = {Arundel, John},
title = {Puppet 3 Beginner's Guide},
year = {2013},
isbn = {1782161244},
publisher = {Packt Publishing},
abstract = {Start from scratch with the Puppet configuration management system, and learn how to fully utilize Puppet through simple, practical examples Overview Shows you step-by-step how to install Puppet and start managing your systems with simple examples Every aspect of Puppet is explained in detail so that you really understand what you're doing. Gets you up and running immediately, from installation to using Puppet for practical tasks in a matter of minutes. Written in a clear, friendly, jargon-free style which doesn't assume any previous knowledge and explains things in practical terms In Detail Everyone's talking about Puppet, the open-source DevOps technology that lets you automate your server setups and manage websites, databases, and desktops. Puppet can build new servers in seconds, keep your systems constantly up to date, and automate daily maintenance tasks. "Puppet 3 Beginner's Guide" gets you up and running with Puppet straight away, with complete real world examples. Each chapter builds your skills, adding new Puppet features, always with a practical focus. You'll learn everything you need to manage your whole infrastructure with Puppet. "Puppet 3 Beginner's Guide" takes you from complete beginner to confident Puppet user, through a series of clear, simple examples, with full explanations at every stage. Through a series of worked examples introducing Puppet to a fictional web company, you'll learn how to manage every aspect of your server setup. Switching to Puppet needn't be a big, long-term project; this book will show you how to start by bringing one small part of your systems under Puppet control and, little by little, building to the point where Puppet is managing your whole infrastructure. Presented in an easy-to-read guide to learning Puppet from scratch, this book explains simply and clearly all you need to know to use this essential IT power tool, all the time applying these solutions to real-world scenarios. What you will learn from this book Installing and configuring your Puppet environment. Running Puppet on multiple servers. Deploy configuration files and templates for lightning-fast installations. Creating and monitoring reports and information. Managing user accounts, security, access control, and scheduled jobs. Best practices for organizing your Puppet code using Git. Approach Presented in an easy-to-follow, step-by-step tutorial format, Puppet 3 Beginner's Guide will lead you through the basics of setting up your Puppet server with plenty of screenshots and real-world solutions. Who this book is written for This book is written for system administrators and developers, and anyone else who needs to manage computer systems. You will need to be able to edit text files and run a few commands on the command line, but otherwise no system administration or programming experience is required.}
}
@article{10.1016/j.infsof.2021.106570,
author = {Santos J\'{u}nior, Paulo S\'{e}rgio and Barcellos, Monalessa Perini and Falbo, Ricardo de Almeida and Almeida, Jo\~{a}o Paulo A.},
title = {From a Scrum Reference Ontology to the Integration of Applications for Data-Driven Software Development},
year = {2021},
issue_date = {Aug 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {136},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106570},
doi = {10.1016/j.infsof.2021.106570},
journal = {Inf. Softw. Technol.},
month = {aug},
numpages = {18},
keywords = {Semantic Interoperability, Application Integration, Scrum, Ontology}
}
@inproceedings{10.1145/3230833.3232854,
author = {Syed, Madiha H. and Fernandez, Eduardo B.},
title = {A Reference Architecture for the Container Ecosystem},
year = {2018},
isbn = {9781450364485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3230833.3232854},
doi = {10.1145/3230833.3232854},
abstract = {Containers have gained immense popularity as a portable and lightweight virtualization solution. They facilitate application development, deployment and distribution across computing environments. Their success is also attributed to the support they offer for DevOps teams and for applications developed using a microservices architecture style. Containers are not the only components in the environment but work closely with other components for managing and supporting them, forming an ecosystem. Architectural modeling can be used as a powerful tool to represent ecosystems which helps understand, build and secure such complex systems. We describe in this paper several models we have created for container ecosystem components. These models are abstract, and they help generalize the systems to handle complexity and heterogeneity; they provide a common vocabulary and build holistic and unified views of the systems. The use of UML for modeling improves precision. This can lead to better implementations with respect to reliability, security and interoperability compared to ad hoc methods. A reference architecture will not just facilitate the work of developers and security engineers but also of anyone who aims to ensure compliance, privacy, safety, reliability and/or governance for container ecosystems and we show how to build one. We also describe relationships between container, cloud and IoT ecosystems. This paper is part of our work on developing a security reference architecture for container ecosystems.},
booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
articleno = {31},
numpages = {6},
keywords = {Containers, container ecosystem, container manager},
location = {Hamburg, Germany},
series = {ARES 2018}
}
@book{10.5555/3294611,
author = {Labouardy, Mohamed},
title = {Hands-On Serverless Applications with Go: Build Real-World, Production-Ready Applications with AWS Lambda},
year = {2018},
isbn = {1789134617},
publisher = {Packt Publishing},
abstract = {Learn to build, secure, deploy, and manage your serverless application in Golang with AWS Lambda Key Features Implement AWS lambda to build scalable and cost-efficient applications in Go Design and set the data flow between cloud services and custom business logicLearn to design Lambda functions using real-world examples and implementation scenarios Book Description Serverless architecture is popular in the tech community due to AWS Lambda. Go is simple to learn, straightforward to work with, and easy to read for other developers; and now it's been heralded as a supported language for AWS Lambda. This book is your optimal guide to designing a Go serverless application and deploying it to Lambda. This book starts with a quick introduction to the world of serverless architecture and its benefits, and then delves into AWS Lambda using practical examples. You'll then learn how to design and build a production-ready application in Go using AWS serverless services with zero upfront infrastructure investment. The book will help you learn how to scale up serverless applications and handle distributed serverless systems in production. You will also learn how to log and test your application. Along the way, you'll also discover how to set up a CI/CD pipeline to automate the deployment process of your Lambda functions. Moreover, you'll learn how to troubleshoot and monitor your apps in near real-time with services such as AWS Cloud Watch and X-ray. This book will also teach you how to secure the access with AWS Cognito. By the end of this book, you will have mastered designing, building, and deploying a Go serverless application. What you will learn Understand how AWS Lambda works and use it to create an application Understand how to scaleup serverless applications Design a cost-effective serverless application in AWS Build a highly scalable and fault-tolerant CI/CD pipeline Understand how to troubleshoot and monitor serverless apps in AWS Discover the working of APIs and single page applications Build a production-ready serverless application in Go Who this book is for This book is for Go developers who would like to learn about serverless architecture. Go programming knowledge is assumed. DevOps and Solution Architects who are interested in building serverless applications in Go can also choose this book.}
}
@book{10.5555/3199925,
author = {Santacroce, Ferdinando},
title = {Git Essentials - Second Edition: Create, Merge, and Distribute Code with Git, the Most Powerful and Flexible Versioning System Available},
year = {2017},
isbn = {1787120724},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Dive and explore into the latest addons of the latest Git. About This Book Master all the basic concepts of Git to protect your code and make it easier to evolve Use Git proficiently, and learn how to resolve day-by-day challenges easily This step-by-step guide is packed with examples to help you learn and work with Gits internals Who This Book Is ForIf you are a software developer with little or no experience of versioning systems, or you are familiar with other centralized versioning systems, then this book is for you. If you have experience in server and system management and need to broaden your use of Git from a DevOps perspective, this book contains everything you need. What You Will Learn Master Git fundamentals Be able to "visualize," even with the help of a valid GUI tool Write principal commands in a shell Figure out the right strategy to run change your daily work with few or no annoyances Explore the tools used to migrate to Git from the Subversion versioning system without losing your development history Plan new projects and repositories with ease, using online services, or local network resources In Detail Since its inception, Git has attracted skilled developers due to its robust, powerful, and reliable features. Its incredibly fast branching ability transformed a piece of code from a niche tool for Linux Kernel developers into a mainstream distributed versioning system. Like most powerful tools, Git can be hard to approach since it has a lot of commands, subcommands, and options that easily confuse newcomers. The 2nd edition of this very successful book will help you overcome this fear and become adept in all the basic tasks in Git. Building upon the success of the first book, we start with a brief step-by-step installation guide; after this, you'll delve into the essentials of Git. For those of you who have bought the first edition, this time we go into internals in far greater depth, talking less about theory and using much more practical examples. The book serves as a primer for topics to follow, such as branching and merging, creating and managing a GitHub personal repository, and fork and pull requests. Youll then learn the art of cherry-picking, taking only the commits you want, followed by Git blame. Finally, we'll see how to interoperate with a Subversion server, covering the concepts and commands needed to convert an SVN repository into a Git repository. To conclude, this is a collection of resources, links, and appendices to satisfy even the most curious. Style and approach This short guide will help you understand the concepts and fundamentals of GIT is a step-by-step manner.}
}
@inproceedings{10.1145/3419111.3421303,
author = {Dai, Ting and Karve, Alexei and Koper, Grzegorz and Zeng, Sai},
title = {Automatically Detecting Risky Scripts in Infrastructure Code},
year = {2020},
isbn = {9781450381376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419111.3421303},
doi = {10.1145/3419111.3421303},
abstract = {Infrastructure code supports embedded scripting languages such as Shell and PowerShell to manage the infrastructure resources and conduct life-cycle operations. Risky patterns in the embedded scripts have widespread of negative impacts across the whole infrastructure, causing disastrous consequences. In this paper, we propose an analysis framework, which can automatically extract and compose the embedded scripts from infrastructure code before detecting their risky code patterns with correlated severity levels and negative impacts. We implement SecureCode based on the proposed framework to check infrastructure code supported by Ansible, i.e., Ansible playbooks. We integrate SecureCode with the DevOp pipeline deployed in IBM cloud and test Secure-Code on 45 IBM Services community repositories. Our evaluation shows that SecureCode can efficiently and effectively identify 3419 true issues with 116 false positives in minutes. Among the 3419 true issues, 1691 have high severity levels.},
booktitle = {Proceedings of the 11th ACM Symposium on Cloud Computing},
pages = {358–371},
numpages = {14},
keywords = {security, reliability, powershell, performance, static analysis, infrastructure-as-code, availability, ansible, shell},
location = {Virtual Event, USA},
series = {SoCC '20}
}
author = {He, Xiang and Tu, Zhiying and Liu, Lei and Xu, Xiaofei and Wang, Zhongjie},
title = {Optimal Evolution Planning and&nbsp;Execution for Multi-Version Coexisting Microservice Systems},
year = {2020},
isbn = {978-3-030-65309-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-65310-1_1},
doi = {10.1007/978-3-030-65310-1_1},
abstract = {A microservice-based system is composed of a set of microservices that are developed and deployed independently for agile DevOps. Intensive and iterative adaptations/upgrades of microservices are essential for such systems to adapt to user requirement changes, and as a consequence, result in the phenomenon of “multi-version microservice coexistence” in a system. Besides traditional API-based functional dependencies between different microservices, there appear complicated dependencies between different versions of difference microservices. The complicated dependencies dramatically deteriorate the maintainability of microservice systems, especially when systems evolve to adapt to user requirement changes. To meet this challenge, a version dependency model is proposed for describing the complex dependencies between different versions of microservices, and a greedy-based optimization algorithm is developed for generating an optimal evolution plan. A programming framework (MF4MS) and cloud-edge based infrastructure (MI4MS) are implemented to facilitate microservice systems to automatically execute the evolution plan. Experiments show that the proposed approach performs well to cope with self-adaptation in the situation where complicated version dependencies exist.},
booktitle = {Service-Oriented Computing: 18th International Conference, ICSOC 2020, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings},
pages = {3–18},
numpages = {16},
keywords = {User requirement changes, Self adaptation, Version dependency, Multi-version coexistence, Microservice systems},
location = {Dubai, United Arab Emirates}
}
@article{10.1007/s11219-020-09507-0,
author = {Leotta, Maurizio and Cerioli, Maura and Olianas, Dario and Ricca, Filippo},
title = {Two Experiments for Evaluating the Impact of Hamcrest and AssertJ on Assertion Development},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09507-0},
doi = {10.1007/s11219-020-09507-0},
abstract = {Test automation enables continuous testing, a cornerstone of agile methods, and DevOps. Assertions play a fundamental role in test automation, and recently competing assertion libraries for unit testing frameworks, such as, for example, JUnit or TestNG, emerged. Thus, it is imperative to gauge assertion libraries in terms of developer/tester productivity, allowing SQA managers and software testers to select the best. The goal of this work is comparing two assertion libraries having a different approach (matchers vs. fluent assertions) w.r.t. two dependent variables: correctness of developed assertions and time to develop them. We conducted two controlled experiments with Bachelor students in Computer Science and Master students in Computer Engineering. AssertJ (fluent assertions approach) is compared with Hamcrest (matchers), in a test development scenario with the Java language where 672 assertions were developed by 48 students overall. The results show that (a) adopting AssertJ improves the tester’s productivity significantly during the development of assertions only for Bachelor students, and (b) time of developing assertions is similar using AssertJ or Hamcrest in both the categories of participants. Testers and SQA managers selecting assertion libraries for their organizations should consider as first choice AssertJ in case of inexperienced developers/testers since our study shows that it increases the productivity of Bachelor students more than Hamcrest.},
journal = {Software Quality Journal},
month = {sep},
pages = {1113–1145},
numpages = {33},
keywords = {Assertion development, Tester productivity, Hamcrest matchers, Evidence-based Software Engineering, AssertJ methods, Controlled experiment}
}
@inproceedings{10.1145/2593812.2593813,
author = {Fitzgerald, Brian and Stol, Klaas-Jan},
title = {Continuous Software Engineering and beyond: Trends and Challenges},
year = {2014},
isbn = {9781450328562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593812.2593813},
doi = {10.1145/2593812.2593813},
abstract = {Throughout its short history, software development has been characterized by harmful disconnects between important activities e.g., planning, development and implementation. The problem is further exacerbated by the episodic and infrequent performance of activities such as planning, testing, integration and releases. Several emerging phenomena reflect attempts to address these problems. For example, the Enterprise Agile concept has emerged as a recognition that the benefits of agile software development will be sub- optimal if not complemented by an agile approach in related organizational function such as finance and HR. Continuous integration is a practice which has emerged to eliminate discontinuities between development and deployment. In a similar vein, the recent emphasis on DevOps recognizes that the integration between software development and its operational deployment needs to be a continuous one. We argue a similar continuity is required between business strategy and development, BizDev being the term we coin for this. These disconnects are even more problematic given the need for reliability and resilience in the complex and data-intensive systems being developed today. Drawing on the lean concept of flow, we identify a number of continuous activities which are important for software development in today’s context. These activities include continuous planning, continuous integration, continuous deployment, continuous delivery, continuous verification, continuous testing, continuous compliance,continuous security, continuous use, continuous trust, continuous run-time monitoring, continuous improvement (both process and product), all underpinned by continuous innovation. We use the umbrella term, ``Continuous *'' (continuous star) to identify this family of continuous activities.},
booktitle = {Proceedings of the 1st International Workshop on Rapid Continuous Software Engineering},
pages = {1–9},
numpages = {9},
keywords = {Continuous Star, DevOps, continuous software engineering, BizDev},
location = {Hyderabad, India},
series = {RCoSE 2014}
}
@book{10.5555/2843013,
author = {Lines, Mark and Ambler, Scott W.},
title = {Introduction to Disciplined Agile Delivery: A Small Agile Team's Journey from Scrum to Continuous Delivery},
year = {2015},
isbn = {1497544386},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
edition = {1st},
abstract = {Introduction to Disciplined Agile Delivery provides a quick overview of how agile software development works from beginning-to-end. It describes the Disciplined Agile Delivery (DAD) process decision framework and then works through a case study describing a typical agile teams experiences adopting a disciplined agile approach. The book describes how the team develops the first release of a mission-critical application while working in a legacy enterprise environment. It describes their experiences from beginning-to-end, starting with their initial team initiation efforts through construction and finally to deploying the solution into production. It also describes how the team stays together for future releases, overviewing their process improvement efforts from their Scrum-based beginnings through to a lean continuous delivery approach that fits in with their organizations evolving DevOps strategy. The DAD framework is a hybrid of existing methods such as Scrum, Kanban, Agile Modeling, SAFe, Extreme Programming, Agile Data, Unified Process and many others. DAD provides the flexibility to use various approaches and plugs the gaps not addressed by mainstream agile methods. In a nutshell, DAD is pragmatic agile. DAD describes proven strategies to adapt and scale your agile initiatives to suit the unique realities of your enterprise without having to figure it all out by yourself. Heres an overview of what each chapter covers: * Chapter 1: Introduction. This chapter provides a quick overview of the book and a brief history of Disciplined Agile. * Chapter 2: Reality over Rhetoric. This chapter explores several common myths about DAD and more importantly disproves them. * Chapter 3: Disciplined Agile Delivery in a Nutshell. This chapter provides a brief yet comprehensive overview of the DAD framework. * Chapter 4: Introduction to the Case Study. This chapter introduces us to the team, describes the market opportunity that they hope to address, and describes the environment in which theyre working. * Chapter 5: Inception. The teams initiation effort includes initial requirements modeling and planning with their stakeholders in a streamlined manner, initial architecture modeling, setting up their physical work environment, setting up the start of their tooling infrastructure, initial risk identification, and finally securing stakeholder support and funding for the rest of the first release. * Chapters 6 through 10: Construction. These chapters each describe a single Construction iteration, sharing the teams experiences during each of those two-week timeboxes. * Chapter 11: Transition. The two-week transition phase focuses on final testing and fixing, training the support/help-desk staff, finishing a few short end-user how to videos, and deploying the solution into production. * Chapter 12: Future Releases. This chapter overviews the teams improvement efforts over the next few releases, describing how they evolve from the agile Scrum-based lifecycle to a leaner approach and eventually to continuous delivery. * Chapter 13: Closing Thoughts. This chapter overviews the disciplined agile resources that are available to you. * Appendix: The Disciplined Agile IT Department. This short appendix overviews our ongoing work on the Disciplined Agile framework to address the full scope of an IT department. At 102 pages, you should find this book to be a quick, informative read.}
}
@inproceedings{10.1145/3486611.3492413,
author = {Mitzutani, Iori and Ramanathan, Ganesh and Mayer, Simon},
title = {Semantic Data Integration with DevOps to Support Engineering Process of Intelligent Building Automation Systems},
year = {2021},
isbn = {9781450391146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486611.3492413},
doi = {10.1145/3486611.3492413},
abstract = {The reliable infrastructure of building automation (BA) systems forms the foundation of smart environments and energy systems in our building towards increasing occupant comfort and safety while reducing the ecological footprint of buildings. This is achieved through the processing of data points collected from sensors and the control of installed actuators, and increasingly incorporates machine learning components. However, engineering of BA systems is intricately linked with the planning, installation, (pre-)commissioning, and operation of building services such as HVAC, and it requires an extensive amount of manual coordination which is often prone to errors, many of which are only detected late in the lifecycle and tends to lose transparency in data provenance. To address this, we propose the application of DevOps, a highly successful paradigm in the field of software engineering, to BA engineering process coordination. In addition, the possibility of using semantic data to develop artifacts such as requirements, construction, and devices of BA systems opens up the avenue of achieving continuous verification of the system as it is built and commissioned. Concretely, we propose a novel approach that integrates a semantic reasoner using the machine-understandable data of the building along with interactions facilitated by Web of Thing Thing Description to the DevOps workflow. The proposed approach is expected to ameliorate limitations of existing workflow management methods and thus provide transparency in the data provenance to gain trust for data-driven AI applications for BA.},
booktitle = {Proceedings of the 8th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {294–297},
numpages = {4},
keywords = {cyber-physical systems, building automation, provenance, semantic data, explainable CPS, DevOps},
location = {Coimbra, Portugal},
series = {BuildSys '21}
}
@inproceedings{10.1145/2791060.2791080,
author = {Van Landuyt, Dimitri and Walraven, Stefan and Joosen, Wouter},
title = {Variability Middleware for Multi-Tenant SaaS Applications: A Research Roadmap for Service Lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791080},
doi = {10.1145/2791060.2791080},
abstract = {Software product line engineering (SPLE) and variability enforcement techniques have been applied to run-time adaptive systems for quite some years, also in the context of multi-tenant Software-as-a-Service (SaaS) applications. The focus has been mainly on (1) the pre-deployment phases of the development life cycle and (2) fine-grained (tenant-level), run-time activation of specific variants. However, with upcoming trends such as DevOps and continuous delivery and deployment, operational aspects become increasingly important.In this paper, we present our integrated vision on the positive interplay between SPLE and adaptive middleware for multi-tenant SaaS applications, focusing on the operational aspects of running and maintaining a successful SaaS offering. This vision, called Service Lines, is based on and motivated by our experience and frequent interactions with a number of Belgian SaaS providers.We concretely highlight and motivate a number of operational use cases that require advanced variability support in middleware and have promising added value for the economic feasibility of SaaS offerings. In addition, we provide a gap analysis of what is currently lacking from the perspectives of variability modeling and management techniques and middleware support, and as such sketch a concrete roadmap for continued research in this area.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {211–215},
numpages = {5},
keywords = {run-time variability, service lines, multi-tenant SaaS, variability middleware, models at run time, operational support},
location = {Nashville, Tennessee},
series = {SPLC '15}
}
@inbook{10.1145/3394171.3414535,
author = {Zhang, Huaizheng and Li, Yuanming and Huang, Yizheng and Wen, Yonggang and Yin, Jianxiong and Guan, Kyle},
title = {MLModelCI: An Automatic Cloud Platform for Efficient MLaaS},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3414535},
abstract = {MLModelCI provides multimedia researchers and developers with a one-stop platform for efficient machine learning (ML) services. The system leverages DevOps techniques to optimize, test, and manage models. It also containerizes and deploys these optimized and validated models as cloud services (MLaaS). In its essence, MLModelCI serves as a housekeeper to help users publish models. The models are first automatically converted to optimized formats for production purpose and then profiled under different settings (e.g., batch size and hardware). The profiling information can be used as guidelines for balancing the trade-off between performance and cost of MLaaS. Finally, the system dockerizes the models for ease of deployment to cloud environments. A key feature of MLModelCI is the implementation of a controller, which allows elastic evaluation which only utilizes idle workers while maintaining online service quality. Our system bridges the gap between current ML training and serving systems and thus free developers from manual and tedious work often associated with service deployment. We release the platform as an open-source project on GitHub under Apache 2.0 license, with the aim that it will facilitate and streamline more large-scale ML applications and research projects.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {4453–4456},
numpages = {4}
}
@book{10.5555/3086719,
author = {Vyas, Uchit},
title = {Applied OpenStack Design Patterns: Design Solutions for Production-Ready Infrastructure with OpenStack Components},
year = {2016},
isbn = {1484224531},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Learn practical and applied OpenStack cloud design solutions to gain maximum control over your infrastructure. You will achieve a complete controlled and customizable platform. Applied OpenStack Design Patternsteaches you how to map your application flow once you set up components and architectural design patterns. Also covered is storage management and computing to map user requests and allocations. Best practices of High Availability and Native Cluster Management are included. Solutions are presented to network components of OpenStack and to reduce latency and enable faster communication gateways between components of OpenStack and native applications. What You Will Learn: Design a modern cloud infrastructureSolve complex infrastructure application problems Understand OpenStack cloud infrastructure components Adopt a business impact analysis to support existing/new cloud infrastructure Use specific components to integrate an existing tool-chain set to gain agility and a quick, continuous delivery model Who This Book Is For: Seasoned solution architects, DevOps, and system engineers and analysts}
}
@book{10.5555/3067054,
author = {Watson, Paul},
title = {Advanced Selenium in Java: With Examples},
year = {2016},
isbn = {1535485701},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
edition = {1st},
abstract = {This book is for software developers, automation testers, Devops and engineers working on selenium automation testing project. Whether you are a beginner or an experienced developer, this book will help you master the skills on Selenium. The book starts with introduction of Selenium and then dives into key concepts like setting up project in IntelliJ, integration with Junit and TestNG, integration with build tools like Gradle and Maven. You will also learn how to integrate selenium with Cucumber. In the end, you will learn how to run the Selenium tests on CI servers like TeamCity, Bamboo and Jenkins. You will also learn how to work with various types of frameworks like Page object models, Page factory Keyword driven frameworks etc. Book also touches the concepts related to mobile automation using Selenium.}
}
@article{10.1002/smr.2174,
author = {O'Connor, Rory V. and Houston, Dan and Hebig, Regina and Kuhrmann, Marco},
title = {ICSSP 2018—Special Issue Introduction},
year = {2019},
issue_date = {May 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {5},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2174},
doi = {10.1002/smr.2174},
abstract = {The International Conference on Software and System Processes (ICSSP) provides a leading forum for the exchange of research outcomes and industrial best practices in process development from software and systems disciplines. ICSSP&nbsp;2018 was held in Gothenburg, Sweden, May 26 to 27, 2018, colocated with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying “Demands on Processes, Processes on Demand” by recognizing the demands on processes that include the need for both well‐developed plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model‐based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise‐level architectures. This special issue includes the revised and extended versions of the five highest ranked full research papers and industry experience papers of ICSSP&nbsp;2018, including the two award‐winning papers.},
journal = {J. Softw. Evol. Process},
month = {may},
numpages = {5},
keywords = {hybrid systems development, project management, continuous development, agile methods, data science, deployment, product duality}
}
@inproceedings{10.1109/SBST.2019.00009,
author = {Martin, Diego and Panichella, Sebastiano},
title = {The Cloudification Perspectives of Search-Based Software Testing},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SBST.2019.00009},
doi = {10.1109/SBST.2019.00009},
abstract = {To promote and sustain the future of our society, the most critical challenge of contemporary software engineering and cloud computing experts are related to the efficient integration of emerging cloudification and DevOps practices in the development and testing processes of modern systems. In this context, we argue that SBST can play a critical role in improving testing practices and automating the verification and validation (V&amp;V) of cloudification properties of Cloud Native Applications (CNA). Hence, in this paper, we focus on the untouched side of SBST in the cloud field, by discussing (1) the testing challenges in the cloud research field and (2) summarizing the recent contributions of SBST in supporting development practices of CNA. Finally, we discuss the emerging research topics characterizing the cloudification perspectives of SBST in the cloud field.},
booktitle = {Proceedings of the 12th International Workshop on Search-Based Software Testing},
pages = {5–6},
numpages = {2},
keywords = {test suite generation, search-based software testing, cloud native applications},
location = {Montreal, Quebec, Canada},
series = {SBST '19}
}
@book{10.5555/2544043,
author = {Helmke, Matthew},
title = {Ubuntu Unleashed 2014 Edition: Covering 13.10 and 14.04},
year = {2013},
isbn = {0672336936},
publisher = {Sams publishing},
edition = {9th},
abstract = {Ubuntu Unleashed 2014 Edition is filled with unique and advanced information for everyone who wants to make the most of the Linux-based Ubuntu operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 13.10 and the forthcoming Ubuntu 14.04. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 13.10/14.04 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find new or improved coverage of Ubuntus Unity interface, various types of servers, software repositories, database options, virtualization and cloud services, development tools, monitoring, troubleshooting, Ubuntus push into mobile and other touch screen devices, and much more. Matthew Helmke served from 2006 to 2011 on the Ubuntu Forum Council, providing leadership and oversight of the Ubuntu Forums, and spent two years on the Ubuntu regional membership approval board for Europe, the Middle East, and Africa. He has written about Ubuntu for several magazines and websites and is the lead author of The Official Ubuntu Book. He works for Pearson Education writing technical documentation for educational testing software. Detailed information on how to Configure and customize the Unity desktop Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, DNS, and HTTP servers (Apache, Nginx, or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust Learn about Ubuntus work toward usability on touch-screen and phone devices Ubuntu 13.10 on DVD DVD includes the full Ubuntu 13.10 distribution for Intel x86 computers as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Kick Start Chapter! Purchase this book and receive a free Ubuntu 14.04 Kick Start chapter after Ubuntu 14.04 is released. See inside back cover for details}
}
@article{10.1109/MS.2017.442103917,
author = {Biddle, Robert and Brown, Judith M. and Greenspan, Steven},
title = {From Incident to Insight: Incident Responders and Software Innovation},
year = {2019},
issue_date = {January 2019},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {36},
number = {1},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2017.442103917},
doi = {10.1109/MS.2017.442103917},
abstract = {Over The Last decade, new software processes have appeared that emphasize collaboration among people involved in creating successful software. For example, agile methods stress collaboration between development teams and business clients, 1 and DevOps emphasizes better collaboration between development teams and deployment teams.},
journal = {IEEE Softw.},
month = {jan},
pages = {56–62},
numpages = {7}
}
@inproceedings{10.1007/978-3-030-65310-1_40,
author = {Kitajima, Shinya and Sekiguchi, Atsuji},
title = {Latest Image Recommendation Method for Automatic Base Image Update in&nbsp;Dockerfile},
year = {2020},
isbn = {978-3-030-65309-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-65310-1_40},
doi = {10.1007/978-3-030-65310-1_40},
abstract = {In recent years, an application deployment method using Docker container has attracted attention by researchers. Docker containers are fast and lightweight, can improve the portability and reproducibility of applications, and are thus often used with CI/CD and DevOps to accelerate the release cycle. However, if a Docker image is not updated, problems such as security risks or a lack of the latest features may occur. Therefore, in this paper, we propose a method for automatically updating the base image to the latest version when the image is considered to be the old version. Our method extracts the information of the base image from the Dockerfile described by the user, and infers the version of the base image that is considered to be certainly used. By applying our method, the user can regularly update the base image. Based on the evaluation result, we confirmed that our method recommends an approximately correct version to the users.},
booktitle = {Service-Oriented Computing: 18th International Conference, ICSOC 2020, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings},
pages = {547–562},
numpages = {16},
keywords = {Dockerfile, Semantic versioning, PaaS, Automatic update},
location = {Dubai, United Arab Emirates}
}
@inproceedings{10.1145/3183519.3183544,
author = {Li, Heng and Chen, Tse-Hsun (Peter) and Hassan, Ahmed E. and Nasser, Mohamed and Flora, Parminder},
title = {Adopting Autonomic Computing Capabilities in Existing Large-Scale Systems: An Industrial Experience Report},
year = {2018},
isbn = {9781450356596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183519.3183544},
doi = {10.1145/3183519.3183544},
abstract = {In current DevOps practice, developers are responsible for the operation and maintenance of software systems. However, the human costs for the operation and maintenance grow fast along with the increasing functionality and complexity of software systems. Autonomic computing aims to reduce or eliminate such human intervention. However, there are many existing large systems that did not consider autonomic computing capabilities in their design. Adding autonomic computing capabilities to these existing systems is particularly challenging, because of 1) the significant amount of efforts that are required for investigating and refactoring the existing code base, 2) the risk of adding additional complexity, and 3) the difficulties for allocating resources while developers are busy adding core features to the system. In this paper, we share our industrial experience of re-engineering autonomic computing capabilities to an existing large-scale software system. Our autonomic computing capabilities effectively reduce human intervention on performance configuration tuning and significantly improve system performance. In particular, we discuss the challenges that we encountered and the lessons that we learned during this re-engineering process. For example, in order to minimize the change impact to the original system, we use a variety of approaches (e.g., aspect-oriented programming) to separate the concerns of autonomic computing from the original behaviour of the system. We also share how we tested such autonomic computing capabilities under different conditions, which has never been discussed in prior work. As there are numerous large-scale software systems that still require expensive human intervention, we believe our experience provides valuable insights to software practitioners who wish to add autonomic computing capabilities to these existing large-scale software systems.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
pages = {1–10},
numpages = {10},
keywords = {performance engineering, software testing, software re-engineering, autonomic computing},
location = {Gothenburg, Sweden},
series = {ICSE-SEIP '18}
}
@book{10.5555/3383743,
author = {Goericke, Stephan},
title = {The Future of Software Quality Assurance},
year = {2019},
isbn = {3030295087},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {This open access book, published to mark the 15th anniversary of the International Software Quality Institute (iSQI), is intended to raise the profile of software testers and their profession. It gathers contributions by respected software testing experts in order to highlight the state of the art as well as future challenges and trends. In addition, it covers current and emerging technologies like test automation, DevOps, and artificial intelligence methodologies used for software testing, before taking a look into the future. The contributing authors answer questions like: "How is the profession of tester currently changing? What should testers be prepared for in the years to come, and what skills will the next generation need? What opportunities are available for further training today? What will testing look like in an agile world that is user-centered and fast-paced? What tasks will remain for testers once the most important processes are automated?" iSQI has been focused on the education and certification of software testers for fifteen years now, and in the process has contributed to improving the quality of software in many areas. The papers gathered here clearly reflect the numerous ways in which software quality assurance can play a critical role in various areas. Accordingly, the book will be of interest to both professional software testers and managers working in software testing or software quality assurance.}
}
@inproceedings{10.1145/3219104.3219147,
author = {Sampedro, Zebula and Holt, Aaron and Hauser, Thomas},
title = {Continuous Integration and Delivery for HPC: Using Singularity and Jenkins},
year = {2018},
isbn = {9781450364461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219104.3219147},
doi = {10.1145/3219104.3219147},
abstract = {Continuous integration, delivery, and deployment (CICD) is widely used in DevOps communities, as it allows for teams of all sizes to deploy rapidly-changing hardware and software resources quickly and confidently. In this paper, we will describe how University of Colorado Boulder Research Computing has adopted these practices on the RMACC Summit supercomputer [17] to allow system engineers and researchers alike to capitalize on the benefits of CICD-centric development workflows. We will introduce the topic of CICD at a high level and describe how such practices can ease common software management challenges for High-Performance Computing (HPC) resources. We will then document the infrastructure deployed for Summit, and explain how software such as Jenkins and Singularity enabled adaptation for an HPC environment. We will conclude with two case studies discussing the use of our CICD infrastructure: one case study from the perspective of a system engineer maintaining user-facing resources, and the other case study from the perspective of a researcher developing, maintaining, and using the MFiX-Exa codebase.},
booktitle = {Proceedings of the Practice and Experience on Advanced Research Computing},
articleno = {6},
numpages = {6},
keywords = {continuous deployment, software builds, continuous integration, containers, software automation, continuous delivery, MFIX-Exa, Singularity},
location = {Pittsburgh, PA, USA},
series = {PEARC '18}
}
@inproceedings{10.1109/ICSE-SEIP52600.2021.00024,
author = {Islam, Mohammad S. and Pourmajidi, William and Zhang, Lei and Steinbacher, John and Erwin, Tony and Miranskyy, Andriy},
title = {Anomaly Detection in a Large-Scale Cloud Platform},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00024},
doi = {10.1109/ICSE-SEIP52600.2021.00024},
abstract = {Cloud computing is ubiquitous: more and more companies are moving the workloads into the Cloud. However, this rise in popularity challenges Cloud service providers, as they need to monitor the quality of their ever-growing offerings effectively. To address the challenge, we designed and implemented an automated monitoring system for the IBM Cloud Platform. This monitoring system utilizes deep learning neural networks to detect anomalies in near-real-time in multiple Platform components simultaneously.After running the system for a year, we observed that the proposed solution frees the DevOps team's time and human resources from manually monitoring thousands of Cloud components. Moreover, it increases customer satisfaction by reducing the risk of Cloud outages.In this paper, we share our solutions' architecture, implementation notes, and best practices that emerged while evolving the monitoring system. They can be leveraged by other researchers and practitioners to build anomaly detectors for complex systems.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {150–159},
numpages = {10},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}
@inproceedings{10.1145/2814189.2833204,
author = {Gray, Jeff and Sprinkle, Jonathan and Tolvanen, Juha-Pekka and Rossi, Matti},
title = {Workshop Preview of the 15th Workshop on Domain Specific Modeling (DSM 2015)},
year = {2015},
isbn = {9781450337229},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814189.2833204},
doi = {10.1145/2814189.2833204},
abstract = {Domain-specific languages provide a viable and time-tested solution for continuing to raise the level of abstraction, and thus productivity, beyond coding, making systems development faster and easier. When accompanied with suitable automated modeling tools and generators it delivers to the promises of continuous delivery and devops. In domain-specific modeling (DSM) the models are constructed using concepts that represent things in the application domain, not concepts of a given programming language. The modeling language follows the domain abstractions and semantics, allowing developers to perceive themselves as working directly with domain concepts. Together with frameworks and platforms, DSM can automate a large portion of software production. This paper introduces Domain-Specific Modeling and describes the SPLASH 2015 workshop, to be held on 27th of October in Pittsburgh, PA, which is the 15th anniversary of the event.},
booktitle = {Companion Proceedings of the 2015 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity},
pages = {101–102},
numpages = {2},
keywords = {Metamodeling, Code Generation, Modeling Languages, Domain-Specific Languages},
location = {Pittsburgh, PA, USA},
series = {SPLASH Companion 2015}
}
@proceedings{10.1145/3202710,
title = {ICSSP '18: Proceedings of the 2018 International Conference on Software and System Process},
year = {2018},
isbn = {9781450364591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The ICSSP conference, continuing the success of the Software Process Workshop (SPW), the Workshop on Software Process Simulation Modeling (ProSim) and the International Conference on Software Process (ICSP) conference series, has become an established premier event in the field of software and systems engineering. It provides a leading forum for the exchange of academic research results and industrial best-practices in process development and evolution on software and systems disciplines.Software and system process decision-making is becoming more challenging for development organizations. These organizations are incorporating engineering advances, seeking to meet expectations of their customers, and responding to the economic pressures of markets. The resulting demands on processes include the need for both well-developed plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures.In response to these demands, process stakeholders---process engineers responsible for designing and implementing processes, managers or coaches who staff and guide them, researchers who study and improve them, tools developers who support and facilitate them, and developers and sustainers who use and tailor them---are producing more varieties of processes and doing so more often. Just as agility is required more frequently in product development, it is also being demanded in processes while maintaining their essential purposes of coordination and communication. Demands on processes are requiring processes on demand. Providing processes on demand is challenging for process designers. They must be able to select compatible process elements for a specific set of situational factors, to assess the risks in and forecast outcomes of a process design or improvement, to specify methods of implementation, and to monitor an enacted process quantitatively and identify needs for modifications. These capabilities require specialized knowledge and engineering methods from researchers.ICSSP 2018 has the conference theme "Demands on Processes, Processes on Demand" and seeks to explore the demands on processes that are requiring more variety and responsiveness in process development.},
location = {Gothenburg, Sweden}
}
@inproceedings{10.1109/IC2E.2014.32,
author = {Wettinger, Johannes and Andrikopoulos, Vasilios and Strauch, Steve and Leymann, Frank},
title = {Characterizing and Evaluating Different Deployment Approaches for Cloud Applications},
year = {2014},
isbn = {9781479937660},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/IC2E.2014.32},
doi = {10.1109/IC2E.2014.32},
abstract = {Fully automated provisioning and deployment in order to reduce the costs for managing applications is one of the most essential requirements to make use of the benefits of Cloud computing. Several approaches and tools are available to automate the involved processes. The DevOps community, for example, provides tooling and artifacts to realize deployment automation on Infrastructure as a Service level in a mostly application-oriented manner. Platform as a Service frameworks are also available for the same purpose. In this paper we categorize and characterize available deployment approaches independently from the underlying technology used. For this purpose, we choose Web applications with different technology stacks and analyze their specific deployment requirements. Afterwards, we provision these applications using each of the identified types of deployment approaches in the Cloud. Finally, we discuss the evaluation results and derive recommendations which deployment approach to use based on the deployment requirements of an application.},
booktitle = {Proceedings of the 2014 IEEE International Conference on Cloud Engineering},
pages = {205–214},
numpages = {10},
keywords = {Cloud computing, application-oriented deployment, middleware-oriented deployment, DevOps, decision support},
series = {IC2E '14}
}
@book{10.5555/3019454,
author = {Mason, Scott and Blackburn, Chris and Swarts, Emile and Ashton, Seb and Winter, David and Foster, Richard and MacDonald, Rory and Morton, Luke and Wood, Nick and Dudhia, Fareed},
title = {A Field Guide To Continuous Delivery},
year = {2016},
isbn = {1530121418},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
abstract = {For teams of software engineers, it's important to be able to deliver great software reliably and quickly, whilst keeping pain points to an absolute minimum. Contrary to traditional software delivery practices, Continuous Delivery allows teams to get software into the hands of their customers at a much faster rate by encouraging greater communication, more frequent collaboration and by automating as much of your deployment process as possible. Written by the team at Made Tech, this book consists of ten chapters, each of which covers a different facet of Continuous Delivery. Over the course of the book, youll learn: What Continuous Delivery is:Discover how and why it was created, and what it ultimately means to practice Continuous Delivery. What the benefits areContinuous Delivery can impact your business in many different, positive ways, and this book discusses the most significant benefits you'll encounter, from minimising risk during deployments, to bringing new features to market much more quickly. How to prepare your team for the transition to a new way of workingPracticing Continuous Delivery brings with it fundamental changes to the way work is approached, and change can famously be difficult at times. Learn how to deal with the most concerns you'll face. The tools you'll needContinuous Delivery falls under the huge umbrella that is DevOps, so it's important to know which tools you should be looking out for to get you started, and what options you have available. How to setup the most important tool: the pipelineThe pipeline is the backbone of any team that practices Continuous Delivery, and this book will teach you how to build yours from the ground up, from development to production. How to keep quality highGood Continuous Delivery allows you to spend more time writing quality software, and the book details a number of best practices worth adopting that will facilitate great code, from feature toggles to test-driven development. The challenges you may faceA single team adopting Continuous Delivery may find it relatively simple, but an entire organisation will face significantly more challenges. This book will teach you how to overcome those challenges, and how you can keep evolving your Continuous Delivery practices to negate any new problems that may arise.}
}
@inproceedings{10.1109/SEAMS.2017.12,
author = {Barna, Cornel and Khazaei, Hamzeh and Fokaefs, Marios and Litoiu, Marin},
title = {Delivering Elastic Containerized Cloud Applications to Enable DevOps},
year = {2017},
isbn = {9781538615508},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEAMS.2017.12},
doi = {10.1109/SEAMS.2017.12},
abstract = {Following recent technological advancements in software systems, like microservices, containers and cloud systems, DevOps has risen as a new development paradigm. Its aim is to bridge the gap between development and management of software systems and enable continuous development, deployment and integration. Towards this end, automated tools and management systems play a crucial role. In this work, we propose a method to develop an autonomic management system for multitier, multi-layer data-intensive containerized applications based on a performance model of such systems. The model is shown to be robust and accurate in estimating and predicting the system's performance for various workloads and topologies, while the AMS is capable of regulating the application's behaviour by taking independent actions on its various parts.},
booktitle = {Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {65–75},
numpages = {11},
keywords = {continuous delivery, autonomic management systems, multi-tier big data applications, scaling, containers, performance models, cloud computing, devops},
location = {Buenos Aires, Argentina},
series = {SEAMS '17}
}
@inbook{10.1145/3387940.3391455,
author = {Leite, Leonardo and Kon, Fabio and Pinto, Gustavo and Meirelles, Paulo},
title = {Platform Teams: An Organizational Structure for Continuous Delivery},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391455},
abstract = {Software-producing organizations are seeking to release faster and more efficiently new versions of their products to their customers to remain competitive in the fierce software market. Continuous delivery practices arise as a potential solution since every commit to the repository could result in a production-candidate version of a product, accelerating time to market, and improving customer satisfaction. In this work, we employed Grounded Theory to investigate how organizations pursuing continuous delivery should organize their development and operations teams. We collected data from 27 IT professionals. After a careful analysis, we started the elaboration of a taxonomy with four patterns of organizational structures: (1) siloed departments, (2) classical DevOps, (3) cross-functional teams, and (4) platform teams. We observed that the platform team structure is the most distinctive classification of our taxonomy, and it has promising results regarding delivery performance. Some relevant aspects we found out about platform teams include: infrastructure specialists need coding skills; product teams have to operate their business services; and much of the non-functional concerns are handled by the platform, alleviating product teams.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {505–511},
numpages = {7}
}
@book{10.5555/3379065,
author = {Bell, Charles},
title = {Introducing MySQL Shell: Administration Made Easy with Python},
year = {2019},
isbn = {1484250826},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Use MySQL Shell, the first modern and advanced client for connecting to and interacting with MySQL. It supports SQL, Python, and JavaScript. That's right! You can write Python scripts and execute them within the shell interactively, or in batch mode. The level of automation available from Python combined with batch mode is especially helpful to those practicing DevOps methods in their database environments. Introducing MySQL Shell covers everything you need to know about MySQL Shell. You will learn how to use the shell for SQL, as well as the new application programming interfaces for working with a document store and even automating your management of MySQL servers using Python. The book includes a look at the supporting technologies and concepts such as JSON, schema-less documents, NoSQL, MySQL Replication, Group Replication, InnoDB Cluster, and more. MySQL Shell is the client that developers and database administrators have been waiting for. Far more powerful than the legacy client, MySQL Shell enables levels of automation that are useful not only for MySQL, but in the broader context of your career as well. Automate your work and build skills in one of the most in-demand languages. With MySQL Shell, you can do both! What You'll Learn Use MySQL Shell with the newest features in MySQL 8 Discover what a Document Store is and how to manage it with MySQL Shell Configure Group Replication and InnoDB Cluster from MySQL Shell Understand the new MySQL Python application programming interfaces Write Python scripts for managing your data and the MySQL high availability features Who This Book Is For Developers and database professionals who want to automate their work and remain on the cutting edge of what MySQL has to offer. Anyone not happy with the limited automation capabilities of the legacy command-line client will find much to like in this book on the MySQL Shell that supports powerful automation through the Python scripting language.}
}
@book{10.5555/2685933,
author = {Morain, Jeanne M. and Mangione, Sheila},
title = {ISpeak Cloud: Crossing the Cloud Chasm Create a Cohesive Cloud Strategy},
year = {2014},
isbn = {0984675728},
publisher = {Coolmody, LLC},
address = {Gilbert, AZ, USA},
edition = {1st},
abstract = {iSpeak Cloud: Crossing the Cloud Chasm takes the reader through a realistic journey that many companies face when creating their overall cloud strategy. Join the executive team at Universal Kingdom as they apply best practices, lessons learned and practical intuition in overcoming many of the challenges faced in creating a cohesive cloud strategy. iSpeak Cloud is unique in that it takes the perspective across functional roles based on real world interviews to enable the reader to identify with real life challenges and best practices for overcoming them to cross the "chasm" between business and technology. iSpeak Cloud will challenge some of the conventional IT thinking that has led to the current state of Cloud Stall and Sprawl within the traditional enterprise. It will help you identify how to properly build your business case and strategy to insure the "juice is worth the squeeze" for maximum benefit with less costs to the business. Many have raced to the cloud only to be disappointed when it was unable to deliver the key benefits at a cost that made sense for the business. This has led to Consumerization of IT, Shadow IT, and general distrust from the Business with their counterparts. How do you cross the "Cloud Chasm" to create a cohesive Cloud strategy between business and technology? Although each company's journey will vary there will be certain challenges that impact nearly every customer out there. iSpeak Cloud highlights those challenges and best practice solutions for overcoming them based on over 100 interviews across functional roles from vendor to the customer. iSpeak Cloud enables the reader to transcend the gap between business and technology by walking them through a 3 Day Workshop that illustrates a typical day in the life of executives faced with creating a comprehensive cloud strategy. Join Charles the CIO of Universal Kingdom and Kayla Coletrain - his resident Cloud expert as they leverage templates and best practices that have been enhanced over 2 decades of implementation across small to large enterprise customers to address common challenges highlighted by interviewees. The step by step workshop enables you to envision key steps needed to cross the cloud chasm from addressing a cohesive DevOps, Agile, Costing, and Requirements gathering strategies. If you are looking to tame your Hybrid Cloud Hydra - look no further, iSpeak Cloud will enable you to identify challenges, address lessons learned and apply best practices to your Cohesive Cloud roadmap.}
}
@book{10.5555/2808968,
author = {Tejada, Zoiner and Bustamante, Michele Leroux and Ellis, Ike},
title = {Exam Ref 70-532 Developing Microsoft Azure Solutions},
year = {2015},
isbn = {0735697043},
publisher = {Microsoft Press},
address = {USA},
edition = {1st},
abstract = {Prepare for Microsoft Exam 70-532--and help demonstrate your real-world mastery of Microsoft Azure solution development. Designed for experienced developers ready to advance their status, Exam Ref focuses on the critical-thinking and decision-making acumen needed for success at the Microsoft Specialist level. Focus on the expertise measured by these objectives: Design and implement Websites Create and manage Virtual Machines Design and implement Cloud Services Design and implement a storage strategy Manage application and network services This Microsoft Exam Ref: Organizes its coverage by exam objectives Features strategic, what-if scenarios to challenge you Will be valuable for Microsoft Azure developers, solution architects, DevOps engineers, and QA engineers Assumes you have experience designing, programming, implementing, automating, and monitoring Microsoft Azure solutions and that you are proficient with tools, techniques, and approaches for building scalable, resilient solutions Developing Microsoft Azure SolutionsAbout the Exam Exam 70-532 focuses on the skills and knowledge needed to develop Microsoft Azure solutions that include websites, virtual machines, cloud services, storage, application services, and network services. About Microsoft Certification Passing this exam earns you a Microsoft Specialist certification in Microsoft Azure, demonstrating your expertise with the Microsoft Azure enterprise-grade cloud platform. You can earn this certification by passing Exam 70-532, Developing Microsoft Azure Solutions; or Exam 70-533, Implementing Microsoft Azure Infrastructure Solutions; or Exam 70-534, Architecting Microsoft Azure Solutions. See full details at: microsoft.com/learning}
}
@inbook{10.1109/ICSE-SEIP52600.2021.00031,
author = {Shetty, Manish and Bansal, Chetan and Kumar, Sumit and Rao, Nikitha and Nagappan, Nachiappan and Zimmermann, Thomas},
title = {Neural Knowledge Extraction from Cloud Service Incidents},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00031},
abstract = {The move from boxed products to services and the widespread adoption of cloud computing has had a huge impact on the software development life cycle and DevOps processes. Particularly, incident management has become critical for developing and operating large-scale services. Prior work on incident management has heavily focused on the challenges with incident triaging and de-duplication. In this work, we address the fundamental problem of structured knowledge extraction from service incidents. We have built SoftNER, a framework for unsupervised knowledge extraction from service incidents. We frame the knowledge extraction problem as a Named-Entity Recognition task for extracting factual information. SoftNER leverages structural patterns like key-value pairs and tables for bootstrapping the training data. Further, we build a novel multitask learning based BiLSTM-CRF model which leverages not just the semantic context but also the data-types for named-entity extraction. We have deployed SoftNER at Microsoft, a major cloud service provider and have evaluated it on more than 2 months of cloud incidents. We show that the unsupervised machine learning pipeline has a high precision of 0.96. Our multi-task learning based deep learning model also outperforms the state of the art NER models. Lastly, using the knowledge extracted by SoftNER we are able to build significantly more accurate models for important downstream tasks like incident triaging.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {218–227},
numpages = {10}
}
@book{10.5555/3283429,
author = {Haff, Gordon},
title = {How Open Source Ate Software: Understand the Open Source Movement and So Much More},
year = {2018},
isbn = {1484238931},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Learn how free software became open source and how you can sell open source software. This book provides a historical context of how open source has thoroughly transformed how we write software, how we cooperate, how we communicate, how we organize, and, ultimately, how we think about business values. Youll look at project and community examples including Linux, BSD, Apache, and Kubernetes, understand the open source development model, and how open source has influenced approaches more broadly, even proprietary software, such as open betas. You'll also examine the flipside, the "Second Machine Age," and the challenges of open source-based business models. Today, open source serves as shorthand for much broader trends and behaviors. Its not just about a free (in all senses of the word) alternative to commercial software. It increasingly is the new commercial software. How Open Source Ate Softwarereveals how open source has much in common, and is often closely allied, with many other trends in business and society. You'll see how it enables projects that go beyond any individual company. That makes open source not just a story about software, but a story about almost everything. What You'll Learn Understand open source opportunities and challenges Sell software if youre giving it away Apply open source principles more broadly to openorg, devops, etc. Review which organizational incentives you can implement Who This Book Is For Anyone who has an interest in what is happening in open source and the open source community, and anyone who is contemplating making a business that involves open source.}
}
@book{10.5555/3360122,
author = {Chandrasekara, Chaminda and Herath, Pushpa},
title = {Hands-On Functional Test Automation: With Visual Studio 2017 and Selenium},
year = {2019},
isbn = {1484244109},
publisher = {APress},
edition = {1st},
abstract = {Get started with functional testing of both web apps and Windows apps using different test frameworks. This book will take you on a deep dive into integrating functional automation testing with deployment pipelines. Hands-On Functional Test Automation contains step-by-step lessons that will give you an understanding of how to do functional test automation using Selenium with C# and Python. Also, you will learn how to enhance your test automation development with third-party frameworks. You will configure test clients, run functional tests through Azure DevOps release management, and carry out performance and load-testing to gain a good understanding of how to do cloud-based load testing. Each lesson comprises an introduction to the related concepts to help you understand how things work. This will broaden your knowledge so you can implement test automation in the correct way. At the end of each lesson alternative options and other enhancement possibilities are discussed to allow you to do further exploration. You will: · Implement functional test automation of Windows and web applications · Use Visual Studio for load and performance testing · Configure and run cloud-based load testing · Integrate testing with deployment pipelines}
}
@article{10.1145/3282517.3302403,
author = {Kuhrmann, Marco and O'Connor, Rory V. and Houston, Dan and Hebig, Regina and Raffo, David},
title = {Summary of the International Conference on Software AndSystem Processes (ICSSP 2018)},
year = {2019},
issue_date = {October 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3282517.3302403},
doi = {10.1145/3282517.3302403},
abstract = {The International Conference on Software and System Processes (ICSSP), continuing the success of Software Process Workshop (SPW), the Software Process Modeling and Simulation Workshop (ProSim) and the International Conference on Software Process (ICSP) conference series, has become the established premier event in the eld of software and systems engineering processes. It provides a leading forum for the exchange of research outcomes and industrial best-practices in process development from software and systems disciplines. ICSSP 2018 was held in Gothenburg, Sweden, 26-27 May 2018, co-located with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying Demands on Processes, Processes on Demand" by recognizing the demands on processes that include the need for both well-developed plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures. Papers presented at ICSSP discussed these issues across di erent domains, providing concepts, evidence, and experiences.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {48–51},
numpages = {4},
keywords = {project management, deployment, agile methods, product quality, data science, hybrid systems development, continuous development}
}
@inproceedings{10.1145/2961111.2962642,
author = {Peppard, Joe},
title = {What about the Benefits? A Missing Perspective in Software Engineering},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962642},
doi = {10.1145/2961111.2962642},
abstract = {The software engineering community has always sought to build great software and continues to seek out ways and approaches for doing this. The UX movement emphasizes the usability of the developed product. Agile approaches like scrum focus on aligning the functionality and features of the final product more closely with user/customer/market requirements. The recent interest in DevOps has brought to the fore the need to address the challenges once software goes into production. Despite this, in an enterprise environment, great software does not necessarily translate into real business benefits; few investments fail because the software didn't work [1], [2]. The overwhelming evidence points to the need to actively manage to achieve the business benefits being sought [3], [4], [5], [6].This keynote presentation introduces the concepts and practices of benefits management and benefits realization that have emerged over the last 25 years. It highlights the issues and challenges in deploying software to deliver expected business outcomes. It suggests that this is a missing perspective in software engineering. Suggestions for how this perspective might be more closely integrated with software engineering are proposed.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {2},
numpages = {1},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}
@book{10.5555/2371232,
author = {Sacks, Matthew},
title = {Pro Website Development and Operations: Streamlining DevOps for Large-Scale Websites},
year = {2012},
isbn = {1430239697},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Pro Website Development and Operationsgives you the experience you need to create and operate a large-scale production website. Large-scale websites have their own unique set of problems regarding their designproblems that can get worse when agile methodologies are adopted for rapid results. Managing large-scale websites, deploying applications, and ensuring they are performing well often requires a full scale team involving the development and operations sides of the companytwo departments that don't always see eye to eye. When departments struggle with each other, it adds unnecessary complexity to the work, and that result shows in the customer experience. Pro Website Development and Operationsshows you how to streamline the work of web development and operations - incorporating the latestinsights and methodologies of DevOps - so that your large-scale website is up and running quickly, with little friction and extreme efficiency between divisions. This book provides critical knowledge for any developer engaged in delivering thebusiness and software engineering goals required tocreate and operatea large-scale production website. It addresses how developers can collaborate effectively with business and engineering teams to ensure applications are smoothly transitioned from product inception to implementation, and are properly deployed and managed. Pro Website Development and Operations provides unique insights into how systems, code, and process can all work together to make large-scale website development and operations ultra-efficient. What youll learn How to tear down efficiency-hampering walls between development and operations How to speed up product launches How to spend less time managing your IT infrastructure, andmore time speeding up team collaboration How to better understand how software engineering and system administration can work together How to improve communications between engineering and operations How to reduce software launch errors Who this book is for Software developers and engineers working to create professional, large-scale websites.}
}
@book{10.5555/2431409,
author = {Helmke, Matthew},
title = {Ubuntu Unleashed 2013 Edition: Covering 12.10 and 13.04},
year = {2012},
isbn = {0672336243},
publisher = {Sams publishing},
edition = {8th},
abstract = {Ubuntu Unleashed 2013 Edition is filled with unique and advanced information for everyone who wants to make the most of the Ubuntu Linux operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 12.10 (Quantal Quetzal) and the forthcoming Ubuntu 13.04. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 12.10/13.04 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and moreincluding intermediate-to-advanced techniques you wont find in any other book. Helmke presents up-to-the-minute introductions to Ubuntus key productivity and Web development tools, programming languages, hardware support, and more. Youll find new or improved coverage of navigation via Unity Dash, wireless networking, VPNs, software repositories, new NoSQL database options, virtualization and cloud services, new programming languages and development tools, monitoring, troubleshooting, and more. Configure and customize the Unity desktop and make the most of the Dash Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line (with added coverage of stdin, stdout, sdterr, redirection, and file comparison) Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, and HTTP servers (Apache or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust}
}
@article{10.1145/3282517.3302415,
author = {Kuhrmann, Marco and O'Connor, Rory V. and Houston, Dan and Hebig, Regina and Raffo, David},
title = {Summary of the International Conference on Software and System Processes (ICSSP 2018)},
year = {2019},
issue_date = {October 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3282517.3302415},
doi = {10.1145/3282517.3302415},
abstract = {The International Conference on Software and System Processes (ICSSP), continuing the success of Software Process Workshop (SPW), the Software Process Modeling and Simulation Workshop (ProSim) and the International Conference on Software Process (ICSP) conference series, has become the established premier event in the field of software and systems engineering processes. It provides a leading forum for the exchange of research outcomes and industrial best-practices in process development from software and systems disciplines. ICSSP 2018 was held in Gothenburg, Sweden, 26-27 May 2018, co-located with the 40th International Conference on Software Engineering (ICSE). The theme of ICSSP 2018 was studying Demands on Processes, Processes on Demand" by recognizing the demands on processes that include the need for both welldeveloped plans and incremental deliveries (agile and hybrid processes), utilization of increased automation (model-based engineering and DevOps), higher degrees of customer collaboration, comprehensive analysis of existing products for reuse (open source and COTS), and performance requirements of enterprise-level architectures. Papers presented at ICSSP discussed these issues across different domains, providing concepts, evidence, and experiences.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {54},
numpages = {1},
keywords = {product quality, data science, project management, hybrid systems development, continuous development, agile methods, deployment}
}
@inproceedings{10.1145/3084226.3084287,
author = {Sharma, Abhishek and Thung, Ferdian and Kochhar, Pavneet Singh and Sulistya, Agus and Lo, David},
title = {Cataloging GitHub Repositories},
year = {2017},
isbn = {9781450348041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3084226.3084287},
doi = {10.1145/3084226.3084287},
abstract = {GitHub is one of the largest and most popular repository hosting service today, having about 14 million users and more than 54 million repositories as of March 2017. This makes it an excellent platform to find projects that developers are interested in exploring. GitHub showcases its most popular projects by cataloging them manually into categories such as DevOps tools, web application frameworks, and game engines. We propose that such cataloging should not be limited only to popular projects. We explore the possibility of developing such cataloging system by automatically extracting functionality descriptive text segments from readme files of GitHub repositories. These descriptions are then input to LDA-GA, a state-of-the-art topic modeling algorithm, to identify categories. Our preliminary experiments demonstrate that additional meaningful categories which complement existing GitHub categories can be inferred. Moreover, for inferred categories that match GitHub categories, our approach can identify additional projects belonging to them. Our experimental results establish a promising direction in realizing automatic cataloging system for GitHub.},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
pages = {314–319},
numpages = {6},
keywords = {Genetic Algorithm, Latent Dirichlet Allocation, GitHub},
location = {Karlskrona, Sweden},
series = {EASE'17}
}
@book{10.5555/3265145,
author = {Saito, Hideto and Lee, Hui-Chuan Chloe and Hsu, Ke-Jou Carol},
title = {Kubernetes Cookbook: Practical Solutions to Container Orchestration, 2nd Edition},
year = {2018},
isbn = {1788837606},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Learn how to automate and manage your containers and reduce the overall operation burden on your system. Key Features Use containers to manage, scale and orchestrate apps in your organization Transform the latest concept of Kubernetes 1.10 into examples Expert techniques for orchestrating containers effectively Book Description Kubernetes is an open source orchestration platform to manage containers in a cluster environment. With Kubernetes, you can configure and deploy containerized applications easily. This book gives you a quick brush up on how Kubernetes works with containers, and an overview of main Kubernetes concepts, such as Pods, Deployments, Services and etc. This book explains how to create Kubernetes clusters and run applications with proper authentication and authorization configurations. With real-world recipes, you'll learn how to create high availability Kubernetes clusters on AWS, GCP and in on-premise datacenters with proper logging and monitoring setup. You'll also learn some useful tips about how to build a continuous delivery pipeline for your application. Upon completion of this book, you will be able to use Kubernetes in production and will have a better understanding of how to manage containers using Kubernetes. What you will learn Build your own container cluster Deploy and manage highly scalable, containerized applications with Kubernetes Build high-availability Kubernetes clusters Build a continuous delivery pipeline for your application Track metrics and logs for every container running in your cluster Streamline the way you deploy and manage your applications with large-scale container orchestration Who This Book Is For This book is for system administrators, developers, DevOps engineers, or any stakeholder who wants to understand how Kubernetes works using a recipe-based approach. Basic knowledge of Kubernetes and Containers is required.}
}
@book{10.5555/3006368,
author = {Rhett, Jo},
title = {Learning Puppet 4: A Guide to Configuration Management and Automation},
year = {2016},
isbn = {1491907665},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {If youre a system administrator, developer, or site reliability engineer responsible for handling hundreds or even thousands of nodes in your network, the Puppet configuration management tool will make your job a whole lot easier. This practical guide shows you what Puppet does, how it works, and how it can provide significant value to your organization. Through hands-on tutorials, DevOps engineer Jo Rhett demonstrates how Puppet manages complex and distributed components to ensure service availability. Youll learn how to secure configuration consistency across servers, clients, your router, and even that computer in your pocket by setting up your own testing environment. Learn exactly what Puppet is, why it was created, and what problems it solvesTailor Puppet to your infrastructure with a design that meets your specific needsWrite declarative Puppet policies to produce consistency in your systemsBuild, test, and publish your own Puppet modulesManage network devices such as routers and switches with puppet device and integrated Puppet agentsScale Puppet servers for high availability and performanceExplore web dashboards and orchestration tools that supplement and complement Puppet}
}
@book{10.5555/2682600,
author = {Chaganti, Ravikanth},
title = {Windows PowerShell Desired State Configuration Revealed},
year = {2014},
isbn = {1484200179},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Desired State Configuration (DSC) is a powerful new configuration management platform that makes it easier than ever to perform cross-platform configuration management of your infrastructure, whether on-premise or in the cloud. DSC provides the management platform and Application Programming Interface (API) that can be used with any programming language. Windows PowerShell Desired State Configuration Revealed will take you through this new technology from start to finish and demonstrates the DSC interfaces through Windows PowerShell. DSC allows you to manage target devices by simply declaring what state you want them to be in, using new declarative language extensions, rather than writing detailed instructions to get them into that state. This makes continuous delivery in Windows easier than ever before. In an environment where changes and deployments are happening all the time, DSC makes the necessary adjustments to the system so you dont have to. Windows PowerShell Desired State Configuration Revealed starts with an overview of the configuration management features in Windows, followed by a discussion of the architecture of DSC and its components. Youll then explore DSCs built-in features and resources, followed by some of the different methods provided for delivering configuration information within your ecosystem, and learn about configuration monitoring and reporting. In the latter part of the book, youll find out how to get more power out of DSC by writing your own custom DSC resources, including a range of useful examples, and the book concludes with vital information on deploying and troubleshooting DSC in a production environment, along with some expert tips and tricks you might find useful along the way. Windows PowerShell Desired State Configuration Revealed is your one-stop guide to this new technology and how it can change your working life for the better. What youll learn Why continuous delivery and configuration management are important Architecture and components of DSCHow to build the infrastructure required to automate configuration management How to use built-in resources and create configuration documents How to create custom DSC resources How to troubleshoot DSC configuration and custom resource issues Who this book is for Windows PowerShell Desired State Configuration Revealed is for IT administrators, developers and DevOps engineers working in Windows-based data center environments. With a little prior PowerShell scripting experience, this book can be used as an in-depth reference to creating, customizing and extending DSC in Windows. IT administrators with limited scripting experience will also find this book a useful overview of what DSC offers and how to use DSC resources to automate configuration management and deployment. DSC is available as part of Windows 8.1 and Windows Server 2012 R2. You can also get DSC on Windows 7, Windows Server 2008 R2 or Windows Server 2012 by installing Windows Management Framework 4.0.}
}
@inproceedings{10.1145/3383219.3383276,
author = {Li, Shanshan and Xu, Qianwen and Hou, Peiyu and Chen, Xiudi and Wang, Yanze and Zhang, He and Rong, Guoping},
title = {Exploring the Challenges of Developing and Operating Consortium Blockchains: A Case Study},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383276},
doi = {10.1145/3383219.3383276},
abstract = {Blockchain and smart contracts are being embraced by more and more industrial practitioners in multiple domains including agriculture, manufacturing, and healthcare. As a distributed, immutable, and partly public ledger, the consortium blockchain demonstrates its potential to enable trustworthy interoperability and collaboration between organizations. However, the mismatch between the unruled software engineering practices and the increased interest of the consortium blockchain technology may pose threats to the quality of systems implemented. To mitigate the possible threats, this study takes the angle of software engineering to systematically understand the challenges and possible solutions in terms of developing and operating a consortium blockchain-based system. For this purpose, we conducted a case study on a typical consortium blockchain-based system and exhaustively collected the data by two rounds in-depth interviews on practitioners of different roles in the case project. Based on the data analysis, eight pairs of challenges and potential solutions were identified, which cover the phases of the development and operation of consortium blockchains. Moreover, we also captured two implications after further analysis of the findings, which worth the special attention of researchers in the near future, i.e. DevOps and microservices for blockchain or smart contracts.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {398–404},
numpages = {7},
keywords = {DevOps, Consortium blockchain, microservices, smart contracts},
location = {Trondheim, Norway},
series = {EASE '20}
}
@article{10.1109/MS.2019.2947982,
author = {Zdun, Uwe and Wittern, Erik and Leitner, Philipp},
title = {Emerging Trends, Challenges, and Experiences in DevOps and Microservice APIs},
year = {2020},
issue_date = {Jan.-Feb. 2020},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {37},
number = {1},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2019.2947982},
doi = {10.1109/MS.2019.2947982},
abstract = {In August 2019, we organized the second Vienna Software Seminar (VSS) with the topic "DevOps and Microservice APIs."&lt;sup&gt;1&lt;/sup&gt; Embracing the positive reception of its first iteration in 2017,&lt;sup&gt;2&lt;/sup&gt; VSS is an opportunity for attendees to discuss recent software technologies, practices, and related research. The seminar's 34 participants included a mix of practitioners and academics, who were invited based on their roles and experiences. The explicit intention of the seminar was to provide ample opportunities for exchange and communication: six themed sessions consisted of one invited keynote and two lightning talks, giving different perspectives on the session?s topic and (ideally) sparking ideas for follow-up discussions. After the talks, all participants decided on subtopics for two to three breakout sessions (i.e., informal, self-organized discussions among interested participants). Breakout session topics included microservice security, tooling for application programming interface (API) evolution, serverless programming models, and identification of microservices using domaindriven design. The sessions provided opportunities for detailed discussions and identifying challenges to address in future collaborations. Toward the end of each session, all participants gathered once more to summarize the breakout discussions. Additional opportunities for communication were provided during shared lunch breaks and social events in the evenings.},
journal = {IEEE Softw.},
month = {jan},
pages = {87–91},
numpages = {5}
}
@inproceedings{10.1109/ESEM.2017.27,
author = {Wang, Yi},
title = {Characterizing Developer Behavior in Cloud Based IDEs},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ESEM.2017.27},
doi = {10.1109/ESEM.2017.27},
abstract = {Background: Cloud based integrated development environments (IDEs) are rapidly gaining popularity for its native support and potential to accelerate DevOps. However, there is little research of how developers behave when interacting with these environments.Aims: To develop empirical knowledge about how developers behave when interacting with cloud based IDEs to deal with programming tasks at various difficulty levels.Method: We conducted a user study using a cloud based IDE, JazzHub. We collected and coded session trace data, self-reported effort and frustration levels, and screen recordings.Results: We built a Markov activity transition model that describes the transitions among common development activities such as coding, debugging, and searching for information. It also captures extended interactions with remote resources. We correlated activity transition with different code growth trajectories. Conclusion: The findings are an early step toward realizing the potential for enhanced interactions in cloud based IDEs. Our study provides empirical evidence that may inspire the future evolution of cloud based IDE designs and features.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {48–57},
numpages = {10},
keywords = {activity transition, developer behavior, code growth trajectory, cloud based IDE},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}
@inproceedings{10.1145/3183377.3183387,
author = {Bai, Xiaoying and Li, Mingjie and Pei, Dan and Li, Shanshan and Ye, Deming},
title = {Continuous Delivery of Personalized Assessment and Feedback in Agile Software Engineering Projects},
year = {2018},
isbn = {9781450356602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183377.3183387},
doi = {10.1145/3183377.3183387},
abstract = {In recent years, Agile development has been adopted in project practices of Software Engineering (SE) courses. However, it is a great challenge to provide timely assessment and feedback to project teams and individual students with a frequency that catches up with iterative, incremental, and cooperative software development with continuous deliveries. Conventional project reviews are mostly dependent upon instructors and teaching assistants in a manual reviewing/mentoring approach, which are simply not scalable.In this paper, we argue that agile projects warrant a "continuous delivery" of personalized assessment and feedback. To this end, we propose an online-offline combined approach and built a system upon GitLab. An online platform was built by integrating DevOps tool chains so that personalized reports and assessments are delivered automatically to the teams/students, which serve as the very efficient trigger and basis for the close and targeted offline interactions between students and TAs: daily discussion over instant messaging and weekly in person meeting. This system has been in operation since 2014 for an undergraduate SE course, with over 500 students participating in over 130 project teams in total. Our results show that such a continuous assessment/feedback delivery system is very effective in educating Agile projects in SE courses.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {58–67},
numpages = {10},
keywords = {project, assessment, software engineering course, devops, agile},
location = {Gothenburg, Sweden},
series = {ICSE-SEET '18}
}
@book{10.5555/3278369,
author = {Riti, Pierluigi},
title = {Practical Scala DSLs: Real-World Applications Using Domain Specific Languages},
year = {2017},
isbn = {1484230353},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Build domain specific languages (DSLs) using Java's most popular functional programming language: Scala. This book introduces the basics of Scala and DSLs using a series of practical examples. In Practical Scala DSLs, youll learn to create pragmatic and complete code examples that explain the actual use of DSLs with Scala: a web API and microservices; a custom language; a mobile app; a Forex system; a game; and cloud applications. At the end of this unique book, youll be able to describe the differences between external and internal DSLs; understand when and how to apply DSLs; create DSLs using Scala; and even create a DSL using another programming language. What You'll Learn Build DSLs in Scala Write a web API and microservices Create a custom language Apply DSLs to mobile apps development, a Forex trading system, game development, and more Discover the role of DSLs in cloud development Integrate DSLs as part of a DevOps program or structure Build internal and external DSLs Who This Book Is For Experienced Java coders with at least some prior experience with Scala. You may be new to DSLs.}
}
@book{10.5555/3158961,
author = {Arundel, John},
title = {Puppet 4.10 Beginner's Guide: From Newbie to pro with Puppet 4.10, 2nd Edition},
year = {2017},
isbn = {1787124002},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Puppet is great for developers, system administrators, IT professionals, and anyone laying the foundation for DevOps practices - this comprehensive guide will get you up to speed, all the way from installation to automation to the latest features of Puppet 4.10. About This Book Develop skills to run Puppet 4.10 on single or multiple servers without hiccups Use Puppet to spin up and manage cloud resources such as Amazon EC2 instances Take full advantage of the powerful new features of Puppet 4.10, including loops, data types, structured facts, R10K module management, control repos, and EPP templates Who This Book Is ForPuppet Beginner's Guide, Second Edition is designed for those who are new to Puppet, including system administrators and developers who are looking to manage computer server systems for configuration management. No prior programming or system administration experience is assumed. What You Will Learn Covers the latest Puppet 4.10 release Install and set up Puppet and discover the latest and most advanced features Configure, build, and run containers in production using Puppet's industry-leading Docker support Deploy configuration files and templates at super-fast speeds and manage user accounts and access control Automate your IT infrastructure Use the latest features in Puppet 4 onward and its official modules Manage clouds, containers, and orchestration Get to know the best practices to make Puppet more reliable and increase its performance In Detail Puppet 4.10 Beginner's Guide, Second Edition, gets you up and running with the very latest features of Puppet 4.10, including Docker containers, Hiera data, and Amazon AWS cloud orchestration. Go from beginner to confident Puppet user with a series of clear, practical examples to help you manage every aspect of your server setup. Whether you're a developer, a system administrator, or you are simply curious about Puppet, you'll learn Puppet skills that you can put into practice right away. With practical steps giving you the key concepts you need, this book teaches you how to install packages and config files, create users, set up scheduled jobs, provision cloud instances, build containers, and so much more. Every example in this book deals with something real and practical that you're likely to need in your work, and you'll see the complete Puppet code that makes it happen, along with step-by-step instructions for what to type and what output you'll see. All the examples are available in a GitHub repo for you to download and adapt for your own server setup. Style and approach This tutorial is packed with quick step-by-step instructions that are immediately applicable for beginners. This is an easy-to-read guide, to learn Puppet from scratch, that explains simply and clearly all you need to know to use this essential IT power tool, while applying these solutions to real-world scenarios.}
}
@book{10.5555/3002514,
author = {Arora, Tarun},
title = {Microsoft Team Foundation Server Cookbook},
year = {2016},
isbn = {1784391050},
publisher = {Packt Publishing},
abstract = {Over 80 hands-on DevOps and ALM-focused recipes for Scrum Teams to enable the Continuous Delivery of high-quality Software... Faster!About This BookRelease high quality, reliable software quickly through building, testing, and deployment automationImprove the predictability, reliability, and availability of TFS in your organization by scheduling administration and maintenance activitiesExtend, customize, and integrate tools with TFS, enabling your teams to manage their application lifecycles effectivelyWho This Book Is ForThis book is aimed at software professionals including Developers, Testers, Architects, Configuration Analysts, and Release Managers who want to understand the capabilities of TFS to deliver better quality software faster.A working setup of TFS 2015 and some familiarity with the concepts of software life cycle management is assumed.What You Will LearnCreating a Team Project with Dashboards, Assigning License, Adding users, and Auditing AccessSetting up a Git repository in an existing TFVC-based Team ProjectSetting up branch policies and conducting Pull requests with code reviewsMapping, assigning and tracking work items shared by multiple teamsSetting up and customizing Backlogs, Kanban board, Sprint Taskboard, and dashboardsCreating a Continuous Integration, Continuous Build, and Release PipelineIntegrating SonarQube with TFBuild to manage Technical DebtTriggering Selenium Web Tests on a Selenium Test Grid using TFBuildUsing Visual Studio Team Services Cloud load testing capability with new Build frameworkExtending and customizing the capabilities of Team Foundation Server using API and Process EditorIn DetailTeam Foundation Server (TFS) allows you to manage code repositories, build processes, test infrastructure, and deploy labs. TFS supports your team, enabling you to connect, collaborate, and deliver on time. Microsoft's approach to Application Lifecycle Management (ALM) provides a flexible and agile environment that adapts to the needs of your team, removes barriers between roles, and streamlines processes.The book introduces you to creating and setting up team projects for scrum teams. You'll explore various source control repositories, branching, and merging activities, along with a demonstration of how to embed quality into every code check-in. Then, you'll discover agile project planning and management tools. Later, emphasis is given to the testing and release management features of TFS which facilitate the automation of the release pipeline in order to create potentially shippable increments.By the end of the book, you'll have learned to extend and customize TFS plugins to incorporate them into other platforms and enable teams to manage the software lifecycle effectively.Style and approachThis book is a recipe-based guide that uses a problem-solution format to call out inefficiencies in the software development lifecycle and then guides you, step-by-step, on how you can use Team Foundation Server to your advantage in those areas.}
}
@inproceedings{10.1145/3377811.3380351,
author = {Ding, Zishuo and Chen, Jinfu and Shang, Weiyi},
title = {Towards the Use of the Readily Available Tests from the Release Pipeline as Performance Tests: Are We There Yet?},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380351},
doi = {10.1145/3377811.3380351},
abstract = {Performance is one of the important aspects of software quality. Performance issues exist widely in software systems, and the process of fixing the performance issues is an essential step in the release cycle of software systems. Although performance testing is widely adopted in practice, it is still expensive and time-consuming. In particular, the performance testing is usually conducted after the system is built in a dedicated testing environment. The challenges of performance testing make it difficult to fit into the common DevOps process in software development. On the other hand, there exist a large number of tests readily available, that are executed regularly within the release pipeline during software development. In this paper, we perform an exploratory study to determine whether such readily available tests are capable of serving as performance tests. In particular, we would like to see whether the performance of these tests can demonstrate performance improvements obtained from fixing real-life performance issues. We collect 127 performance issues from Hadoop and Cassandra, and evaluate the performance of the readily available tests from the commits before and after the performance issue fixes. We find that most of the improvements from the fixes to performance issues can be demonstrated using the readily available tests in the release pipeline. However, only a very small portion of the tests can be used for demonstrating the improvements. By manually examining the tests, we identify eight reasons that a test cannot demonstrate performance improvements even though it covers the changed source code of the issue fix. Finally, we build random forest classifiers determining the important metrics influencing the readily available tests (not) being able to demonstrate performance improvements from issue fixes. We find that the test code itself and the source code covered by the test are important factors, while the factors related to the code changes in the performance issues fixes have a low importance. Practitioners may focus on designing and improving the tests, instead of fine-tuning tests for different performance issues fixes. Our findings can be used as a guideline for practitioners to reduce the amount of effort spent on leveraging and designing tests that run in the release pipeline for performance assurance activities.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1435–1446},
numpages = {12},
keywords = {performance issues, software performance, performance testing},
location = {Seoul, South Korea},
series = {ICSE '20}
}
@book{10.5555/3278950,
author = {Bai, Haishi},
title = {Programming Microsoft Azure Service Fabric (2nd Edition)},
year = {2018},
isbn = {1509307095},
publisher = {Microsoft Press},
address = {USA},
edition = {2nd},
abstract = {Build, operate, and orchestrate scalable microservices applications in the cloud This book combines a comprehensive guide to success with Microsoft Azure Service Fabric and a practical catalog of design patterns and best practices for microservices design, implementation, and operation. Haishi Bai brings together all the information youll need to deliver scalable and reliable distributed microservices applications on Service Fabric. He thoroughly covers the crucial DevOps aspects of utilizing Service Fabric, reviews its interactions with key cloud-based services, and introduces essential service integration mechanisms such as messaging systems and reactive systems. Leading Microsoft Azure expert Haishi Bai shows how to: Set up your Service Fabric development environment Program and deploy Service Fabric applications to a local or a cloud-based cluster Compare and use stateful services, stateless services, and the actor model Design Service Fabric applications to maximize availability, reliability, and scalability Improve management efficiency via scripting Configure network security and other advanced cluster settings Collect diagnostic data, and use Azure Operational Management Suite to interpret it Integrate microservices components developed in parallel Use containers to mobilize applications for failover, replication, scaling, and load balancing Streamline containerization with Docker in Linux and Windows environments Orchestrate containers to schedule workloads and maintain services at desired states Implement proven design patterns for common cloud application workloads Balance throughput, latency, scalability, and cost}
}
@book{10.5555/3384199,
author = {Chandrasekara, Chaminda and Herath, Pushpa},
title = {Hands-on Azure Repos: Understanding Centralized and Distributed Version Control in Azure DevOps Services},
year = {2019},
isbn = {1484254244},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Use Azure Repos to manage your code in both centralized and distributed version control systems. This book will show you how to work with Team Foundation Version Control (TFVC) and distributed version control (Git), while exploring their best practices. You'll start with an introduction to Azure Repos, focusing on TFVC and Git, and then gradually transition to hands on lessons of working with TVFC. Next, you'll see how to set up and work with TFVC branches and tracking systems followed by usage of command line and security in TFVC Repos. Create and work on Git Repos in Azure DevOps and use branching with Azure Git Repos and Git command line in Visual Studio and vscode. The book then explores security in Git Repos and advanced options you can use to import from external Repos. With Hands-on Azure Repos as your guide, you'll be able to work with these version control tools on any platform and with any language. What You'll Learn Integrate Azure Repos with Azure Boards to enable tracking work with code.; Create guidelines to tackle difficult situations in using Azure Repos; Clone Azure Repo to local using Visual Studio and vscode; Work with shelvesets, code reviews and lock types; Perform activities using REST API with Azure Repos; Who This Book Is For Software developers, tech leads and architects.}
}
@inproceedings{10.1007/978-3-030-85172-9_17,
author = {Wang, Runan and Casale, Giuliano and Filieri, Antonio},
title = {Service Demand Distribution Estimation for Microservices Using Markovian Arrival Processes},
year = {2021},
isbn = {978-3-030-85171-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-85172-9_17},
doi = {10.1007/978-3-030-85172-9_17},
abstract = {Building performance models for microservices applications in DevOps is costly and error-prone. Accurate service demand distribution estimation is critical to performance model parameterization. However, traditional service demand estimation methods focus on capturing the mean service demand, disregarding higher-order moments of the distribution. To address this limitation, we propose to estimate higher moments of the service demand distribution for a microservice from monitoring traces. We first generate a closed queueing model to abstract a microservice and model the departure process at the queue node as a Markovian arrival process. This allows formulating the estimation of service demand as an optimization problem, which aims to find the optimal parameters of the first multiple moments of the service demand distribution based on the inter-departure times. We then estimate the service demand distribution with a novel maximum likelihood algorithm, and heuristics to mitigate the computational cost of the optimization process for scalability. We apply our method to real traces from a microservice-based application and demonstrate that its estimations lead to greater prediction accuracy than exponential distributions assumed in traditional service demand estimation approaches.},
booktitle = {Quantitative Evaluation of Systems: 18th International Conference, QEST 2021, Paris, France, August 23–27, 2021, Proceedings},
pages = {310–328},
numpages = {19},
keywords = {Maximum likelihood estimation, Markovian arrival process, Service demand distribution, Performance, Queueing models},
location = {Paris, France}
}
author = {Ferry, Nicolas and Chauvel, Franck and Song, Hui and Solberg, Arnor},
title = {Continous Deployment of Multi-Cloud Systems},
year = {2015},
isbn = {9781450338172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804371.2804377},
doi = {10.1145/2804371.2804377},
abstract = {In this paper we present our mechanism and tooling for the continuous deployment and resource provisioning of multi-cloud applications. In order to facilitate collaboration between development and operation teams as promoted in the DevOps movement, our deployment and resource provisioning engine is based on the Models@Runtime principles. This enables applying the same concepts and language (i.e., CloudML) for deployment and resource provisioning at development-and operation-time.},
booktitle = {Proceedings of the 1st International Workshop on Quality-Aware DevOps},
pages = {27–28},
numpages = {2},
keywords = {deployment, model-driven engineering, CloudML, Models@Runtime, Cloud computing},
location = {Bergamo, Italy},
series = {QUDOS 2015}
}
@book{10.5555/3299145,
author = {Fleming, Stephen},
title = {Blockchain Technology and Kubernetes: Non-Programmer?S Handbook},
year = {2018},
isbn = {1727447743},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
abstract = {Are you a non-coder looking for insight into Blockchain Technology and Kubernetes? You may be a consultant, Advisor, Project Manager or a novice into IT/Consulting industry; looking for latest Technologies, Application Development methodologies and Service Oriented Architecture models. This book is a collection of my two manuscripts (Blockchain Technology &amp; Kubernetes Handbook) which will provide you with insights into Blockchain Technology and Kubernetes. It also includes additional booklets with the latest case studies and interesting facts. Blockchain Questions Answered:- How would Blockchain Technology impact the day to day lives of common people?- How could the government leverage the Blockchain Technology to improve the service delivery?- How would the existing businesses be impacted and integrated with this new Technology?- How the current Businesses and Jobs would be transformed?- What are the other sectors where this Technology have been Implemented? Kubernetes Questions Answered:The Background of it? Why we needed this system in first place? How Kubernetes Operates? The Nuts and Bolts of the system. How it is deployed? Best Practices After going through this guide you would be able to appreciate related concepts like Blockchain Wallet, Distributed Ledger, Agile, SOA, Monolith Architecture, DevOps, Docker, Kubernetes etc. You would also get to know about the latest development and case studies in these fields. I am confident that after going through the book you would be able to navigate the discussion with any stakeholder and take your agenda ahead as per your role. Additionally, if you are new to the industry, and looking for a job in Technology Consulting, this book will help you to prepare with all the relevant information and understanding of the topics.}
}
@article{10.1109/MS.2017.3571578,
author = {Carter, Kim},
title = {Francois Raynaud on DevSecOps},
year = {2017},
issue_date = {2017},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {34},
number = {5},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2017.3571578},
doi = {10.1109/MS.2017.3571578},
abstract = {Host Kim Carter talks with Francois Raynaud about how to easily apply DevOps principles to security, and how this helps improve the relationship between security and development teams and ultimately the success of a product or business. The full podcast of this interview is at www.se-radio.net/2017/04/se-radio-episode-288-devsecops.},
journal = {IEEE Softw.},
month = {jan},
pages = {93–96},
numpages = {4}
}
@article{10.1155/2021/6623666,
author = {Wang, Xue and Liu, Fan and Feng, Yixin and Zhao, Jiabao and Zhang, Zhen},
title = {A Two-Layer Architecture for Failure Prediction Based on High-Dimension Monitoring Sequences},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/6623666},
doi = {10.1155/2021/6623666},
abstract = {In recent years, the distributed architecture has been widely adopted by security companies with the rapid expansion of their business. A distributed system is comprised of many computing nodes of different components which are connected by high-speed communication networks. With the increasing functionality and complexity of the systems, failures of nodes are inevitable which may result in considerable loss. In order to identify anomalies of the possible failures and enable DevOps engineers to operate in advance, this paper proposes a two-layer prediction architecture based on the monitoring sequences of nodes status. Generally speaking, in the first layer, we make use of EXPoSE anomaly detection technique to derive anomaly scores in constant time which are then used as input data for ensemble learning in the second layer. Experiments are conducted on the data provided by one of the largest security companies, and the results demonstrate the predictability of the proposed approach.},
journal = {Complex.},
month = {jan},
numpages = {9}
}
@book{10.5555/3306860,
author = {Aggarwal, Manuj},
title = {Learn Apache Mesos: A Beginner's Guide to Scalable Cluster Management and Deployment},
year = {2018},
isbn = {1789137381},
publisher = {Packt Publishing},
abstract = {Scale applications with high availability and optimized resource management across data centers Key Features Create clusters and perform scheduling, logging, and resource administration with Mesos Explore practical examples of managing complex clusters at scale with real-world data Write native Mesos frameworks with Python Book Description Apache Mesos is an open source cluster manager that provides efficient resource isolation and sharing across distributed applications or frameworks. This book will help you build a strong foundation of Mesos' capabilities along with practical examples to support the concepts explained throughout the book. Learn Apache Mesos dives straight into how Mesos works. You will be introduced to the distributed system and its challenges and then learn how you can use Mesos and its framework to solve data problems. You will also gain a full understanding of Mesos' internal mechanisms and get equipped to use Mesos and develop applications. Furthermore, this book lets you explore all the steps required to create highly available clusters and build your own Mesos frameworks. You will also cover application deployment and monitoring. By the end of this book, you will have learned how to use Mesos to make full use of machines and how to simplify data center maintenance. What you will learn Deploy and monitor a Mesos cluster Set up servers on AWS to deploy Mesos components Explore Mesos resource scheduling and the allocation module Deploy Docker-based services and applications using Mesos Marathon Configure and use SSL to protect crucial endpoints of your Mesos cluster Debug and troubleshoot services and workloads on a Mesos cluster Who this book is for This book is for DevOps and data engineers and administrators who work with large data clusters. You'll also find this book useful if you have experience working with virtualization, databases, and platforms such as Hadoop and Spark. Some experience in database administration and design will help you get the most out of this book.}
}
@inproceedings{10.5555/3172795.3172863,
author = {Shah, Devan and Lindsay, Larry and Brunet, Thomas and Asghar, Ali and Pandhi, Charu},
title = {Hands-on: Accessibility in the DevOps Era},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {Through the last few years, IBM has undergone a major transformation, embracing continuous integration (CI) and DevOps practices. This transformation focuses on building solutions that work well for people while using tools that improve delivery collaboration and responsiveness to user needs.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {361},
numpages = {1},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}
@inproceedings{10.1145/3375555.3383120,
author = {Gias, Alim U. and van Hoorn, Andr\'{e} and Zhu, Lulai and Casale, Giuliano and D\"{u}llmann, Thomas F. and Wurster, Michael},
title = {Performance Engineering for Microservices and Serverless Applications: The RADON Approach},
year = {2020},
isbn = {9781450371094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375555.3383120},
doi = {10.1145/3375555.3383120},
abstract = {Microservices and serverless functions are becoming integral parts of modern cloud-based applications. Tailored performance engineering is needed for assuring that the applications meet their requirements for quality attributes such as timeliness, resource efficiency, and elasticity. A novel DevOps-based framework for developing microservices and serverless applications is being developed in the RADON project. RADON contributes to performance engineering by including novel approaches for modeling, deployment optimization, testing, and runtime management. This paper summarizes the contents of our tutorial presented at the 11th ACM/SPEC International Conference on Performance Engineering (ICPE).},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {46–49},
numpages = {4},
keywords = {microservices, serverless, performance engineering},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}
@book{10.5555/2685410,
author = {Gregory, Janet and Crispin, Lisa},
title = {More Agile Testing: Learning Journeys for the Whole Team},
year = {2014},
isbn = {0321967054},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {Janet Gregory and Lisa Crispin pioneered the agile testing discipline with their previous work, Agile Testing. Now, in More Agile Testing, they reflect on all theyve learned since. They address crucial emerging issues, share evolved agile practices, and cover key issues agile testers have asked to learn more about. Packed with new examples from real teams, this insightful guide offers detailed information about adapting agile testing for your environment; learning from experience and continually improving your test processes; scaling agile testing across teams; and overcoming the pitfalls of automated testing. Youll find brand-new coverage of agile testing for the enterprise, distributed teams, mobile/embedded systems, regulated environments, data warehouse/BI systems, and DevOps practices. Youll come away understanding How to clarify testing activities within the team Ways to collaborate with business experts to identify valuable features and deliver the right capabilities How to design automated tests for superior reliability and easier maintenance How agile team members can improve and expand their testing skills How to plan just enough, balancing small increments with larger feature sets and the entire system How to use testing to identify and mitigate risks associated with your current agile processes and to prevent defects How to address challenges within your product or organizational context How to perform exploratory testing using personas and tours Exploratory testing approaches that engage the whole team, using test charters with session- and thread-based techniques How to bring new agile testers up to speed quicklywithout overwhelming them Janet Gregory is founder of DragonFire Inc., an agile quality process consultancy and training firm. Her passion is helping teams build quality systems. For almost fifteen years, she has worked as a coach and tester, introducing agile practices into companies of all sizes and helping users and testers understand their agile roles. She is a frequent speaker at agile and testing software conferences, and is a major contributor to the agile testing community. Lisa Crispin, an experienced agile testing practitioner and coach, regularly leads conference workshops on agile testing and contributes frequently to agile software publications. She enjoys collaborating as part of an awesome agile team to produce quality software. Since 1982, she has worked in a variety of roles on software teams, in a wide range of industries. She joined her first agile team in 2000 and continually learns from other teams and practitioners.}
}
@inproceedings{10.1145/2804371.2804378,
author = {Guerriero, Michele and Ciavotta, Michele and Gibilisco, Giovanni Paolo and Ardagna, Danilo},
title = {SPACE4Cloud: A DevOps Environment for Multi-Cloud Applications},
year = {2015},
isbn = {9781450338172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804371.2804378},
doi = {10.1145/2804371.2804378},
abstract = {Cloud computing has been a game changer in the design, development and management of modern applications, which have grown in scope and size becoming distributed and service oriented. New methodologies have emerged to deal with this paradigm shift in software engineering. Consequently, new tools, devoted to ease the convergence between developers and other IT professional, are required. Here, we present SPACE4Cloud, a DevOps integrated environment for model-driven design-time QoS assessment and optimization, and runtime capacity allocation for Cloud applications.},
booktitle = {Proceedings of the 1st International Workshop on Quality-Aware DevOps},
pages = {29–30},
numpages = {2},
keywords = {DevOps, Model-Driven, Cloud, runtime, design-time, QoS},
location = {Bergamo, Italy},
series = {QUDOS 2015}
}
@book{10.5555/3265224,
author = {Jackson, Kevin L. and Goessling, Scott},
title = {Architecting Cloud Computing Solutions: Build Cloud Strategies That Align Technology and Economics While Effectively Managing Risk},
year = {2018},
isbn = {178847242X},
publisher = {Packt Publishing},
abstract = {Accelerating Business and Mission Success with Cloud Computing. Key Features A step-by-step guide that will practically guide you through implementing Cloud computing services effectively and efficiently. Learn to choose the most ideal Cloud service model, and adopt appropriate Cloud design considerations for your organization. Leverage Cloud computing methodologies to successfully develop a cost-effective Cloud environment successfully. Book Description Cloud adoption is a core component of digital transformation. Scaling the IT environment, making it resilient, and reducing costs are what organizations want. Architecting Cloud Computing Solutions presents and explains critical Cloud solution design considerations and technology decisions required to choose and deploy the right Cloud service and deployment models, based on your business and technology service requirements. This book starts with the fundamentals of cloud computing and its architectural concepts. It then walks you through Cloud service models (IaaS, PaaS, and SaaS), deployment models (public, private, community, and hybrid) and implementation options (Enterprise, MSP, and CSP) to explain and describe the key considerations and challenges organizations face during cloud migration. Later, this book delves into how to leverage DevOps, Cloud-Native, and Serverless architectures in your Cloud environment and presents industry best practices for scaling your Cloud environment. Finally, this book addresses (in depth) managing essential cloud technology service components such as data storage, security controls, and disaster recovery. By the end of this book, you will have mastered all the design considerations and operational trades required to adopt Cloud services, no matter which cloud service provider you choose. What you will learn Manage changes in the digital transformation and cloud transition process Design and build architectures that support specific business cases Design, modify, and aggregate baseline cloud architectures Familiarize yourself with cloud application security and cloud computing security threats Design and architect small, medium, and large cloud computing solutions Who This Book Is ForIf you are an IT Administrator, Cloud Architect, or a Solution Architect keen to benefit from cloud adoption for your organization, then this book is for you. Small business owners, managers, or consultants will also find this book useful. No prior knowledge of Cloud computing is needed.}
}
@book{10.5555/3161500,
author = {Tanasseri, Namit and Rai, Rahul},
title = {Microservices with Azure: Build Highly Maintainable and Scalable Enterprise-Grade Apps},
year = {2017},
isbn = {1787121143},
publisher = {Packt Publishing},
abstract = {Architect enterprise-grade, Microservice-based solutions using Microsoft Azure Service Fabric. About This Book Explore architectural patterns for building modern day Microservice-based systems Learn about Microsoft Service Fabric as a platform to host distributed Microservices Discover multiple options for hosting Microservices on heterogeneous, cross-platform environmentsLearn to configure Azure Service Fabric clusters for enterprise-grade service deployments Who This Book Is ForThe book is aimed at IT architects, system administrators, and DevOps engineers who have a basic knowledge of the Microsoft Azure platform and are working on, or are curious about, the concepts of Microservices and Microservice architecture. What You Will Learn Understand the basics of Microservices and how Microsoft Azure fits into the equation Master Azure Service Fabric architecture and services Explore Azure Service Fabric application programming models Comprehensive study of various architecture patterns for building enterprise-grade Microservices Manage and deploy Microservices on Azure Service Fabric An insight into the future of Microservices with containers and serverless computingIn Detail Microsoft Azure is rapidly evolving and is widely used as a platform on which you can build Microservices that can be deployed on-premise and on-cloud heterogeneous environments through Microsoft Azure Service Fabric. This book will help you understand the concepts of Microservice application architecture and build highly maintainable and scalable enterprise-grade applications using the various services in Microsoft Azure Service Fabric. We will begin by understanding the intricacies of the Microservices architecture and its advantages over the monolithic architecture and Service Oriented Architecture (SOA) principles. We will present various scenarios where Microservices should be used and walk you through the architectures of Microservice-based applications. Next, you will take an in-depth look at Microsoft Azure Service Fabric, which is the best-in-class platform for building Microservices. You will explore how to develop and deploy sample applications on Microsoft Azure Service Fabric to gain a thorough understanding of it. Building Microservice-based application is complicated. Therefore, we will take you through several design patterns that solve the various challenges associated with realizing the Microservices architecture in enterprise applications. Each pattern will be clearly illustrated with examples that you can keep referring to when designing applications. Finally, you will be introduced to advanced topics such as Serverless computing and DevOps using Service Fabric, to help you undertake your next venture with confidence. Style and approach This book introduces its readers to the concept of Microservices and Microsoft Azure Service Fabric as a distributed platform to host enterprise-grade Microservices. It then addresses common architectural challenges associated with the Microservice architecture, using proven architectural patterns.}
}
@inproceedings{10.1109/MSR.2019.00089,
author = {Zerouali, Ahmed and Cosentino, Valerio and Robles, Gregorio and Gonzalez-Barahona, Jesus M. and Mens, Tom},
title = {ConPan: A Tool to Analyze Packages in Software Containers},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00089},
doi = {10.1109/MSR.2019.00089},
abstract = {Deploying software packages and services into containers is a popular software engineering practice that increases portability and reusability. Docker, the most popular containerization technology, helps DevOps practitioners in their daily activities. Despite being successfully and increasingly employed, containers may include buggy and vulnerable packages that put at risk the environments in which the containers have been deployed. Existing quality and security monitoring tools provide only limited support to analyze Docker containers, thus forcing practitioners to perform additional manual work or develop adhoc scripts when the analysis goes beyond security purposes. This limitation also affects researchers desiring to empirically study the evolution dynamics of Docker containers and their contained packages. To overcome this limitation, we present ConPan, an automated tool to inspect the characteristics of packages in Docker containers, such as their outdatedness and other possible flaws (e.g., bugs and security vulnerabilities). ConPan comes with a CLI and API, and the analysis results can be presented to the user in a variety of formats.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {592–596},
numpages = {5},
keywords = {bugs, containers, docker, outdated software, vulnerabilities},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}
@article{10.1145/3012426.3015763,
author = {Bailey, Josh and Stuart, Stephen},
title = {Faucet: Deploying SDN in the Enterprise: Using OpenFlow and DevOps for Rapid Development},
year = {2016},
issue_date = {September-October 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {5},
issn = {1542-7730},
url = {https://doi.org/10.1145/3012426.3015763},
doi = {10.1145/3012426.3015763},
abstract = {While SDN as a technology continues to evolve and become even more programmable, Faucet and OpenFlow 1.3 hardware together are sufficient to realize benefits today. This article describes specifically how to take advantage of DevOps practices to develop and deploy features rapidly. It also describes several practical deployment scenarios, including firewalling and network function virtualization.},
journal = {Queue},
month = {oct},
pages = {54–68},
numpages = {15}
}
@article{10.1145/3125621,
author = {Ferry, Nicolas and Chauvel, Franck and Song, Hui and Rossini, Alessandro and Lushpenko, Maksym and Solberg, Arnor},
title = {CloudMF: Model-Driven Management of Multi-Cloud Applications},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3125621},
doi = {10.1145/3125621},
abstract = {While the number of cloud solutions is continuously increasing, the development and operation of large-scale and distributed cloud applications are still challenging. A major challenge is the lack of interoperability between the existing cloud solutions, which increases the complexity of maintaining and evolving complex applications potentially deployed across multiple cloud infrastructures and platforms. In this article, we show how the Cloud Modelling Framework leverages model-driven engineering and supports the DevOps ideas to tame this complexity by providing: (i) a domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for their continuous provisioning, deployment, and adaptation.},
journal = {ACM Trans. Internet Technol.},
month = {jan},
articleno = {16},
numpages = {24},
keywords = {DevOps, model-driven engineering, models@run-time, Cloud computing, multi-cloud}
}
@article{10.1007/s10922-020-09517-0,
author = {Clemm, Alexander and Zhani, Mohamed Faten and Boutaba, Raouf},
title = {Network Management 2030: Operations and Control of Network 2030 Services},
year = {2020},
issue_date = {Oct 2020},
publisher = {Plenum Press},
address = {USA},
volume = {28},
number = {4},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-020-09517-0},
doi = {10.1007/s10922-020-09517-0},
abstract = {The networking landscape is expected to undergo profound changes over the course of the next decade. New network services are expected to emerge that will enable new applications such as the Tactile Internet, Holographic-Type Communications, or Tele-Driving. Many of these services will be characterized by very high degrees of precision with which end-to-end service levels must be supported. This will have profound implications on the management of those networks and services, from the need to support new methods for assurance of ultra-high-precision services to the need for new network programming models that will allow the industry to move beyond DevOps and SDN towards User-Defined Networking. This article analyzes those implications and provides an overview of challenges along with possible solution approaches and opportunities for research.},
journal = {J. Netw. Syst. Manage.},
month = {oct},
pages = {721–750},
numpages = {30},
keywords = {Network programming models, Research challenges, BPP, Network operations, Service assurance, High precision networking, New IP, Intent, Service management}
}
@book{10.5555/3169224,
author = {Rankin, Kyle},
title = {Linux Hardening in Hostile Networks: Server Security from TLS to Tor},
year = {2017},
isbn = {0134173260},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {Implement Industrial-Strength Security on Any Linux Server In an age of mass surveillance, when advanced cyberwarfare weapons rapidly migrate into every hackers toolkit, you cant rely on outdated security methodsespecially if youre responsible for Internet-facing services. In Linux Hardening in Hostile Networks, Kyle Rankin helps you to implement modern safeguards that provide maximum impact with minimum effort and to strip away old techniques that are no longer worth your time. Rankin provides clear, concise guidance on modern workstation, server, and network hardening, and explains how to harden specific services, such as web servers, email, DNS, and databases. Along the way, he demystifies technologies once viewed as too complex or mysterious but now essential to mainstream Linux security. He also includes a full chapter on effective incident response that both DevOps and SecOps can use to write their own incident response plan. Each chapter begins with techniques any sysadmin can use quickly to protect against entry-level hackers and presents intermediate and advanced techniques to safeguard against sophisticated and knowledgeable attackers, perhaps even state actors. Throughout, you learn what each technique does, how it works, what it does and doesnt protect against, and whether it would be useful in your environment. Apply core security techniques including 2FA and strong passwords Protect admin workstations via lock screens, disk encryption, BIOS passwords, and other methods Use the security-focused Tails distribution as a quick path to a hardened workstation Compartmentalize workstation tasks into VMs with varying levels of trust Harden servers with SSH, use apparmor and sudo to limit the damage attackers can do, and set up remote syslog servers to track their actions Establish secure VPNs with OpenVPN, and leverage SSH to tunnel traffic when VPNs cant be used Configure a software load balancer to terminate SSL/TLS connections and initiate new ones downstream Set up standalone Tor services and hidden Tor services and relays Secure Apache and Nginx web servers, and take full advantage of HTTPS Perform advanced web server hardening with HTTPS forward secrecy and ModSecurity web application firewalls Strengthen email security with SMTP relay authentication, SMTPS, SPF records, DKIM, and DMARC Harden DNS servers, deter their use in DDoS attacks, and fully implement DNSSEC Systematically protect databases via network access control, TLS traffic encryption, and encrypted data storage Respond to a compromised server, collect evidence, and prevent future attacks Normal 0 false false false EN-US X-NONE X-NONE Register your product at informit.com/register for convenient access to downloads, updates, and corrections as they become available. Normal 0 false false false EN-US X-NONE X-NONE}
}
@article{10.1109/MCOM.2018.1600104,
author = {Van Rossem, Steven and Tavernier, Wouter and Colle, Didier and Pickavet, Mario and Demeester, Piet},
title = {Introducing Development Features for Virtualized Network Services},
year = {2018},
issue_date = {August 2018},
publisher = {IEEE Press},
volume = {56},
number = {8},
issn = {0163-6804},
url = {https://doi.org/10.1109/MCOM.2018.1600104},
doi = {10.1109/MCOM.2018.1600104},
abstract = {Network virtualization and softwarizing network functions are trends aiming at higher network efficiency, cost reduction and agility. They are driven by the evolution in Software Defined Networking (SDN) and Network Function Virtualization (NFV). This shows that software will play an increasingly important role within telecommunication services, which were previously dominated by hardware appliances. Service providers can benefit from this, as it enables faster introduction of new telecom services, combined with an agile set of possibilities to optimize and fine-tune their operations. However, the provided telecom services can only evolve if the adequate software tools are available. In this article, we explain how the development, deployment and maintenance of such an SDN/NFV-based telecom service puts specific requirements on the platform providing it. A Software Development Kit (SDK) is introduced, allowing service providers to adequately design, test and evaluate services before they are deployed in production and also update them during their lifetime. This continuous cycle between development and operations, a concept known as DevOps, is a well known strategy in software development. To extend its context further to SDN/NFV-based services, the functionalities provided by traditional cloud platforms are not yet sufficient. By giving an overview of the currently available tools and their limitations, the gaps in DevOps for SDN/NFV services are highlighted. The benefit of such an SDK is illustrated by a secure content delivery network service (enhanced with deep packet inspection and elastic routing capabilities). With this use-case, the dynamics between developing and deploying a service are further illustrated.},
journal = {Comm. Mag.},
month = {aug},
pages = {184–192},
numpages = {9}
}
@inproceedings{10.1007/978-3-030-65310-1_42,
author = {Ntentos, Evangelos and Zdun, Uwe and Plakidas, Konstantinos and Meixner, Sebastian and Geiger, Sebastian},
title = {Metrics for Assessing Architecture Conformance to Microservice Architecture Patterns and Practices},
year = {2020},
isbn = {978-3-030-65309-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-65310-1_42},
doi = {10.1007/978-3-030-65310-1_42},
abstract = {Many contemporary service-based systems follow the microservice approach, particularly in DevOps or continuous delivery contexts. They share a set of important tenets such as independent development and deployment, high releasability, polyglot technology support, and loose coupling. A number of best practices for microservice architectures have been codified as patterns, which embody those tenets. However, no real-world microservices system can support all patterns and practices well, but rather architectural decisions making trade-offs among them are needed. Conformance to the patterns and practices selected in such decisions is hard to ensure and assess automatically, especially in large-scale, complex, and evolving systems. In this work, we propose a model-based approach based on generic, technology-independent metrics, tied to typical architectural design decisions in the microservice domain. With this approach we can measure conformance to the patterns and related tenets. We demonstrate and assess the validity and appropriateness of these metrics in performing an assessment of a system’s conformance to patterns through statistical methods.},
booktitle = {Service-Oriented Computing: 18th International Conference, ICSOC 2020, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings},
pages = {580–596},
numpages = {17},
location = {Dubai, United Arab Emirates}
}
@book{10.5555/3153178,
author = {Morar, Mahindra and Kumar, Abhishek and Abbott, Martin and Gautam, Gyanendra Kumar and Corbould, James and Bhambhani, Ashish},
title = {Robust Cloud Integration with Azure},
year = {2017},
isbn = {1786465574},
publisher = {Packt Publishing},
abstract = {Its an incredibly exciting time for cloud integration. In 2017, Microsoft Windows Azure has accelerated the development of logic apps, web apps for developers and IoT. Looking to build scalable app services in the cloud? With this essential installment in our Azure books series, find everything you need to design and implement cloud integration. Any software developers, architects, and technical managers lookng to learn about Azure IaaS essentials need look no further. This book is ideal for Microsoft Enterprise developers, DevOps or any IT professionals looking to connect cloud-based and on-premises systems with Azure. With this book, youll learn about: Building and supporting highly available and scalable API Apps Deploying and delivering applications that integrate and adapt seamlessly in the cloud Deploying hybrid applications that work and integrate on the cloud (using Logic Apps and BizTalk Server) Exploring new models of robust cloud integration in Microsoft Azure Creating your own connector and learn how to publish and manage it Building reliable, scalable, and secure business workflows using Azure Logic Apps Simplifying SaaS connectivity with Azure using Logic Apps Connecting your on-premises system to Azure securely}
}
@book{10.5555/3203456,
author = {Meyler, Kerrie and Buchanan, Steve and Scholman, Mark and Svendsen, Jakob Gottlieb and Rangama, Janaka},
title = {Microsoft Hybrid Cloud Unleashed with Azure Stack and Azure},
year = {2017},
isbn = {0672338505},
publisher = {Sams publishing},
edition = {1st},
abstract = {Microsoft Hybrid Cloud Unleashed brings together comprehensive and practical insights into hybrid cloud technologies, complete CloudOps and DevOps implementation strategies, and detailed guidance for deploying Microsoft Azure Stack in your environment. Written by five Microsoft Cloud and Datacenter Management MVPs, this book is built on real-world scenarios and the authors extraordinary hands-on experiences as early adopters. Step by step, the authors help you integrate your optimal mix of private and public cloud, with a unified management experience that lets you move workloads at will, achieving unprecedented flexibility. The authors also guide you through all aspects of building your own secure, high-performance hybrid cloud infrastructure. Youll discover how Azure Stack enables you to run data centers with the same scalability, redundancy, and reliability as Microsofts Azure data centers; how to integrate Azure infrastructure and platform services with internal operations; and how to manage crucial external dependencies. The book concludes with a deep dive into automating and customizing Azure Stack for maximum reliability, productivity, and cost savings. Detailed information on how to Run a private/hybrid cloud on your hardware in your data center, using APIs and code identical to public Azure Apply ITIL and DevOps lifecycles to your hybrid cloud implementation Gain a deep understanding of Azure Stack architecture, components, and internals Install and configure Azure Stack and master the Azure Stack Portal Integrate and utilize infrastructure, core, and custom resource providers Effectively provision, secure, and manage tenants Manage, monitor, troubleshoot, and back up Azure Stack with CloudOps Automate resource provisioning with PowerShell, the Azure CLI, templates, and Azure Stacks API Write your own Azure Resource Manager templates Centrally automate cloud management and complex tasks connected to external systems Develop customized, production-ready Azure Stack marketplace items}
}
@inproceedings{10.1109/EDOC.2015.29,
author = {Weerasiri, Denis and Benatallah, Boualem},
title = {Unified Representation and Reuse of Federated Cloud Resources Configuration Knowledge},
year = {2015},
isbn = {9781467392037},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/EDOC.2015.29},
doi = {10.1109/EDOC.2015.29},
abstract = {The proliferation of tools for different aspects of cloud resource configuration processes encourages DevOps to design end-to-end and automated configuration processes that span across a selection of best-of-breed tools. But heterogeneities among configuration knowledge representation models of such tools pose vital limitations for acquisition, discovery and curation of configuration knowledge for federated cloud application and resource requirements. We propose an embryonic data-model for representing cloud resource configuration knowledge artifacts. We also propose a rule based recommender service, which empowers (1) incremental knowledge acquisition and curation, and (2) declarative context driven knowledge recommendation. The paper describes the concepts, techniques and current implementation of the proposed system. Experiments on 36 real-life cloud resources show efficient re-use of configuration knowledge by our approach compared to traditional techniques.},
booktitle = {Proceedings of the 2015 IEEE 19th International Enterprise Distributed Object Computing Conference},
pages = {142–150},
numpages = {9},
keywords = {Federated Cloud, Recommender services, Cloud Configuration Knowledge Representation, Ripple Down Rules},
series = {EDOC '15}
}
@inproceedings{10.5555/3172795.3172821,
author = {Jim\'{e}nez, Miguel and Villegas, Norha M. and Tamura, Gabriel and M\"{u}ller, Hausi A.},
title = {Deployment Specification Challenges in the Context of Large Scale Systems},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {Traditionally, the focus of software deployment has been mainly on the infrastructure to realise deployment and configuration (D&amp;C) of complex and distributed systems, with an increasing interest in deployment of internet of things and cyber-physical systems. Advances in job scheduling, storage orchestration, containerized applications, along with agile practices such as continuous integration and microservices architecture, have improved the state of the practice. However, little effort has been devoted to the need for D&amp;C specifications to support the various levels of detail and abstraction present in large-scale systems. The understanding of the software components hierarchy has shifted from the comprehension of design artefacts, usually specified with static diagrams, to the understanding of runtime concepts. The DevOps movement has dramatically influenced how and when deployment is realised, but little has been done from the software perspective in terms of documentation and linkage between design and runtime artefacts in the sense of software specification as such. This paper presents an overview of the state of the art of deployment requirements for large-scale, distributed and complex software and its automation and characterises a set of deployment specification challenges intended as starting points for advancing the field of software deployment.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {220–226},
numpages = {7},
keywords = {runtime artefacts, DevOps, deployment specification, continuous integration continuous configuration, continuous software deployment, models at runtime},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}
@book{10.5555/3204003,
author = {Akula, Madhu and Mahajan, Akash},
title = {Security Automation with Ansible 2: Leverage Ansible 2 to Automate Complex Security Tasks like Application Security, Network Security, and Malware Analysis},
year = {2017},
isbn = {1788394518},
publisher = {Packt Publishing},
abstract = {Automate security-related tasks in a structured, modular fashion using the best open source automation tool availableKey FeaturesLeverage the agentless, push-based power of Ansible 2 to automate security tasksLearn to write playbooks that apply security to any part of your system This recipe-based guide will teach you to use Ansible 2 for various use cases such as fraud detection, network security, governance, and more Book Description Security automation is one of the most interesting skills to have nowadays. Ansible allows you to write automation procedures once and use them across your entire infrastructure. This book will teach you the best way to use Ansible for seemingly complex tasks by using the various building blocks available and creating solutions that are easy to teach others, store for later, perform version control on, and repeat. We ll start by covering various popular modules and writing simple playbooks to showcase those modules. You ll see how this can be applied over a variety of platforms and operating systems, whether they are Windows/Linux bare metal servers or containers on a cloud platform. Once the bare bones automation is in place, you ll learn how to leverage tools such as Ansible Tower or even Jenkins to create scheduled repeatable processes around security patching, security hardening, compliance reports, monitoring of systems, and so on. Moving on, you ll delve into useful security automation techniques and approaches, and learn how to extend Ansible for enhanced security. While on the way, we will tackle topics like how to manage secrets, how to manage all the playbooks that we will create and how to enable collaboration using Ansible Galaxy. In the final stretch, we ll tackle how to extend the modules of Ansible for our use, and do all the previous tasks in a programmatic manner to get even more powerful automation frameworks and rigs. What you will learn Use Ansible playbooks, roles, modules, and templating to build generic, testable playbooks Manage Linux and Windows hosts remotely in a repeatable and predictable manner See how to perform security patch management, and security hardening with scheduling and automation Set up AWS Lambda for a serverless automated defense Run continuous security scans against your hosts and automatically fix and harden the gaps Extend Ansible to write your custom modules and use them as part of your already existing security automation programs Perform automation security audit checks for applications using Ansible Manage secrets in Ansible using Ansible Vault Who This Book Is ForIf you are a system administrator or a DevOps engineer with responsibility for finding loop holes in your system or application, then this book is for you. It s also useful for security consultants looking to automate their infrastructure s security model.}
}
@book{10.5555/3202546,
author = {Farmer, Rick and Jain, Rahul and Wu, David},
title = {Cloud Foundry for Developers: Deploy, Manage, and Orchestrate Cloud-Native Applications with Ease},
year = {2017},
isbn = {1788391446},
publisher = {Packt Publishing},
abstract = {Deploy and scale applications on Cloud FoundryAbout This BookGain hands-on experience using Cloud FoundryImplement deployment, management and scaling of applications on Cloud FoundryLearn best practices and troubleshooting tips for running applications on Cloud FoundryWho This Book Is ForThis book is aimed at developers, engineers and architects who want to learn key aspects of developing and running applications on the Cloud Foundry Platform. Prior knowledge Cloud Foundry is not necessary. What You Will LearnUnderstand Cloud Foundry (CF) tools and concepts. Understand the breadth of possibilities unleashed through a lightweight agile approach to building and deploying applications. Design and deploy cloud native applications that run well on Cloud Foundry. Learn Microservice design concepts and worker applications. Customize service brokers to publish your services in the Cloud Foundry marketplace. Using, managing and creating buildpacks for the Cloud Foundry Platform. Troubleshoot applications on Cloud FoundryPerform zero-downtime deployments using blue/green routes, A/B testing, and painless rollbacks to earlier versions of the application. In DetailCloud Foundry is the open source platform to deploy, run, and scale applications. Cloud Foundry is growing rapidly and a leading product that provides PaaS (Platform as a Service) capabilities to enterprise, government, and organizations around the globe. Giants like Dell Technologies, GE, IBM, HP and the US government are using Cloud Foundry innovate faster in a rapidly changing world. Cloud Foundry is a developers dream. Enabling them to create modern applications that can leverage the latest thinking, techniques and capabilities of the cloud, including: DevOps Application Virtualization Infrastructure agnosticism Orchestrated containers Automation Zero downtime upgrades A/B deploymen tQuickly scaling applications out or in This book takes readers on a journey where they will first learn the Cloud Foundry basics, including how to deploy and scale a simple application in seconds. Readers will build their knowledge of how to create highly scalable and resilient cloud-native applications and microservices running on Cloud Foundry. Readers will learn how to integrate their application with services provided by Cloud Foundry and with those external to Cloud Foundry. Readers will learn how to structure their Cloud Foundry environment with orgs and spaces. After that, well discuss aspects of continuous integration/continuous delivery (CI/CD), monitoring and logging. Readers will also learn how to enable health checks, troubleshoot and debug applications. By the end of this book, readers will have hands-on experience in performing various deployment and scaling tasks. Additionally, they will have an understanding of what it takes to migrate and develop applications for Cloud Foundry. Style and Approach A practitioner's guide to Cloud Foundry that covers the areas of application development, deployment and services.}
}
@inbook{10.1145/3379337.3422877,
author = {Hodges, Steve},
title = {Democratizing the Production of Interactive Hardware},
year = {2020},
isbn = {9781450375146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379337.3422877},
abstract = {The development of new hardware can be split into two phases: prototyping and production. A wide variety of tools and techniques have empowered people to build prototypes during the first phase, but the transition to production is still complex, costly and prone to failure. This means the second phase often requires an up-front commitment to large volume production in order to be viable. I believe that new tools and techniques can democratize hardware production. Imagine "DevOps for hardware" - everything from circuit simulation tools to re-usable hardware test jig designs; and from test-driven development for hardware to telepresence for remote factory visits. Supporting low volume production and organic scaling in this way would spur innovation and increase consumer choice. I encourage the UIST community to join me in pursuit of this vision.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
pages = {5–6},
numpages = {2}
}
@inbook{10.1109/ICSE-SEIP52600.2021.00037,
author = {Angermeir, Florian and Voggenreiter, Markus and Moy\'{o}n, Fabiola and Mendez, Daniel},
title = {Enterprise-Driven Open Source Software: A Case Study on Security Automation},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00037},
abstract = {Agile and DevOps are widely adopted by the industry. Hence, integrating security activities with industrial practices, such as continuous integration (CI) pipelines, is necessary to detect security flaws and adhere to regulators' demands early. In this paper, we analyze automated security activities in CI pipelines of enterprise-driven open source software (OSS). This shall allow us, in the long-run, to better understand the extent to which security activities are (or should be) part of automated pipelines. In particular, we mine publicly available OSS repositories and survey a sample of project maintainers to better understand the role that security activities and their related tools play in their CI pipelines. To increase transparency and allow other researchers to replicate our study (and to take different perspectives), we further disclose our research artefacts.Our results indicate that security activities in enterprise-driven OSS projects are scarce and protection coverage is rather low. Only 6.83% of the analyzed 8,243 projects apply security automation in their CI pipelines, even though maintainers consider security to be rather important. This alerts industry to keep the focus on vulnerabilities of 3rd Party software and it opens space for other improvements of practice which we outline in this manuscript.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {278–287},
numpages = {10}
}
@book{10.5555/2636999,
author = {Burgess, Mark},
title = {In Search of Certainty: The Science of Our Information Infrastructure},
year = {2013},
isbn = {1492389161},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
abstract = {Ruling the Machines that Rule the World? Our planet's information systems have now reached a level of scale and complexity at which we can no longer simply decide how they will behave. They are so sophisticated and so interconnected that humans can neither steer nor comprehend them with certainty. Can we trust such an infrastructure to society? For more than twenty years, Mark Burgess has been one of the pioneers of the science and technology behind the operation of this information infrastructure. In this book, he explains how far we have come in our understanding of the systems, and whether we yet have the necessary knowledge to prevent them from spiralling out of control. In Search of Certainty takes the reader on a fascinating journey, from the beginnings of scientific thought to our present day, illuminating information technology as an integral part of our modern historical and cultural narrative. It lays out key challenges for the future and suggests a daring new way to think about the future governance of the vast cybernetic organism we are in process of creating. "An instant classic in computer science! 'In Search of Certainty' is a brilliant piece of work by one of the most brilliant people I've ever met. Complex systems, like modern IT services, need to be understood from a perspective very different from traditional IT practice. The answers are rooted in science and Mark Burgess exposes this science like nobody else." -- Glenn O'Donnell, Principal Analyst, Forrester Research "An incredible journey by one of the [IT] industry's most important thinkers over the past 20 years. Like everything else he's done, this is unique and astonishing in its implications." --Carolyn Rowland, NIST "Mark brings together the digital microcosm and macrocosm, the mundane and the profound, the human and the technological, in a way that is important, wonderful, and truly mind-stretching." -- Jeff Sussna, Ingineering.IT "Mark Burgess practically invented modern IT infrastructure management software. Now he has produced a revolutionary work, part personal journey, part theoretical review, as he advances the state of infrastructure science -- and our comprehension -- again. IN SEARCH OF CERTAINTY is a must-read book from a true visionary." --Christopher Little, BMC Software "There are thought leaders, and then there are thought leaders. Mark Burgess is a scientist who can talk to the real world, and has been challenging it for 20 years, with the message of science." -- Reynold Jabbour, J.P. Morgan-Chase "Holy cow! ... Mark Burgess' pioneering work in the late-1990s presaged how large scale systems were designed and operated, and it has taken the world nearly two decades to catch up with him. Ignore the design principles and patterns described in this book at your peril -- in two decades, I'm sure that it will be embedded in how every architect, developers and operations professional talks about our craft, for practitioners, suppliers and researchers alike." -- Gene Kim, Author of Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win "To err is human, to explain is Mark Burgess." -- Patrick Debois "I only got through the Introduction and Chapter 1. I was so encouraged by just those that I started applying it to organization at Joyent and forgot to come back to the book." -- Ben Rockwood, Joyent "What I liked most about the book was the vast number of topics it drew on, there are examples from a very broad array of domains. This made it very fun. ... It really is a tour de force of most interesting things that have happened for the past 500 years..." -- Sigurd Teigen, CFEngine "The book is in parts a very personal description of the world we live in, and how it evolved... the book is about a journey, a personal one. I did like that part very much." -- Sven van der Meer, Ericsson}
}
@book{10.5555/3235995,
author = {Kocher, Parminder Singh},
title = {Microservices and Containers},
year = {2018},
isbn = {0134598385},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {Transition to Microservices and DevOps to Transform Your Software Development Effectiveness Thanks to the tech sectors latest game-changing innovationsthe Internet of Things (IoT), software-enabled networking, and software as a service (SaaS), to name a fewthere is now a seemingly insatiable demand for platforms and architectures that can improve the process of application development and deployment. In Microservices and Containers, longtime systems architect and engineering team leader Parminder Kocher analyzes two of the hottest new technology trends: microservices and containers. Together, as Kocher demonstrates, microservices and Docker containers can bring unprecedented agility and scalability to application development and deployment, especially in large, complex projects where speed is crucial but small errors can be disastrous. Learn how to leverage microservices and Docker to drive modular architectural design, on-demand scalability, application performance and reliability, time-to-market, code reuse, and exponential improvements in DevOps effectiveness. Kocher offers detailed guidance and a complete roadmap for transitioning from monolithic architectures, as well as an in-depth case study that walks the reader through the migration of an enterprise-class SOA system. Understand how microservices enable you to organize applications into standalone components that are easier to manage, update, and scale Decide whether microservices and containers are worth your investment, and manage the organizational learning curve associated with them Apply best practices for interprocess communication among microservices Migrate monolithic systems in an orderly fashion Understand Docker containers, installation, and interfaces Network, orchestrate, and manage Docker containers effectively Use Docker to maximize scalability in microservices-based applications Apply your learning with an in-depth, hands-on case study Whether you are a software architect/developer or systems professional looking to move on from older approaches or a manager trying to maximize the business value of these technologies, Microservices and Containers will be an invaluable addition to your library. Register your product at informit.com/register for convenient access to downloads, updates, and/or corrections as they become available.}
}
@inproceedings{10.23919/INM.2017.7987386,
author = {Van Rossem, Steven and Cai, Xuejun and Cerratoz, Ivano and Danielsson, Per and N\'{e}meth, Felici\'{a}n and Pechenot, Bertrand and Pelle, Istv\'{a}n and Risso, Fulvio and Sharma, Sachin and Sk\"{o}ldstr\"{o}m, Pontus and John, Wolfgang},
title = {NFV Service Dynamicity with a DevOps Approach},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/INM.2017.7987386},
doi = {10.23919/INM.2017.7987386},
abstract = {Next generation network services will be realized by NFV-based microservices to enable greater dynamics in deployment and operations. Here, we present a demonstrator that realizes this concept using the NFV platform built in the EU FP7 project UNIFY. Using the example of an Elastic Router service, we show automated deployment and configuration of service components as well as corresponding monitoring components facilitating automated scaling of the entire service. We also demonstrate automatic execution of troubleshooting and debugging actions. Operations of the service are inspired by DevOps principles, enabling quick detection of operational conditions and fast corrective actions. This demo conveys essential insights on how the life-cycle of an NFV-based network service may be realized in future NFV platforms.},
booktitle = {2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM)},
pages = {865–866},
numpages = {2},
location = {Lisbon, Portugal}
}
@inproceedings{10.1007/978-3-319-46295-0_12,
author = {Weerasiri, Denis and Barukh, Moshe Chai and Benatallah, Boualem and Cao, Jian},
title = {A Model-Driven Framework for Interoperable Cloud Resources Management},
year = {2016},
isbn = {978-3-319-46294-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-46295-0_12},
doi = {10.1007/978-3-319-46295-0_12},
abstract = {The proliferation of cloud computing has enabled powerful virtualization capabilities and outsourcing strategies. Suitably, a vast variety of cloud resource configuration and management tools have emerged to meet this needs, whereby DevOps are empowered to design end-to-end and automated cloud management tasks that span across a selection of best-of-breed tools. However, inherent heterogeneities among resource description models and management capabilities of such tools pose fundamental limitations when managing complex and dynamic cloud resources. In this paper we thus propose the notion of “Domain-specific Models” – a higher-level model-driven approach for describing elementary and federated cloud resources as reusable knowledge artifacts over existing tools. We also propose a pluggable architecture to translate these artifacts into lower-level resource descriptions and management rules. This paper describes concepts, techniques and a prototypical implementation. Experiments on real-world federated cloud resources display significant improvements in productivity. As well as notably enhanced usability achieved by our approach in comparison to traditional techniques.},
booktitle = {Service-Oriented Computing: 14th International Conference, ICSOC 2016, Banff, AB, Canada, October 10-13, 2016, Proceedings},
pages = {186–201},
numpages = {16},
keywords = {Cloud resource management, Interoperability, DevOps},
location = {Banff, Canada}
}
@book{10.5555/3294411,
author = {Chou, Eric},
title = {Mastering Python Networking: Your One-Stop Solution to Using Python for Network Automation, DevOps, and Test-Driven Development, 2nd Edition},
year = {2018},
isbn = {1789135990},
publisher = {Packt Publishing},
edition = {2nd},
abstract = {Master the art of using Python for a diverse range of network engineering tasks Key Features Explore the power of Python libraries to tackle difficult network problems efficiently and effectively Use Python for network device automation, DevOps, and software-defined networkingBecome an expert in implementing advanced network-related tasks with Python Book Description Networks in your infrastructure set the foundation for how your application can be deployed, maintained, and serviced. Python is the ideal language for network engineers to explore tools that were previously available to systems engineers and application developers. In this second edition of Mastering Python Networking, youll embark on a Python-based journey to transition from traditional network engineers to network developers ready for the next-generation of networks. This book begins by reviewing the basics of Python and teaches you how Python can interact with both legacy and API-enabled network devices. As you make your way through the chapters, you will then learn to leverage high-level Python packages and frameworks to perform network engineering tasks for automation, monitoring, management, and enhanced security. In the concluding chapters, you will use Jenkins for continuous network integration as well as testing tools to verify your network. By the end of this book, you will be able to perform all networking tasks with ease using Python. What you will learn Use Python libraries to interact with your network Integrate Ansible 2.5 using Python to control Cisco, Juniper, and Arista eAPI network devices Leverage existing frameworks to construct high-level APIs Learn how to build virtual networks in the AWS Cloud Understand how Jenkins can be used to automatically deploy changes in your network Use PyTest and Unittest for Test-Driven Network Development Who this book is for Mastering Python Networking is for network engineers and programmers who want to use Python for networking. Basic familiarity with Python programming and networking-related concepts such as Transmission Control Protocol/Internet Protocol (TCP/IP) will be useful.}
}
@article{10.1109/MS.2021.3094955,
author = {Gloor, Martin and Mazalin, Matija and Zimmermann, Adrian and Pautasso, Cesare and Zimmermann, Olaf},
title = {Automated Payment Terminal Testing: How to Achieve Continuous Integration for Systems That Are Almost Impossible to Virtualize},
year = {2021},
issue_date = {Nov.-Dec. 2021},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {38},
number = {6},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2021.3094955},
doi = {10.1109/MS.2021.3094955},
abstract = {Today, continuous integration (CI) is state of the art for agile software practices. Teams can choose from a range of tools, such as Jenkins, Atlassian Bamboo, and Microsoft Azure DevOps, that facilitate CI, from build servers to deployment platforms. For pure software solutions and where hardware can be virtualized, CI is relatively easy to achieve thanks to fully automated testing. It becomes significantly harder for systems involving hardware that have to be interacted with when executing test cases.},
journal = {IEEE Softw.},
month = {nov},
pages = {17–23},
numpages = {7}
}
@book{10.5555/3275619,
author = {Vohra, Deepak},
title = {Amazon Fargate Quick Start Guide: Learn How to Use AWS Fargate to Run Containers with Ease},
year = {2018},
isbn = {1789345014},
publisher = {Packt Publishing},
abstract = {This book gets you started and gives you knowledge about AWS Fargate in order to successfully incorporate it in your ECS container application. Key Features Gives you a quick walk-through over the Amazon Elastic Container Services (ECS)Provides an in depth knowledge of the components that Amazon Fargate has to offer. Learn the practical aspects of Docker application development with a managed serviceBook Description Amazon Fargate is new launch type for the Amazon Elastic Container Service (ECS). ECS is an AWS service for Docker container orchestration. Docker is the de facto containerization framework and has revolutionized packaging and deployment of software. The introduction of Fargate has made the ECS platform serverless. The book takes you through how Amazon Fargate runs ECS services composed of tasks and Docker containers and exposes the containers to the user. Fargate has simplified the ECS platform. We will learn how Fargate creates an Elastic Network Interface (ENI) for each task and how auto scaling can be enabled for ECS tasks. You will also learn about using an IAM policy to download Docker images and send logs to Cloud Watch. Finally, by the end of this book, you will have learned about how to use ECS CLI to create an ECS cluster and deploy tasks with Docker Compose. What you will learn Running Docker containers with a managed service Use Amazon ECS in Fargate launch mode Configure Cloud Watch Logging with Fargate Use an IAM Role with Fargate Understand how ECS CLI is used with Fargate Learn how to use an Application Load Balancer with Fargate Learn about Auto Scaling with Fargate Who this book is for This book is for Docker users and developers who want to learn about the Fargate platform. Typical job roles for which the book is suitable are DevOps Architect, Docker Engineer, and AWS Cloud Engineer. Prior knowledge of AWS and ECS is helpful but not mandatory. Table of Contents Getting Started with Amazon ECS and Amazon Fargate Networking Using Cloud Watch Logs Using Auto Scaling Using IAM Using an Application Load Balancer Using Amazon ECS CLI}
}
@inproceedings{10.1145/3486609.3487199,
author = {Atouani, Abdallah and Kirchhof, J\"{o}rg Christian and Kusmenko, Evgeny and Rumpe, Bernhard},
title = {Artifact and Reference Models for Generative Machine Learning Frameworks and Build Systems},
year = {2021},
isbn = {9781450391122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486609.3487199},
doi = {10.1145/3486609.3487199},
abstract = {Machine learning is a discipline which has become ubiquitous in the last few years. While the research of machine learning algorithms is very active and continues to reveal astonishing possibilities on a regular basis, the wide usage of these algorithms is shifting the research focus to the integration, maintenance, and evolution of AI-driven systems. Although there is a variety of machine learning frameworks on the market, there is little support for process automation and DevOps in machine learning-driven projects. In this paper, we discuss how metamodels can support the development of deep learning frameworks and help deal with the steadily increasing variety of learning algorithms. In particular, we present a deep learning-oriented artifact model which serves as a foundation for build automation and data management in iterative, machine learning-driven development processes. Furthermore, we show how schema and reference models can be used to structure and maintain a versatile deep learning framework. Feasibility is demonstrated on several state-of-the-art examples from the domains of image and natural language processing as well as decision making and autonomous driving.},
booktitle = {Proceedings of the 20th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {55–68},
numpages = {14},
keywords = {metamodeling, training, build systems, compiler, reference models, artificial intelligence, machine learning, artifact models},
location = {Chicago, IL, USA},
series = {GPCE 2021}
}
@inproceedings{10.5555/3507788.3507844,
author = {Kontogiannis, Kostas and Amyot, Daniel and Mylopoulos, John},
title = {Software Techniques for Engineering Cyber-Physical Systems},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cyber-Physical Systems (CPSs) refer to systems comprising software components, physical components, and social entities which monitor, control, and coordinate processes within a physical environment. CPSs apply to a wide range of mission-critical applications that span from the intelligent management of logistics in complex supply chains, advanced manufacturing systems, and smart contracts, all the way to autonomous systems, and systems that support the smart interactions between humans and machines (M2H), or between machines (M2M). In this respect, the engineering of CPSs goes beyond existing Software Engineering concepts, tools, and techniques because of the very nature of CPSs that spans three realms (cyber, physical, social) and therefore needs to address requirements that span these realms. During the workshop, the participants discussed and debated techniques and directions in six main thematic areas on engineering Cyber-Physical Systems. These thematic areas deal with specification and modeling, DevOps processes for CPSs, data management and analytics, infrastructure and event handling, run-time adaptivity, and finally security, trust, and traceability.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {289–290},
numpages = {2},
keywords = {continuous software engineering, software repositories, process metrics, fault-proneness prediction},
location = {Toronto, Canada},
series = {CASCON '21}
}
@article{10.1504/ijguc.2019.102710,
author = {Casola, Valentina and Benedictis, Alessandra De and Rak, Massimiliano and Villano, Umberto and Rios, Erkuden and Rego, Angel and Capone, Giancarlo},
title = {Model-Based Deployment of Secure Multi-Cloud Applications},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {10},
number = {6},
issn = {1741-847X},
url = {https://doi.org/10.1504/ijguc.2019.102710},
doi = {10.1504/ijguc.2019.102710},
abstract = {The wide diffusion of cloud services, offering functionalities in different application domains and addressing different computing and storage needs, opens up the possibility of building multi-cloud applications relying upon heterogeneous services, offered by multiple cloud service providers. This flexibility not only enables an efficient usage of resources, but also allows to cope with specific requirements in terms of security and performance, while requiring, however, a typically high development effort. The MUSA framework leverages a DevOps approach to develop multi-cloud applications with desired Security Service Level Agreements (SSLA). This paper describes the MUSA Deployer models and tools, which aim at decoupling the multi-cloud application modelling and development from application deployment and cloud services provisioning. With MUSA tools, designers and developers are able to express and easily evaluate the application security requirements, and to deploy it automatically by acquiring and configuring cloud services with the needed software components.},
journal = {Int. J. Grid Util. Comput.},
month = {jan},
pages = {639–653},
numpages = {14},
keywords = {cloud security, multi-cloud deployment, automated deployment}
}
@article{10.1145/3338851,
author = {Sun, Daniel and Chen, Shiping and Li, Guoqiang and Zhang, Yuanyuan and Atif, Muhammad},
title = {Multi-Objective Optimisation of Online Distributed Software Update for DevOps in Clouds},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1533-5399},
url = {https://doi.org/10.1145/3338851},
doi = {10.1145/3338851},
abstract = {This article studies synchronous online distributed software update, also known as rolling upgrade in DevOps, which in clouds upgrades software versions in virtual machine instances even when various failures may occur. The goal is to minimise completion time, availability degradation, and monetary cost for entire rolling upgrade by selecting proper parameters. For this goal, we propose a stochastic model and a novel optimisation method. We validate our approach to minimise the objectives through both experiments in Amazon Web Service (AWS) and simulations.},
journal = {ACM Trans. Internet Technol.},
month = {aug},
articleno = {43},
numpages = {20},
keywords = {rolling upgrade, stochastic modelling, software system reliability, multi-objective optimisation, Software operation}
}
@article{10.1109/MS.2012.38,
author = {Spinellis, Diomidis},
title = {Package Management Systems},
year = {2012},
issue_date = {March 2012},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {29},
number = {2},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2012.38},
doi = {10.1109/MS.2012.38},
abstract = {A package management system organizes and simplifies the installation and maintenance of software by standardizing and organizing the production and consumption of software collections. As a software developer, you can benefit from package managers in two ways: through a rich and stable development environment and through friction-free reuse.Promisingly, the structure that package managers bring both to the tools we use in our development process and the libraries we reuse in our products ties nicely with the recent move emphasizing DevOps (development operations) as an integration between software development and IT operations.},
journal = {IEEE Softw.},
month = {mar},
pages = {84–86},
numpages = {3},
keywords = {shared library, package management system, module dependencies, DevOps, software reuse}
}
@book{10.5555/2888515,
author = {Varghese, Shiju},
title = {Web Development with Go: Building Scalable Web Apps and RESTful Services},
year = {2015},
isbn = {1484210530},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Go, the open-source programming language originally developed at Google, makes it easy to build simple, reliable, and efficient software. It's a fast, statically typed, compiled language that feels like a dynamically typed, interpreted language. Its concurrency mechanisms, coupled with modern hardware, makes Go an effective general purpose programming language for a wide range of applications such as, system programming and embedded systems, desktop development and distributed systems, backend services for mobile and web, DevOps, and cloud application development. Web Development with Go will teach you how to develop scalable real-world web apps, RESTful services, and backend systems with Go. The book starts off by covering Go programming language fundamentals as a prerequisite for web development. After a thorough understanding of the basics, the book delves into web development using the built-in package, net/http. With each chapter youll be introduced to new concepts for gradually building a real-world web system. The book further shows you how to integrate Go with other technologies. For example, it provides an overview of using MongoDB as a means of persistent storage, and providesan end-to-end REST API sample features MongoDB as well. Developers looking for a full-fledged web development framework for building web apps will be introduced to Beego. The book then moves on to demonstrate how to deploy web apps to the cloud using the Google Cloud platform. Finally, the book introduces Docker, a revolutionary container technology platform for deploying containerized Go web apps to the Cloud. Web Development with Go provides:Basic fundamentals for building real-world web apps in Go. Through coverage of prerequisites and practical code examples. Demo web apps for attaining a deeper understanding of web development A reference REST API app which can be used to build scalable real-world backend services in Go. A through demonstration of deploying web apps to the Cloud using the Google Cloud platform, and Docker for deploying Go Servers. In totality, Go is a high-performance language while providing greater level of developer productivity, therefore Web Development with Go equips you with the necessary skills and knowledge required for effectively building robust and efficient web apps by leveraging the features of Go, and find yourself become the sought after person on Go among your peers and employers alike, in no time.}
}
@inproceedings{10.1145/3377813.3381353,
author = {Bansal, Chetan and Renganathan, Sundararajan and Asudani, Ashima and Midy, Olivier and Janakiraman, Mathru},
title = {DeCaf: Diagnosing and Triaging Performance Issues in Large-Scale Cloud Services},
year = {2020},
isbn = {9781450371230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377813.3381353},
doi = {10.1145/3377813.3381353},
abstract = {Large scale cloud services use Key Performance Indicators (KPIs) for tracking and monitoring performance. They usually have Service Level Objectives (SLOs) baked into the customer agreements which are tied to these KPIs. Dependency failures, code bugs, infrastructure failures, and other problems can cause performance regressions. It is critical to minimize the time and manual effort in diagnosing and triaging such issues to reduce customer impact. Large volume of logs and mixed type of attributes (categorical, continuous) in the logs makes diagnosis of regressions non-trivial.In this paper, we present the design, implementation and experience from building and deploying DeCaf, a system for automated diagnosis and triaging of KPI issues using service logs. It uses machine learning along with pattern mining to help service owners automatically root cause and triage performance issues. We present the learnings and results from case studies on two large scale cloud services in Microsoft where DeCaf successfully diagnosed 10 known and 31 unknown issues. DeCaf also automatically triages the identified issues by leveraging historical data. Our key insights are that for any such diagnosis tool to be effective in practice, it should a) scale to large volumes of service logs and attributes, b) support different types of KPIs and ranking functions, c) be integrated into the DevOps processes.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice},
pages = {201–210},
numpages = {10},
keywords = {issue triaging, root causing, machine learning, cloud services, performance analysis},
location = {Seoul, South Korea},
series = {ICSE-SEIP '20}
}
@inproceedings{10.1007/978-3-030-50323-9_10,
author = {Bromberg, Y\'{e}rom-David and Gitzinger, Louison},
title = {DroidAutoML: A Microservice Architecture to Automate the Evaluation of Android Machine Learning Detection Systems},
year = {2020},
isbn = {978-3-030-50322-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-50323-9_10},
doi = {10.1007/978-3-030-50323-9_10},
abstract = {The mobile ecosystem is witnessing an unprecedented increase in the number of malware in the wild. To fight this threat, actors from both research and industry are constantly innovating to bring concrete solutions to improve security and malware protection. Traditional solutions such as signature-based anti viruses have shown their limits in front of massive proliferation of new malware, which are most often only variants specifically designed to bypass signature-based detection. Accordingly, it paves the way to the emergence of new approaches based on Machine Learning (ML) technics to boost the detection of unknown malware variants. Unfortunately, these solutions are most often underexploited due to the time and resource costs required to adequately fine tune machine learning algorithms. In reality, in the Android community, state-of-the-art studies do not focus on model training, and most often go through an empirical study with a manual process to choose the learning strategy, and/or use default values as parameters to configure ML algorithms. However, in the ML domain, it is well known admitted that to solve efficiently a ML problem, the tunability of hyper-parameters is of the utmost importance. Nevertheless, as soon as the targeted ML problem involves a massive amount of data, there is a strong tension between feasibility of exploring all combinations and accuracy. This tension imposes to automate the search for optimal hyper-parameters applied to ML algorithms, that is not anymore possible to achieve manually. To this end, we propose a generic and scalable solution to automatically both configure and evaluate ML algorithms to efficiently detect Android malware detection systems. Our approach is based on devOps principles and a microservice architecture deployed over a set of nodes to scale and exhaustively test a large number of ML algorithms and hyper-parameters combinations. With our approach, we are able to systematically find the best fit to increase up&nbsp;to 11% the accuracy of two state-of-the-art Android malware detection systems.},
booktitle = {Distributed Applications and Interoperable Systems: 20th IFIP WG 6.1 International Conference, DAIS 2020, Held as Part of the 15th International Federated Conference on Distributed Computing Techniques, DisCoTec 2020, Valletta, Malta, June 15–19, 2020, Proceedings},
pages = {148–165},
numpages = {18},
keywords = {Android, Machine learning, AutoML, Malware},
location = {Valletta, Malta}
}
@inproceedings{10.1145/3383219.3383282,
author = {Akbar, Muhammad Azeem and Huang, Zhiqiu and Yu, Zhou and Mehmood, Faisal and Hussain, Yasir and Hamza, Muhammad},
title = {Towards Continues Code Recommendation and Implementation System: An Initial Framework},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383282},
doi = {10.1145/3383219.3383282},
abstract = {In the current era, the auto and reliable recommendation system plays a significant role in human life. The code recommender systems are being used in various source code databases to recommend the most suitable source code to the user. While code recommendation, the code analysis concerning 'code quality' and 'code implementation' is important to recommend the most reliable code by considering the objective of the user. The ultimate aim of this research work is to propose a code recommendation and implementation model using the characteristics of DevOps that assist in extracting, analyzing, implementing, and updating the recommender system continuously. The current study presents an initial framework of the proposed code recommender model. The design of the model is based on the data collected through literature review and by conducting an empirical study with experts. We believe that the proposed model will assist the researchers and practitioners to recommend the most secure and suitable source code according to their requirement.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {439–444},
numpages = {6},
keywords = {Empirical investigation, DevOps, Code recommendation system},
location = {Trondheim, Norway},
series = {EASE '20}
}
@inproceedings{10.5555/3124497.3124515,
author = {Syed, Madiha H. and Fernandez, Eduardo B.},
title = {The Software Container Pattern},
year = {2015},
isbn = {9781941652039},
publisher = {The Hillside Group},
address = {USA},
abstract = {A Software Container provides an execution environment for applications sharing a host operating system, binaries, and libraries with other containers with strong isolation between them. Software containers although not new, have become very important to support convenient, secure, and low overhead applications. Containers facilitate application deployment and distribution across computing environments. We present a pattern for a Software Containers which describes advantages and liabilities of the container in addition to examples of existing solutions. Containers have made a significant difference in supporting agile development frameworks like DevOps.},
booktitle = {Proceedings of the 22nd Conference on Pattern Languages of Programs},
articleno = {15},
numpages = {7},
keywords = {architecture patterns, virtualization, software containers, security patterns, security},
location = {Pittsburgh, Pennsylvania},
series = {PLoP '15}
}
@inproceedings{10.1109/HICSS.2016.674,
author = {Chen, Hong-Mei and Kazman, Rick and Haziyev, Serge and Kropov, Valentyn and Chtchourov, Dmitri},
title = {Big Data as a Service: A Neo-Metropolis Model Approach for Innovation},
year = {2016},
isbn = {9780769556703},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HICSS.2016.674},
doi = {10.1109/HICSS.2016.674},
abstract = {Big data as a Service (BDaaS) provides a viable alternative to circumvent many obstacles in implementing a big data strategy. Many BDaaS vendors are providing cloud platforms utilizing microservices and DevOps technologies to enable big data analytics for organizations that seek cost-effective and elastic deployments. However, existing models of BDaaS are mostly proprietary, closed-world operations and this can limit the potential for innovation. In this article, we argue for a new model called the Neo-Metropolis model -- a variant of the Metropolis model -- that offers an organized, coherent set of open-world innovation opportunities for vendors as well as for the platform's edge customers. We identify Neo-Metropolis model characteristics and illustrate Neo-Metropolis principles for developing BDaaS using a case study of Cisco's Intercloud Analytics platform. The implications of the Neo-Metropolis model are far beyond just BDaaS and it is foreseen to be an important model for future service platform development.},
booktitle = {Proceedings of the 2016 49th Hawaii International Conference on System Sciences (HICSS)},
pages = {5458–5467},
numpages = {10},
series = {HICSS '16}
}
@inproceedings{10.5555/2827719.2827735,
author = {Rajagopalan, Shriram and Jamjoom, Hani},
title = {App-Bisect: Autonomous Healing for Microservice-Based Apps},
year = {2015},
publisher = {USENIX Association},
address = {USA},
abstract = {The microservice and DevOps approach to software design has resulted in new software features being delivered immediately to users, instead of waiting for long refresh cycles. On the downside, software bugs and performance regressions have now become an important cause of downtime. We propose app-bisect, an autonomous tool to troubleshoot and repair such software issues in production environments. Our insight is that the evolution of microservices in an application can be captured as mutations to the graph of microservice dependencies, such that a particular version of the graph from the past can be deployed automatically, as an interim measure until the problem is permanently fixed. Using canary testing and version-aware routing techniques, we describe how the search process can be sped up to identify such a candidate version. We present the overall design and key challenges towards implementing such a system.},
booktitle = {Proceedings of the 7th USENIX Conference on Hot Topics in Cloud Computing},
pages = {16},
numpages = {1},
location = {Santa Clara, CA},
series = {HotCloud'15}
}
@article{10.1002/smr.2248,
author = {Ali, Nazakat and Daneth, Horn and Hong, Jang‐Eui},
title = {A Hybrid DevOps Process Supporting Software Reuse: A Pilot Project},
year = {2020},
issue_date = {July 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {32},
number = {7},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2248},
doi = {10.1002/smr.2248},
abstract = {Large software development organizations manage reusable software components through a reusable software repository in order to reduce development time and cost and to improve software quality and productivity. This paper presents a hybrid DevOps process with a systematic reuse‐based software development and management process to reduce the effort and cost required for the rework and to increase productivity. The proposed approach promotes the systematic reuse of software components based on both information retrieval and ontology‐based retrieval techniques. The reusable assets are presented in different styles to ease and support the reuse process with fine‐grained reusable artifacts. To evaluate our proposed process, a pilot project, aiming to monitor the health of a patient, was developed and monitored the reuse activities throughout the whole experiment. The results revealed that our proposed process got an average gain of 35.2% in terms of developed function points by reusing 30.63% of reusable artifacts available in the reuse repository.We proposed a hybrid DevOps process with a systematic reuse‐based software development and management process to reduce the effort and cost required for the rework and to increase productivity. DevOps encourage tool support during the software delivery process for quick delivery. Therefore, we have developed a reuse repository to support rapid delivery by reusing artifacts during the development process. A pilot project—a health‐monitoring and management application—was developed to evaluate our proposed hybrid DevOps process. image},
journal = {J. Softw. Evol. Process},
month = {jul},
numpages = {23},
keywords = {software reuse, DevOps, reuse repository, software development process}
}
@inproceedings{10.1145/3209914.3209938,
author = {Loseva, E. and Obeid, A. and Richter, H. and Backes, R. and Eichhorn, D.},
title = {Fixit - A Semi-Automatic Software Deployment Tool for Arbitrary Targets},
year = {2018},
isbn = {9781450364218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209914.3209938},
doi = {10.1145/3209914.3209938},
abstract = {The deployment of software packages becomes more and more difficult. Thus Canonical Ltd. has created a framework called "JuJu" that serves as a DevOps toolchain. JuJu allows an integrated software development, deployment and operation of software packages. Additionally Canocial provided hundreds of open-source JuJu-maintained software packages in an own online store for download. However, our tests revealed that only 14 % of 35 picked packages from the Canonical's JuJu charm store really be installed as they are. The reason is that many of them are sensitive against mismatches of what is contained in the relevant JuJu files and what exists as target hardware at the customer. Because of that, a new concept and tool called Fixit was created by us for the semi-automatic software-deployment of JuJu software packages onto arbitrary hardware and software environments such as Windows and Linux operating systems. Fixit improves the quota of successful first-try installations from 14 to 69 %. This is accomplished by semi-automatic analysis and transformation of the package source codes.},
booktitle = {Proceedings of the 2018 International Conference on Information Science and System},
pages = {16–24},
numpages = {9},
keywords = {system configuration, Software deployment, source code transformation, DevOps, JuJu},
location = {Jeju, Republic of Korea},
series = {ICISS '18}
}
@inproceedings{10.1145/3276945.3276952,
author = {Marron, Mark},
title = {Log++ Logging for a Cloud-Native World},
year = {2018},
isbn = {9781450360302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3276945.3276952},
doi = {10.1145/3276945.3276952},
abstract = {Logging is a fundamental part of the software development and deployment lifecycle but logging support is often provided as an afterthought via limited library APIs or third-party modules. Given the critical nature of logging in modern cloud, mobile, and IoT development workflows, the unique needs of the APIs involved, and the opportunities for optimization using semantic knowledge, we argue logging should be included as a central part of the language and runtime designs. This paper presents a rethinking of the logger for modern cloud-native workflows. Based on a set of design principles for modern logging we build a logging system, that supports near zero-cost for disabled log statements, low cost lazy-copying for enabled log statements, selective persistence of logging output, unified control of logging output across different libraries, and DevOps integration for use with modern cloud-based deployments. To evaluate these concepts we implemented the Log++ logger for Node.js hosted JavaScript applications.},
booktitle = {Proceedings of the 14th ACM SIGPLAN International Symposium on Dynamic Languages},
pages = {25–36},
numpages = {12},
keywords = {Runtime Monitoring, Logging, JavaScript},
location = {Boston, MA, USA},
series = {DLS 2018}
}
@article{10.1145/3393673.3276952,
author = {Marron, Mark},
title = {Log++ Logging for a Cloud-Native World},
year = {2018},
issue_date = {August 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/3393673.3276952},
doi = {10.1145/3393673.3276952},
abstract = {Logging is a fundamental part of the software development and deployment lifecycle but logging support is often provided as an afterthought via limited library APIs or third-party modules. Given the critical nature of logging in modern cloud, mobile, and IoT development workflows, the unique needs of the APIs involved, and the opportunities for optimization using semantic knowledge, we argue logging should be included as a central part of the language and runtime designs. This paper presents a rethinking of the logger for modern cloud-native workflows. Based on a set of design principles for modern logging we build a logging system, that supports near zero-cost for disabled log statements, low cost lazy-copying for enabled log statements, selective persistence of logging output, unified control of logging output across different libraries, and DevOps integration for use with modern cloud-based deployments. To evaluate these concepts we implemented the Log++ logger for Node.js hosted JavaScript applications.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {25–36},
numpages = {12},
keywords = {JavaScript, Logging, Runtime Monitoring}
}
@book{10.5555/2846202,
author = {Pabbathi, Kiran Kumar and ServiceManagers.Org},
title = {Guidance for Problem Management: According to ISO/IEC 20000 &amp; 9001 Standards, Six Sigma and ITSM Best Practices},
year = {2015},
isbn = {0991320557},
publisher = {ServiceManagers.org},
abstract = {Today there are numerous books on ITSM, but none which tells how to implement and improve ITSM practices for organizations and how to bring effectiveness in ITSM operations. Hence, I have chosen to write books in this area, providing detailed information; and this book "Guidance for Problem Management" is part of a series with explicit focus on problem management. And the focus is on topics like implementing problem management through Six Sigma's DMADV approach, improving problem management through Six Sigma's DMAIC approach, Roles and responsibilities in Problem management, Essentials for problem management operations, Integrations in problem management with other processes and functions, Best practices for problem management, Best practices for RCA, Problem management in DEVOPS and SCRUM, Advice for PM operations and many more interesting topics.}
}
@book{10.5555/3281341,
author = {Bhat, Sathyajith},
title = {Practical Docker with Python: Build, Release and Distribute Your Python App with Docker},
year = {2018},
isbn = {1484237838},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Learn the key differences between containers and virtual machines. Adopting a project based approach, this book introduces you to a simple Python application to be developed and containerized with Docker. After an introduction to Containers and Docker you'll be guided through Docker installation and configuration. You'll also learn basic functions and commands used in Docker by running a simple container using Docker commands. The book then moves on to developing a Python based Messaging Bot using required libraries and virtual environment where you'll add Docker Volumes to your project, ensuring your container data is safe. You'll create a database container and link your project to it and finally, bring up the Bot-associated database all at once with Docker Compose. What You'll Learn Build, run, and distribute Docker containers Develop a Python App and containerize it Use Dockerfile to run the Python App Define and run multi-container applications with Docker Compose Work with persisting data generated by and used by Docker containers Who This Book Is For Intermediate developers/DevOps practitioners who are looking to improve their build and release workflow by containerizing applications}
}
author = {Zhou, Huan and Hu, Yang and Su, Jinshu and de Laat, Cees and Zhao, Zhiming},
title = {CloudsStorm: An Application-Driven Framework to Enhance the Programmability and Controllability of&nbsp;Cloud Virtual Infrastructures},
year = {2018},
isbn = {978-3-319-94294-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-94295-7_18},
doi = {10.1007/978-3-319-94295-7_18},
abstract = {Most current IaaS (Infrastructure-as-a-Service) clouds provide dedicated virtual infrastructure resources to cloud applications with only limited programmability and controllability, which enlarges the management gap between infrastructures and applications. Traditional DevOps (development and operations) approaches are not suitable in&nbsp;today’s cloud environments, because of the slow, manual and error-prone collaboration between developers and operations personnel. It is essential to involve the operation into the cloud application development phase, which needs to make the infrastructure able to be controlled by the application directly. Moreover, each of these cloud providers offers their own set of APIs to access the resources. It causes the vendor lock-in problem for the application when managing its infrastructure across federated clouds or multiple data centers. To mitigate this gap, we have designed CloudsStorm, an application-driven DevOps framework that allows the application directly program and control its infrastructure. In particular, it provides multi-level programmability and controllability according to the applications’ specifications. We evaluate it by comparing its functionality to other proposed solutions. Moreover, we implement an extensible TSV-Engine, which is the core component of CloudsStorm for managing infrastructures. It is the first to be able to provision a networked infrastructure among public clouds. At last, we conduct a set of experiments on actual clouds and compare with other related DevOps tools. The experimental results demonstrate our solution is efficient and outperforms others.},
booktitle = {Cloud Computing – CLOUD 2018: 11th International Conference, Held as Part of the Services Conference Federation, SCF 2018, Seattle, WA, USA, June 25–30, 2018, Proceedings},
pages = {265–280},
numpages = {16},
keywords = {Cloud Applications, DevOps Tools, Virtual Infrastructure, Jclouds, Application Development Phase},
location = {Seattle, WA, USA}
}
@book{10.5555/3360253,
author = {Zadka, Moshe},
title = {DevOps in Python: Infrastructure as Python},
year = {2019},
isbn = {148424432X},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Explore and apply best practices for efficient application deployment. This book draws upon author Moshe Zadka's years of Dev Ops experience and focuses on the parts of Python, and the Python ecosystem, that are relevant for DevOps engineers. You'll start by writing command-line scripts and automating simple DevOps-style tasks. You'll then move on to more advanced cases, like using Jupyter as an auditable remote-control panel, and writing Ansible and Salt extensions. This work also covers how to use the AWS API to manage cloud infrastructure, and how to manage Python programs and environments on remote machines. Python was invented as a systems management language for distributed operating systems, which makes it an ideal tool for DevOps. u200bAssuming a basic understanding of Python concepts, this book is perfect for engineers who want to move from operations/system administration into coding. What You'll Learn Use third party packages and create new packages Create operating system management and automation code in Python Write testable code, and testing best practices Work with REST APIs for web clients Who This Book Is For Junior or intermediate sysadmin who has picked up some bash and Python basics.}
}
@book{10.5555/3235578,
author = {Farcic, Viktor},
title = {The DevOps 2.2 Toolkit},
year = {2018},
isbn = {1788991273},
publisher = {Packt Publishing},
abstract = {Learn from an expert on how use self-adapting and self-healing systems within Docker. Key Features Viktor Farcic shows you all aspects in the creation of self-adapting and self-healing systems in both a practical and hands-on approach. Learn how to choose a successful solution for metrics storage and query, including InfluxDB, Nagios and Sensu, Prometheus and Graphite. Discover how to integrate Docker Flow Monitor with Docker Flow Proxy. How to apply Docker self-healing and self-adaptive to both services and infrastructure. Book Description Building on The DevOps 2.0 Toolkit and The DevOps 2.1 Toolkit: Docker Swarm, Viktor Farcic brings his latest exploration of the Docker technology as he records his journey to explore two new programs, self-adaptive and self-healing systems within Docker. The DevOps 2.2 Toolkit: Self-Sufficient Docker Clusters is the latest book in Viktor Farcic's series that helps you build a full DevOps Toolkit. This book in the series looks at Docker, the tool designed to make it easier in the creation and running of applications using containers. In this latest entry, Viktor combines theory with a hands-on approach to guide you through the process of creating self-adaptive and self-healing systems. Within this book, Viktor will cover a wide-range of emerging topics, including what exactly self-adaptive and self-healing systems are, how to choose a solution for metrics storage and query, the creation of cluster-wide alerts and what a successful self-sufficient system blueprint looks like. Work with Viktor and dive into the creation of self-adaptive and self-healing systems within Docker. What you will learn Let Viktor Farcic show you all aspects in the creation of self-adapting and self-healing systems in both a practical and hands-on approach. Learn how to choose a successful solution for metrics storage and query, including InfluxDB, Nagios and Sensu, Prometheus and Graphite. Understand how to integrate Docker Flow Monitor with Docker Flow Proxy. The creation of cluster-wide alerts by creating alerts based on metrics. How to apply self-healing and self-adaptive to both services and infrastructure. Who this book is forThis book is for professionals experienced with Docker looking to create both self-adapting and self-healing systems using the software.}
}
@book{10.5555/3384195,
author = {Buchanan, Steve and Rangama, Janaka and Bellavance, Ned},
title = {Introducing Azure Kubernetes Service: A Practical Guide to Container Orchestration},
year = {2019},
isbn = {1484255186},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Go from zero to sixty deploying and running a Kubernetes cluster on Microsoft Azure! This hands-on practical guide to Microsoft's Azure Kubernetes Service (AKS), a managed container orchestration platform, arms you with the tools and knowledge you need to easily deploy and operate on this complex platform. Take a journey inside Docker containers, container registries, Kubernetes architecture, Kubernetes components, and core Kubectl commands. Drawing on hard-earned experience in the field, the authors provide just enough theory to help you grasp important concepts, teaching the practical straightforward knowledge you need to start running your own AKS cluster. You will dive into topics related to the deployment and operation of AKS, including Rancher for management, security, networking, storage, monitoring, backup, scaling, identity, package management with HELM, and AKS in CI/CD. What You Will Learn Develop core knowledge of Docker containers, registries, and Kubernetes; Gain AKS skills for Microsoft's fastest growing services in the cloud; Understand the pros and cons of deploying and operating AKS; Deploy and manage applications on the AKS platform; Use AKS within a DevOps CI/CD process; Who This Book Is For IT professionals who work with DevOps, the cloud, Docker, networking, storage, Linux, or Windows. Experience with cloud, DevOps, Docker, or application development is helpful.}
}
@book{10.5555/3169320,
author = {Macero, Moises},
title = {Microservices - The Practical Way},
year = {2017},
isbn = {197430745X},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
edition = {1st},
abstract = {This book is a complete guide to building a Microservices Architecture, supported by an application that evolves from a small monolith to a microservice ecosystem. The author follows a very pragmatic approach to explain the benefits of using this type of software architecture, instead of keeping the reader distracted with just theoretical concepts. A practical, evolving example This book, in contrast to guides available on the Internet, is based on a realistic, evolving example. Short guides can't focus on the multiple aspects of building microservices, and normally don't fit into more complex scenarios. Besides, trying to combine these short guides to make up a real application means facing a lot of gaps in the big puzzle of microservices. Guides are too shallow to help you building something real. On the other hand, most books about microservices are sometimes too focused on theory. Some books are usually on the other side of the spectrum. They explain topics like Domain Driven Design, Event Sourcing, Service Discovery, API Gateway, Centralized Logging, Continuous Deployment, DevOps, Reactive Systems, Circuit-Breaker patterns, etc. But that might be overwhelming: where to start? Is it needed to use all of these concepts in a microservice architecture? How to put them in practice? Those are the questions answered in this book, supported with code examples from the included application. Covered topics This book covers some of the state-of-the-art techniques in computer programming, from a practical point of view: - Microservices with Spring Boot - Event Driven Architecture and Messaging with RabbitMQ - RESTful services with Spring - Service Discovery with Eureka and Load Balancing with Ribbon - Routing requests with Zuul as your API Gateway - Test Driven Development: write your tests first - End to End Tests for an Event Driven Architecture using Cucumber - Continuous Integration and Deployment - On the other hand, this book also helps the reader to focus on what's important, - starting with the Minimum Viable Product but keeping the flexibility to evolve it.}
}
@inproceedings{10.1007/978-3-030-39306-9_13,
author = {Murphy, Gail C. and Kersten, Mik},
title = {Towards Bridging the Value Gap in DevOps},
year = {2019},
isbn = {978-3-030-39305-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39306-9_13},
doi = {10.1007/978-3-030-39306-9_13},
abstract = {The DevOps movement, which combines software development with information technology operations, enables the more frequent delivery of changes to a software system. Adopting DevOps practices is seen as enabling the ability to deliver more. But is the more that is getting done actually of value to the end user or to the producing organization? In this paper, we describe how the ideas of value streams are being applied to software development and how more systematic handling of features is key to enabling an increased focus on the delivery of value.},
booktitle = {Software Engineering Aspects of Continuous Development and New Paradigms of Software Production and Deployment: Second International Workshop, DEVOPS 2019, Ch\^{a}teau de Villebrumier, France, May 6–8, 2019, Revised Selected Papers},
pages = {181–190},
numpages = {10},
keywords = {Software development productivity, Value stream maps, Software requirements},
location = {Villebrumier, France}
}
@inproceedings{10.1109/ASE.2019.00081,
author = {Alizadeh, Vahid and Ouali, Mohamed Amine and Kessentini, Marouane and Chater, Meriem},
title = {RefBot: Intelligent Software Refactoring Bot},
year = {2019},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00081},
doi = {10.1109/ASE.2019.00081},
abstract = {The adoption of refactoring techniques for continuous integration received much less attention from the research community comparing to root-canal refactoring to fix the quality issues in the whole system. Several recent empirical studies show that developers, in practice, are applying refactoring incrementally when they are fixing bugs or adding new features. There is an urgent need for refactoring tools that can support continuous integration and some recent development processes such as DevOps that are based on rapid releases. Furthermore, several studies show that manual refactoring is expensive and existing automated refactoring tools are challenging to configure and integrate into the development pipelines with significant disruption cost.In this paper, we propose, for the first time, an intelligent software refactoring bot, called RefBot. Integrated into the version control system (e.g. GitHub), our bot continuously monitors the software repository, and it is triggered by any "open" or "merge" action on pull requests. The bot analyzes the files changed during that pull request to identify refactoring opportunities using a set of quality attributes then it will find the best sequence of refactorings to fix the quality issues if any. The bot recommends all these refactorings through an automatically generated pull-request. The developer can review the recommendations and their impacts in a detailed report and select the code changes that he wants to keep or ignore. After this review, the developer can close and approve the merge of the bot's pull request. We quantitatively and qualitatively evaluated the performance and effectiveness of RefBot by a survey conducted with experienced developers who used the bot on both open source and industry projects.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {823–834},
numpages = {12},
keywords = {quality, Software bot, refactoring},
location = {San Diego, California},
series = {ASE '19}
}
@book{10.5555/3235124,
author = {Marx, Ben and Valim, Jose and Tate, Bruce},
title = {Adopting Elixir: From Concept to Production},
year = {2018},
isbn = {1680502522},
publisher = {Pragmatic Bookshelf},
edition = {1st},
abstract = {Adoption is more than programming. Elixir is an exciting new language, but to successfully get your application from start to finish, you're going to need to know more than just the language. The case studies and strategies in this book will get you there. Learn the best practices for the whole life of your application, from design and team-building, to managing stakeholders, to deployment and monitoring. Go beyond the syntax and the tools to learn the techniques you need to develop your Elixir application from concept to production. Learn real-life strategies from the people who built Elixir and use it successfully at scale. See how Ben Marx and Bleacher Report maintain one of the highest-traffic Elixir applications by selling the concept to management and delivering on that promise. Find out how Bruce Tate and icanmakeitbetter hire and train Elixir engineers, and the techniques they've employed to design and ensure code consistency since Elixir's early days. Explore customer challenges in deploying and monitoring distributed applications with Elixir creator Jose Valim and Plataformatec. Make a business case and build a team before you finish your first prototype. Once you're in development, form strategies for organizing your code and learning the constraints of the runtime and ecosystem. Convince stakeholders, both business and technical, about the value they can expect. Prepare to make the critical early decisions that will shape your application for years to come. Manage your deployment with all of the knobs and gauges that good DevOps teams demand. Decide between the many options available for deployment, and how to best prepare yourself for the challenges of running a production application. This book picks up where most Elixir books leave off. It won't teach you to program Elixir, or any of its tools. Instead, it guides you through the broader landscape and shows you a holistic approach to adopting the language. What You Need: This book works with any version of Elixir.}
}
@inproceedings{10.1145/3501409.3501533,
author = {Xie, Yang and Tian, Guiyu and Tao, Yizheng and Li, Gongliang and Hu, Qian},
title = {Research on Application Development and Implementation Method Based on "Platform +APP" Mode},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501409.3501533},
doi = {10.1145/3501409.3501533},
abstract = {With the rise of the Internet, Internet software process methods have been introduced into the field of enterprise informatization, hoping to adapt to the rapid change of business and deliver value quickly. However, the requirements of enterprise informatization on software quality and security are usually ignored, which makes the software insufficient to solve the problems that enterprises pay more attention to, such as business complexity and consistency. At present, enterprise digital transformation and upgrading needs to simultaneously solve the problems of complexity, consistency, variability and invisibility, and efficiently deliver high quality, high security software to realize business value. Focusing on this demand, this paper analyzes and studies software process methods such as software engineering quality system management, safety software development life cycle and Devops method, and puts forward the "four-stages and twelve-nodes" software development and implementation method based on "Platform +APP" mode. This method carries out APP research and development activities and manages the software development process based on the common capabilities provided by the Cloud platform based on the Internet mode. The overall idea of "big agility, small waterfall" is adopted to give consideration to reliability, security and development efficiency. This method has been applied to the application system construction of the digital transformation of a large enterprise, and the practice proves that this method can take into account the reliability, security and variability of software, and the improvement of software batch supply ability is remarkable.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {689–694},
numpages = {6},
keywords = {Enterprise digitization, Devops, Software development process, Micro service},
location = {Xiamen, China},
series = {EITCE 2021}
}
@article{10.1145/2735399.2735416,
author = {Waller, Jan and Ehmke, Nils C. and Hasselbring, Wilhelm},
title = {Including Performance Benchmarks into Continuous Integration to Enable DevOps},
year = {2015},
issue_date = {March 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/2735399.2735416},
doi = {10.1145/2735399.2735416},
abstract = {The DevOps movement intends to improve communication, collaboration, and integration between software developers (Dev) and IT operations professionals (Ops). Automation of software quality assurance is key to DevOps success. We present how automated performance benchmarks may be included into continuous integration. As an example, we report on regression benchmarks for application monitoring frameworks and illustrate the inclusion of automated benchmarks into continuous integration setups.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {apr},
pages = {1–4},
numpages = {4},
keywords = {Kieker, Jenkins, MooBench}
}
@inproceedings{10.23919/INM.2017.7987357,
author = {Van Rossem, Steven and Cai, Xuejun and Cerrato, Ivano and Danielsson, Per and N\'{e}meth, Felici\'{a}n and Pechenot, Bertrand and Pelle, Istv\'{a}n and Risso, Fulvio and Sharma, Sachin and Sk\"{o}ldstr\"{o}m, Pontus and John, Wolfgang},
title = {NFV Service Dynamicity with a DevOps Approach: Insights from a Use-Case Realization},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/INM.2017.7987357},
doi = {10.23919/INM.2017.7987357},
abstract = {This experience paper describes the process of leveraging the NFV orchestration platform built in the EU FP7 project UNIFY to deploy a dynamic network service exemplified by an elastic router. Elasticity is realized by scaling dataplane resources as a function of traffic load. To achieve this, the service includes a custom scaling logic and monitoring capabilities. An automated monitoring framework not only triggers elastic scaling, but also a troubleshooting process which detects and analyzes anomalies, pro-actively aiding both dev and ops personnel. Such a DevOps-inspired approach enables a shorter update cycle to the running service. We highlight multiple learnings yielded throughout the prototype realization, focussing on the functional areas of service decomposition and scaling; programmable monitoring; and automated troubleshooting. Such practical insights will contribute to solving challenges such as agile deployment and efficient resource usage in future NFV platforms.},
booktitle = {2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM)},
pages = {674–679},
numpages = {6},
location = {Lisbon, Portugal}
}
@book{10.5555/3158716,
author = {Uphill, Thomas and Arundel, John and Khare, Neependra},
title = {DevOps: Puppet, Docker, and Kubernetes},
year = {2017},
isbn = {178829761X},
publisher = {Packt Publishing},
abstract = {Get hands-on recipes to automate and manage Linux containers with the Docker 1.6 environment and jump-start your Puppet development About This Book * Successfully deploy DevOps with proven solutions and recipes * Automate your infrastructure with Puppet and combine powerful DevOps methods * Deploy and manage highly scalable applications using Kubernetes * streamline the way you manage your applications Who This Book Is For This Learning Path is for developers, system administrators, and DevOps engineers who want to use Puppet, Docker, and Kubernetes in their development, QA, or production environments. This Learning Path assumes experience with Linux administration and requires some experience with command-line usage and basic text file editing. What You Will Learn * Discover how to build high availability Kubernetes clusters * Deal with inherent issues with container virtualization and container concepts * Create services with Docker to enable the swift development and deployment of applications * Make optimum use of Docker in a testing environment * Create efficient manifests to streamline your deployments * Automate Puppet master deployment using Git hooks, r10k, and PuppetDB In Detail With so many IT management and DevOps tools on the market, both open source and commercial, it's difficult to know where to start. DevOps is incredibly powerful when implemented correctly, and here's how to get it done. This Learning Path covers three broad areas: Puppet, Docker, and Kubernetes. This Learning Path is a large resource of recipes to ease your daily DevOps tasks. We begin with recipes that help you develop a complete and expert understanding of Puppet's latest and most advanced features. Then we provide recipes that help you efficiently work with the Docker environment. Finally, we show you how to better manage containers in different scenarios in production using Kubernetes. This course is based on these books: * Puppet Cookbook, Third Edition * Docker Cookbook * Kubernetes Cookbook Style and approach This easy-to-follow tutorial-style guide teaches you precisely how to configure complex systems in Puppet and manage your containers using Kubernetes.}
}
@inproceedings{10.1145/3409334.3452085,
author = {Light, Jarred and Pfeiffer, Phil and Bennett, Brian},
title = {An Evaluation of Continuous Integration and Delivery Frameworks for Classroom Use},
year = {2021},
isbn = {9781450380683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409334.3452085},
doi = {10.1145/3409334.3452085},
abstract = {Continuous integration and delivery (CI/CD) frameworks are a core element of DevOps-based software development. A PHP-based case study assessed the suitability of five such frameworks---JFrog Arti-factory, Bitbucket Pipelines, Jenkins, Azure DevOps, and TeamCity---for instructional use. The five were found to be roughly equivalent in terms of their usability for simple configurations. The effort needed to implement CI/CD substantially increased for more realistic production scenarios, like deployments to cloud and load-balanced platforms. These results suggest a need to limit CI/CD-based academic projects to simple infrastructure and technology stacks: e.g., a web application on a single instance web server.},
booktitle = {Proceedings of the 2021 ACM Southeast Conference},
pages = {204–208},
numpages = {5},
keywords = {CI/CD, computer science education, software engineering, DevOps, information systems education},
location = {Virtual Event, USA},
series = {ACM SE '21}
}
@book{10.5555/3137445,
author = {Farcic, Viktor},
title = {The DevOps 2.1 Toolkit: Docker Swarm Building, Testing, Deploying, and Monitoring Services inside Docker Swarm Clusters (Volume 2)},
year = {2017},
isbn = {1542468914},
publisher = {CreateSpace Independent Publishing Platform},
address = {North Charleston, SC, USA},
abstract = {The book envelops all aspects of building, testing, deploying, and monitoring services inside Docker Swarm clusters. We'll go through all the tools required for running a cluster. We'll go through the whole process with clusters running locally on a laptop. Once we are confident with the outcome, we'll translate the experience to different hosting providers like AWS, Azure, DigitalOcean, and so on. The book goes deeper into one of the subjects explored in The DevOps 2.0 Toolkit. It is updated to use the latest and greatest features and techniques introduced in Docker 1.12. We'll go through many practices and even more tools. While there will be a lot of theory, this is a hands-on book. You won't be able to complete it by reading it in a metro on a way to work. You'll have to read this book while in front of the computer and get your hands dirty.}
}
@inproceedings{10.1145/2756594.2756595,
author = {Austel, Paula and Chen, Han and Mikalsen, Thomas and Rouvellou, Isabelle and Sharma, Upendra and Silva-Lepe, Ignacio and Subramanian, Revathi},
title = {Continuous Delivery of Composite Solutions: A Case for Collaborative Software Defined PaaS Environments},
year = {2015},
isbn = {9781450335683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2756594.2756595},
doi = {10.1145/2756594.2756595},
abstract = {To help drive top line growth of their businesses, the development and IT organizations are under increasing pressure to create and deliver applications at ever faster paces. The advent of Cloud Computing has not only lowered the cost of IT operations but also enabled the notion of continuous delivery, which promises to radically reduce frictions in DevOps processes and speed up the product delivery cycle. With increased demand on functionality and feature, we have also seen these applications becoming more sophisticated, often integrating multiple modern programming models and techniques with the traditional n-tier web application into a composite application. This paper proposes an architectural blueprint for improved continuous delivery of these complex composite applications. It treats a solution as a holistic entity comprised of application logic and software-defined environment that the logic relies on. It also proposes a collaborative approach to software-defined Platform-as-a-Service environment building. This being an ongoing research project, this paper also briefly describes prototype, work-in-progress and thoughts on future directions.},
booktitle = {Proceedings of the 2nd International Workshop on Software-Defined Ecosystems},
pages = {3–6},
numpages = {4},
keywords = {software-defined environment, solution lifecycle, platform-as-a-service, cloud computing, continuous delivery},
location = {Portland, Oregon, USA},
series = {BigSystem '15}
}
@book{10.5555/3165237,
author = {Picozzi, Stefano and Hepburn, Mike and O'Connor, Noel},
title = {DevOps with OpenShift: Cloud Deployments Made Easy},
year = {2017},
isbn = {1491975962},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {For many organizations, a big part of DevOps appeal is software automation using infrastructure-as-code techniques. This book presents developers, architects, and infra-ops engineers with a more practical option. Youll learn how a container-centric approach from OpenShift, Red Hats cloud-based PaaS, can help your team deliver quality software through a self-service view of IT infrastructure. Three OpenShift experts at Red Hat explain how to configure Docker application containers and the Kubernetes cluster manager with OpenShifts developer- and operational-centric tools. Discover how this infrastructure-agnostic container management platform can help companies navigate the murky area where infrastructure-as-code ends and application automation begins. Get an application-centric view of automationand understand why its importantLearn patterns and practical examples for managing continuous deployments such as rolling, A/B, blue-green, and canaryImplement continuous integration pipelines with OpenShifts Jenkins capabilityExplore mechanisms for separating and managing configuration from static runtime softwareLearn how to use and customize OpenShifts source-to-image capabilityDelve into management and operational considerations when working with OpenShift-based application workloadsInstall a self-contained local version of the OpenShift environment on your computer}
}
@inbook{10.1145/3474624.3474630,
author = {Pereira, Igor and Carneiro, Tiago and Figueiredo, Eduardo},
title = {Main Differences of DevOps on IoT Systems},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3474630},
abstract = {IoT systems have barriers related to the different areas that involve their development. Hence, the scientific literature and industry practices investigate approaches that enable continuous interaction of these areas. Through semi-structured interviews with thirty-one professionals working in industry, this study investigated how DevOps is applied to make the development of IoT projects continuous and meet the demands of the industry. Through group discussions, we categorized the results of this study. As a preliminary contribution to this work, we investigate the contrasts between using DevOps in IoT system projects and using rigid, plan-oriented processes to develop embedded systems.},
booktitle = {Brazilian Symposium on Software Engineering},
pages = {315–319},
numpages = {5}
}
@article{10.1145/2693208.2693221,
author = {Du, Miao and Versteeg, Steve and Schneider, Jean-Guy and Han, Jun and Grundy, John},
title = {Interaction Traces Mining for Efficient System Responses Generation},
year = {2015},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2693208.2693221},
doi = {10.1145/2693208.2693221},
abstract = {Software service emulation is an emerging technique for creating realistic executable models of server-side behaviour. It is particularly useful in quality assurance and DevOps, replicating production-like conditions for large-scale enterprise software systems. Existing approaches can automatically build client-server and server-server interaction models of complex software systems directly from analysis of service interaction trace data. However, when these interaction traces become large, searching an entire trace library to generate a run-time responses can become very slow. In this paper we describe a new technique that utilises data mining, specifically clustering algorithms, to pre-process large amounts of recorded interaction trace data. With the obtained clusters we facilitate efficient yet well-formed runtime response generation in our Enterprise System emulation environment. We evaluate our approach using two common application-layer protocols: LDAP and SOAP. Our experimental results show that by utilising clustering techniques in the pre-processing step, the response generation time can be reduced by 99% on average compared with existing approaches.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {feb},
pages = {1–8},
numpages = {8},
keywords = {Interaction emulation, Automatic modelling, Service emulation, Traces clustering}
}
@inproceedings{10.1109/ICSE-Companion.2019.00022,
author = {Kersten, Mik},
title = {Analyzing Flow to Measure Value in Software Delivery},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion.2019.00022},
doi = {10.1109/ICSE-Companion.2019.00022},
abstract = {Projects, org charts, and software architecture are the best representations of value creation we have today. They are insufficient to support the scale and complexity of the software that is powering more and more of the world economy. In this talk, Dr. Kersten will propose a new set of abstractions for understanding and improving how software is built. He will introduce the concept of Value Stream Networks, which provide a set of models that span beyond the software architecture to include all of the artifacts involved in building software, from business idea to customer support. He will then show how we can visualize and operate on this new model in order to gain insights into the ground truth of what flows through organizations delivering software, and how we can improve that flow using the Flow Framework™. Kersten will summarize his experiences from open source, building a successful startup, and supporting some of the largest Agile and DevOps transformations in order to propose ideas for the research and practices still needed to better understand and manage software delivery at scale.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings},
pages = {3},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}
@inproceedings{10.1145/3219104.3219151,
author = {Cleveland, Sean B. and Dooley, Rion and Perry, David and Stubbs, Joe and Fonner, John M. and Jacobs, Gwen A.},
title = {Building Science Gateway Infrastructure in the Middle of the Pacific and Beyond: Experiences Using the Agave Deployer and Agave Platform to Build Science Gateways},
year = {2018},
isbn = {9781450364461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219104.3219151},
doi = {10.1145/3219104.3219151},
abstract = {In order to increase support for diverse projects amongst a wide range of research areas in accessing advanced computational and data resources, both local and national, the University of Hawai'i at Manoa (UH) and the University of Melbourne, Australia (Melbourne) partnered with the Texas Advanced Computing Center (TACC) to utilize the Agave platform. However, due to distance and the unique geographical locations of Hawai'i and Australia it was necessary to setup local Agave platform instances to provide responsive and robust middleware against which flexible science gateways could be constructed. To lower the entry barrier, required staff, and time required to stand up a local infrastructure, UH became the first external site to use the Agave Deployer which provides a combination of DevOps automation tools and containers to deploy and maintain a functional local Agave authentication/authorization, core science, and data persistence API instances. UH worked with TACC on testing the initial release of the Agave Deployer to provision the local UH infrastructure and later assisted Melbourne in adopting the Agave Deployer to stand up their infrastructure. We present the experiences and lessons learned in deploying and developing science gateway infrastructure and applications at these two institutions.},
booktitle = {Proceedings of the Practice and Experience on Advanced Research Computing},
articleno = {4},
numpages = {8},
keywords = {Science Gateway, HPC, ACM proceedings},
location = {Pittsburgh, PA, USA},
series = {PEARC '18}
}
@book{10.5555/3384197,
author = {Atwal, Harvinder},
title = {Practical DataOps: Delivering Agile Data Science at Scale},
year = {2019},
isbn = {1484251032},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Gain a practical introduction to DataOps, a new discipline for delivering data science at scale inspired by practices at companies such as Facebook, Uber, LinkedIn, Twitter, and eBay. Organizations need more than the latest AI algorithms, hottest tools, and best people to turn data into insight-driven action and useful analytical data products. Processes and thinking employed to manage and use data in the 20th century are a bottleneck for working effectively with the variety of data and advanced analytical use cases that organizations have today. This book provides the approach and methods to ensure continuous rapid use of data to create analytical data products and steer decision making. Practical DataOps shows you how to optimize the data supply chain from diverse raw data sources to the final data product, whether the goal is a machine learning model or other data-orientated output. The book provides an approach to eliminate wasted effort and improve collaboration between data producers, data consumers, and the rest of the organization through the adoption of lean thinking and agile software development principles. This book helps you to improve the speed and accuracy of analytical application development through data management and DevOps practices that securely expand data access, and rapidly increase the number of reproducible data products through automation, testing, and integration. The book also shows how to collect feedback and monitor performance to manage and continuously improve your processes and output. What You Will Learn, Develop a data strategy for your organization to help it reach its long-term goals; Recognize and eliminate barriers to delivering data to users at scale; Work on the right things for the right stakeholders through agile collaboration; Create trust in data via rigorous testing and effective data management; Build a culture of learning and continuous improvement through monitoring deployments and measuring outcomes; Create cross-functional self-organizing teams focused on goals not reporting lines; Build robust, trustworthy, data pipelines in support of AI, machine learning, and other analytical data products; Who This Book Is For Data science and advanced analytics experts, CIOs, CDOs (chief data officers), chief analytics officers, business analysts, business team leaders, and IT professionals (data engineers, developers, architects, and DBAs) supporting data teams who want to dramatically increase the value their organization derives from data. The book is ideal for data professionals who want to overcome challenges of long delivery time, poor data quality, high maintenance costs, and scaling difficulties in getting data science output and machine learning into customer-facing production.}
}
@article{10.2478/cait-2020-0018,
author = {Angara, Jayasri and Prasad, Srinivas and Sridevi, Gutta},
title = {DevOps Project Management Tools for Sprint Planning, Estimation and Execution Maturity},
year = {2020},
issue_date = {Jun 2020},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {20},
number = {2},
issn = {1314-4081},
url = {https://doi.org/10.2478/cait-2020-0018},
doi = {10.2478/cait-2020-0018},
abstract = {The goal of DevOps is to cut down the project timelines, increase the productivity, and manage rapid development-deployment cycles without impacting business and quality. It requires efficient sprint management. The objective of this paper is to develop different sprint level project management tools for quick project level Go/No-Go decision making (using real-time projects data and machine learning), sprint estimation technique (gamified-consensus based), statistical understanding of overall project management maturity, project sentiment &amp; perception. An attempt is made to device a model to calibrate the perception or the tone of a project culture using sentiment analysis.},
journal = {Cybern. Inf. Technol.},
month = {jun},
pages = {79–92},
numpages = {14},
keywords = {sentimental analysis, effort estimation, planning poker, Machine Learning (ML), DevOps}
}
@inproceedings{10.1007/978-3-030-55583-2_16,
author = {Zaeske, Wanja and Durak, Umut},
title = {Leveraging Semi-Formal Approaches for DepDevOps},
year = {2020},
isbn = {978-3-030-55582-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55583-2_16},
doi = {10.1007/978-3-030-55583-2_16},
abstract = {While formal methods have long been praised by the dependable Cyber-Physical System community, continuous software engineering practices are now employing or promoting semi-formal approaches for achieving lean and agile processes. This paper is a discussion about using Behaviour Driven Development, particularly Gherkin and RSpec for DepDevOps, DevOps for dependable Cyber-Physical Systems.},
booktitle = {Computer Safety, Reliability, and Security. SAFECOMP 2020 Workshops: DECSoS 2020, DepDevOps 2020, USDAI 2020, and WAISE 2020, Lisbon, Portugal, September 15, 2020, Proceedings},
pages = {217–222},
numpages = {6},
keywords = {Agile, Dependable systems, Semi-formal approaches},
location = {Lisbon, Portugal}
}
@inproceedings{10.5555/3155562.3155566,
author = {Deursen, Arie van},
title = {Software Engineering without Borders},
year = {2017},
isbn = {9781538626849},
publisher = {IEEE Press},
abstract = {DevOps approaches software engineering by advocating the removal of borders between development and operations. DevOps emphasizes operational resilience, continuous feedback from operations back to development, and rapid deployment of features developed. In this talk we will look at selected (automation) aspects related to DevOps, based on our collaborations with various industrial partners. For example, we will explore (automated) methods for analyzing log data to support deployments and monitor REST API integrations, (search-based) test input generation for reproducing crashes and testing complex database queries, and zero downtime database schema evolution and deployment. We will close by looking at borders beyond those between development and operations, in order to see whether there are other borders we need to remove in order to strengthen the impact of software engineering research.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering},
pages = {3},
numpages = {1},
location = {Urbana-Champaign, IL, USA},
series = {ASE 2017}
}
@inproceedings{10.5555/3124497.3124517,
author = {Sousa, Tiago Boldt and Correia, Filipe Figueiredo and Ferreira, Hugo Sereno},
title = {Patterns for Software Orchestration on the Cloud},
year = {2015},
isbn = {9781941652039},
publisher = {The Hillside Group},
address = {USA},
abstract = {Software businesses are redirecting their expansion towards service-oriented businesses models, highly supported by cloud computing. While cloud computing is not a new research subject, there's a clear lack of documented best practices on how to orchestrate cloud environments, either public, private or hybrid. This paper is targeted at DevOps practitioners and explores solutions for cloud orchestration, describing them as three patterns: a) Software Containerization, providing resource sharing with minimal virtualization overhead, b) Local Reverse Proxy, allowing applications to access any service in a cluster abstracting its placement and c) Orchestration by Resource Offering, ensuring applications get orchestrated in a machine with the required resources to run it. The authors believe that these three DevOps patterns will help researchers and newcomers to cloud orchestration to identify and adopt existing best practices earlier, hence, simplifying software life cycle management.},
booktitle = {Proceedings of the 22nd Conference on Pattern Languages of Programs},
articleno = {17},
numpages = {12},
keywords = {DevOps patterns, cloud computing, design-patterns},
location = {Pittsburgh, Pennsylvania},
series = {PLoP '15}
}
@book{10.5555/3002846,
author = {Atchison, Lee},
title = {Architecting for Scale: High Availability for Your Growing Applications},
year = {2016},
isbn = {1491943394},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Every day, companies struggle to scale critical applications. As traffic volume and data demands increase, these applications become more complicated and brittle, exposing risks and compromising availability. This practical guide shows IT, devops, and system reliability managers how to prevent an application from becoming slow, inconsistent, or downright unavailable as it grows. Scaling isnt just about handling more users; its also about managing risk and ensuring availability. Author Lee Atchison provides basic techniques for building applications that can handle huge quantities of traffic, data, and demand without affecting the quality your customers expect. In five parts, this book explores:Availability: learn techniques for building highly available applications, and for tracking and improving availability going forward Risk management: identify, mitigate, and manage risks in your application, test your recovery/disaster plans, and build out systems that contain fewer risks Services and microservices: understand the value of services for building complicated applications that need to operate at higher scale Scaling applications: assign services to specific teams, label the criticalness of each service, and devise failure scenarios and recovery plans Cloud services: understand the structure of cloud-based services, resource allocation, and service distribution}
}
@article{10.1016/j.jss.2018.07.014,
author = {Makki, Majid and Van Landuyt, Dimitri and Lagaisse, Bert and Joosen, Wouter},
title = {A Comparative Study of Workflow Customization Strategies: Quality Implications for Multi-Tenant SaaS},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.07.014},
doi = {10.1016/j.jss.2018.07.014},
journal = {J. Syst. Softw.},
month = {oct},
pages = {423–438},
numpages = {16},
keywords = {Workflow automation, Multi-tenancy, Functional customization, Software-as-a-Service, Software quality}
}
@book{10.5555/3306724,
author = {Klaffenbach, Florian and Klein, Markus and Hoppe, Sebastian and Michalski, Oliver and Damaschke, Jan-Henrik},
title = {Implementing Azure Solutions: Deploy and Manage Azure Containers and Build Azure Solutions with Ease, 2nd Edition},
year = {2018},
isbn = {1789343046},
publisher = {Packt Publishing},
abstract = {Get up and running with Azure services and learn how to implement them in your organization Key Features Deploy Azure Services in a controlled and preconfigured environment Discover best practices and techniques for implementing Azure Solutions Build and deploy an app using Azure App Services Book Description Microsoft Azure offers numerous solutions that can shape the future of any business. However, the major challenge that architects and administrators face lies in implementing these solutions. Implementing Azure Solutions helps you overcome this challenge by enabling you to implement Azure Solutions effectively. The book begins by guiding you in choosing the backend structure for your solutions. You will then work with the Azure toolkit and learn how to use Azure Managed Apps to share your solutions with the Azure service catalog. The book then focuses on various implementation techniques and best practices such as implementing Azure Cloud Services by configuring, deploying, and managing cloud services. As you progress through the chapters, you'll learn how to work with Azure-managed Kubernetes and Azure Container Services. By the end of the book, you will be able to build robust cloud solutions on Azure. What you will learn Create and manage a Kubernetes cluster in Azure Kubernetes Service (AKS) Implement site-to-site VPN and Express Route connections in your environment Explore the best practices in building and deploying app services Use Telemetry to monitor your Azure Solutions Design an Azure IoT solution and learn how to operate in different scenarios Implement a Hybrid Azure Design using Azure Stack Who this book is for If you're an IT architect, IT professional, or DevOps engineer who plans to implement Azure Solutions for your organization, this book is for you.}
}
@inproceedings{10.1145/3147704.3147742,
author = {Van Heesch, U. and Theunissen, T. and Zimmermann, O. and Zdun, U.},
title = {Software Specification and Documentation in Continuous Software Development: A Focus Group Report},
year = {2017},
isbn = {9781450348485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147704.3147742},
doi = {10.1145/3147704.3147742},
abstract = {We have been observing an ongoing trend in the software engineering domain towards development practices that rely heavily on verbal communication and small, closely-interacting teams. Among others, approaches like Scrum, Lean Software Development, and DevOps fall under this category. We refer to such development practices as Continuous Software Development (ConSD). Some core principles of ConSD are working in short iterations with frequent delivery, striving for an optimal balance between effectiveness and efficiency, and amplify learning in the development team. In such a context, many traditional patterns of software specification, documentation and knowledge preservation are not applicable anymore.To explore relevant topics, opinions, challenges and chances around specification, documentation and knowledge preservation in ConSD, we conducted a workshop at the 22nd European Conference on Pattern Languages of Programs (EuroPLoP), held in Germany in July 2017. The workshop participants came from the industry and academia.In this report, we present the results of the workshop. Among others, we elaborate on the difference between specification and documentation, the special role of architecture in ConSD in general, and architecture decision documentation in particular, and the importance of tooling that combines aspects of development, project management, and quality assurance. Furthermore, we describe typical issues with documentation and identify means to efficiently and effectively organize specification and documentation tasks in ConSD.},
booktitle = {Proceedings of the 22nd European Conference on Pattern Languages of Programs},
articleno = {35},
numpages = {13},
keywords = {Specification, Lean, Agile, Software engineering, DevOps, Continuous Software Development},
location = {Irsee, Germany},
series = {EuroPLoP '17}
}
@inproceedings{10.5555/3154690.3154720,
author = {Tak, Byungchul and Isci, Canturk and Duri, Sastry and Bila, Nilton and Nadgowda, Shripad and Doran, James},
title = {Understanding Security Implications of Using Containers in the Cloud},
year = {2017},
isbn = {9781931971386},
publisher = {USENIX Association},
address = {USA},
abstract = {Container technology is being adopted as a mainstream platform for IT solutions because of high degree of agility, reusability and portability it offers. However, there are challenges to be addressed for successful adoption. First, it is difficult to establish the full pedigree of images downloaded from public registries. Some might have vulnerabilities introduced unintentionally through rounds of updates by different users. Second, non-conformance to the immutable software deployment policies, such as those promoted by the DevOps principles, introduces vulnerabilities and the loss of control over deployed software. In this study, we investigate containers deployed in a production cloud to derive a set of recommended approaches to address these challenges. Our analysis reveals evidences that (i), images of unresolved pedigree have introduced vulnerabilities to containers belonging to third parties; (ii), updates to live public containers are common, defying the tenet that deployed software is immutable; and (iii), scanning containers or images alone is insufficient to eradicate vulnerabilities from public containers. We advocate for better systems support for tracking image provenance and resolving disruptive changes to containers, and propose practices that container users should adopt to limit the vulnerability of their containers.},
booktitle = {Proceedings of the 2017 USENIX Conference on Usenix Annual Technical Conference},
pages = {313–319},
numpages = {7},
location = {Santa Clara, CA, USA},
series = {USENIX ATC '17}
}
@inproceedings{10.1145/3350768.3350786,
author = {Souza, Renata and Rocha, Larissa and Silva, Franklin and Machado, Ivan},
title = {Investigating Agile Practices in Software Startups},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350786},
doi = {10.1145/3350768.3350786},
abstract = {Software development practices have smoothly shifted from traditional software development to new approaches that fit better to the real and unpredictable world. Agile practices might help practitioners respond quickly to customer change requests and deliver a working software on-schedule. Software startups are companies that develop innovative and software-intensive products and services in a dynamic and fast-growing market. This study aims to investigate the use of agile practices in software startups. We conducted 14 in-depth semi-structured interviews with the CEO and CTO from early-stage software startups. The results indicate that DevOps, Fundamentals, Design and Extreme Programming are the most used agile practice areas. Our results open up an opportunity to improve software engineering practices in early-stage software startups.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {317–321},
numpages = {5},
keywords = {Agile practices, Interview, Software startups, Software engineering},
location = {Salvador, Brazil},
series = {SBES 2019}
}
@inproceedings{10.1145/3451471.3451478,
author = {Gunawan, Fandi and K. Budiardjo, Eko},
title = {&nbsp;A Quest of Software Process Improvements in DevOps and Kanban: A Case Study in Small Software Company},
year = {2021},
isbn = {9781450388955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3451471.3451478},
doi = {10.1145/3451471.3451478},
abstract = {A good software process improves software products. In the case of a small software company, software development is a matter of survivability due to its limited resources to develop software. XYZ Company is a very small software company that adopted Kanban and DevOps and faced software delivery delays. It is necessary to recommend the software process improvements to solve this problem. Software process improvements are the outcomes of measurement and analysis of maturity levels using the ISO 29110 framework in a qualitative study. They are then analyzed using the Lean Six Sigma tools, namely gap analysis, root cause analysis, and Pareto analysis. Delphi method validated them and resulted in 18 improvement recommendations within four domains, namely (a) product, (b) people, (c) technology, and (d) process. The improvements span across two main processes within software development, namely (a) Project Management (PM) and (b) Software Implementation (SI). The XYZ Company or any agile-based software company could adopt the 18 improvement recommendations to enhance the software process and quality.},
booktitle = {2021 The 4th International Conference on Software Engineering and Information Management},
pages = {39–45},
numpages = {7},
keywords = {agile, SPI, Kanban, Software Process Improvement, ISO 29110, DevOps, small software company},
location = {Yokohama, Japan},
series = {ICSIM 2021}
}
@inproceedings{10.1145/3383219.3383252,
author = {Florea, Raluca and Stray, Viktoria},
title = {A Qualitative Study of the Background, Skill Acquisition, and Learning Preferences of Software Testers},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383252},
doi = {10.1145/3383219.3383252},
abstract = {Context: There is an indisputable industrial need for highly skilled individuals in the role of software testers. However, little is known about the educational background of these professionals, their first contact with the role, their preferences in acquiring skills, the impediments they face, and their perception of the software testing role. Objective: In the current paper, we report on the background, skills, learning preferences, and role profiles as described by professionals in software testing, spanning over a significant number of industries, countries, and software development models. Method: We conducted 19 in-depth, semi-structured interviews with software testing practitioners, across eight industries. We performed a content and thematic analysis of the collected data. Results: The practitioners in software testing had diverse educational backgrounds, and their first contact with the testing role was accidental. Exploratory testing was the preferred testing technique, while curiosity was identified as the most important feature in their skill set. Our respondents collaborated extensively with the developers, whom they perceived as a learning source and symbiotic work partner. Conclusion: The professionals in software testing described their skills as a rather undefined heap of knowledge, increasing with each work task. They used mainly informal and hands-on learning approaches. They found it necessary for education providers to present information on software testing. Generally, companies assisted them well in their skill development but need to allocate sufficient time for the learning. We identified five specialties of the role: product owner in testing, UX tester, DevOps tester, test-script automator, and test-process coordinator.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {299–305},
numpages = {7},
keywords = {Skill Acquisition, Software Tester, Software Testing, Hiring Software Testers, Software Testing Profiles},
location = {Trondheim, Norway},
series = {EASE '20}
}
@book{10.5555/3202455,
author = {Weise, Thomas and Ramanath, Munagala V. and Yan, David and Knowles, Kenneth},
title = {Learning Apache Apex: Real-Time Streaming Applications with Apex},
year = {2017},
isbn = {1788296400},
publisher = {Packt Publishing},
abstract = {Designing and writing a real-time streaming publication with Apache Apex About This BookGet a clear, practical approach to real-time data processing Program Apache Apex streaming applications This book shows you Apex integration with the open source Big Data ecosystem Who This Book Is For This book assumes knowledge of application development with Java and familiarity with distributed systems. Familiarity with other real-time streaming frameworks is not required, but some practical experience with other big data processing utilities might be helpful. What You Will LearnPut together a functioning Apex application from scratchScale an Apex application and configure it for optimal performance Understand how to deal with failures via the fault tolerance features of the platform Use Apex via other frameworks such as Beam Understand the DevOps implications of deploying Apex In Detail Apache Apex is a next-generation stream processing framework designed to operate on data at large scale, with minimum latency, maximum reliability, and strict correctness guarantees. Half of the book consists of Apex applications, showing you key aspects of data processing pipelines such as connectors for sources and sinks, and common data transformations. The other half of the book is evenly split into explaining the Apex framework, and tuning, testing, and scaling Apex applications. Much of our economic world depends on growing streams of data, such as social media feeds, financial records, data from mobile devices, sensors and machines (the Internet of Things - IoT). The projects in the book show how to process such streams to gain valuable, timely, and actionable insights. Traditional use cases, such as ETL, that currently consume a significant chunk of data engineering resources are also covered. The final chapter shows you future possibilities emerging in the streaming space, and how Apache Apex can contribute to it. Style and approach This book is divided into two major parts: first it explains what Apex is, what its relevant parts are, and how to write well-built Apex applications. The second part is entirely application-driven, walking you through Apex applications of increasing complexity.}
}
@book{10.5555/3383493,
author = {Ljubuncic, Igor and Litterer, Tom},
title = {System Administration Ethics: Ten Commandments for Security and Compliance in a Modern Cyber World},
year = {2019},
isbn = {1484249879},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Successfully navigate through the ever-changing world of technology and ethics and reconcile system administration principles for separation of duty, account segmentation, administrative groups and data protection. As security breaches become more common, businesses need to protect themselves when facing ethical dilemmas in today's digital landscape. This book serves as a equitable guideline in helping system administrators, engineers - as well as their managers - on coping with the ethical challenges of technology and security in the modern data center by providing real-life stories, scenarios, and use cases from companies both large and small. You'll examine the problems and challenges that people working with customer data, security and system administration may face in the cyber world and review the boundaries and tools for remaining ethical in an environment where it is so easy to step over a line - intentionally or accidentally. You'll also see how to correctly deal with multiple ethical situations, problems that arise, and their potential consequences, with examples from both classic and DevOps-based environments. Using the appropriate rules of engagement, best policies and practices, and proactive "building/strengthening" behaviors, System Administration Ethics provides the necessary tools to securely run an ethically correct environment. What You'll Learn The concepts of Least Privilege and Need to Know Request change approval and conduct change communication Follow "Break Glass" emergency procedures Code with data breaches, hacking and security violations, and proactively embrace and design for failures Build and gain trust with employees and build the right ethical culture Review what managers can do to improve ethics and protect their employees Who This Book Is For This book's primary audience includes system administrators and information security specialists engaged with the creation, process and administration of security policies and systems. A secondary audience includes company leaders seeking to improve the security, privacy, and behavioral practices.}
}
@inproceedings{10.1145/3275219.3275230,
author = {Ren, Zhongshan and Wang, Wei and Wu, Guoquan and Gao, Chushu and Chen, Wei and Wei, Jun and Huang, Tao},
title = {Migrating Web Applications from Monolithic Structure to Microservices Architecture},
year = {2018},
isbn = {9781450365901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3275219.3275230},
doi = {10.1145/3275219.3275230},
abstract = {In the traditional software development and deployment, the centralized monolithic is always adopted, as the modules are tightly coupled, which caused many inconvenience in software DevOps. The modules with bottlenecks in monolithic application cannot be extend separately as the application is an integral part, and different module cannot use different technology stack. To prolong the lifecycle of the monolithic applications, its need to migrated it to microservice architecture. Due to the complex logic and large number of third party framework libraries depended, get an accurate comprehensive of the application characteristics is challenging. The existing research mostly based on the static characteristics, lack of consideration of the runtime dynamic characteristics, and the completeness and accuracy of the static analysis is inadequate. To resolve above problems, we combined static and dynamic analysis to get static structure and runtime behavior characteristics of monolithic application. We employed the coupling among functions to evaluate the degree of dependence, and through function clustering to achieve the migration of legacy monolithic applications and its data to microservices architecture. Through the empirical study of migrate the typical legacy project to microservices, it is proved that we proposed method can offer precise guidance and assistance in the migration procedure. Experiments show that the method has high accuracy and low performance cost.},
booktitle = {Proceedings of the Tenth Asia-Pacific Symposium on Internetware},
articleno = {7},
numpages = {10},
keywords = {application migration, monolithic application, microservices, function clustering},
location = {Beijing, China},
series = {Internetware '18}
}
@article{10.1147/JRD.2016.2630478,
author = {Meng, F. J. and Wegman, M. N. and Xu, J. M. and Zhang, X. and Chen, P. and Chafle, G.},
title = {IT Troubleshooting with Drift Analysis in the DevOps Era},
year = {2017},
issue_date = {January/February 2017},
publisher = {IBM Corp.},
address = {USA},
volume = {61},
number = {1},
issn = {0018-8646},
url = {https://doi.org/10.1147/JRD.2016.2630478},
doi = {10.1147/JRD.2016.2630478},
abstract = {Over the past few years, DevOps practices have led to many changes in the software industry. The need for agility has resulted in continuous development and deployment of frequent small updates in IT production systems. However, the ever-changing applications and their IT operations environments challenge existing IT troubleshooting approaches, which generally depend on prebuilt domain knowledge and ignore the frequent changes in the DevOps era. Moreover, the complexity and diversity of application architectures exacerbate the challenges. In this paper, we propose an unsupervised learning based drift analysis tool named CHASER to detect and analyze abnormal changes (referred to as "drifts," which include configuration errors, processes hanging, etc.), with learned change models and patterns in real time as well as in the root cause analysis. First, we categorize the changes into two distinct groups (static and dynamic state changes) and periodically collect the finer grained changes. Then, we extract the time-series and structural features from these changes and apply statistical and machine learning algorithms to learn models and patterns from historical data. Furthermore, we apply these models and patterns to detect drifts in real time and infer possible root causes of reported errors based on a multidimensional correlation approach to improve the precision. Through experiments and case studies, we demonstrate the capability of CHASER.},
journal = {IBM J. Res. Dev.},
month = {jan},
pages = {6:62–6:73},
numpages = {12}
}
@inproceedings{10.1145/3194760.3194768,
author = {Steffens, Andreas and Lichter, Horst and D\"{o}ring, Jan Simon},
title = {Designing a Next-Generation Continuous Software Delivery System: Concepts and Architecture},
year = {2018},
isbn = {9781450357456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194760.3194768},
doi = {10.1145/3194760.3194768},
abstract = {Continuous Integration and Continuous Delivery are established practices in modern agile software development. The DevOps movement adapted theses practices and places the deployment pipeline at its heart as one of the main requirements to automate the software development process and to deliver and operate software in a more robust way with higher quality.Over the time a lot of systems and tools has been developed to implement the deployment pipeline and to support continuous delivery. But software development is complex, its process even more and due to the individual organization of software vendors no real all-in-one solution for CD exists. Literature identified a lot of challenges when adopting CD and DevOps in an organization.This paper presents a conceptual model and fundamental design decisions for a new generation of software delivery systems tackling some of these issues. Our approach focuses on two specific challenges for adopting CD. The first is the lack of flexibility and maintainability of software delivery systems. The second is the insufficient user support to model and manage delivery processes and pipelines. We introduce an automated mechanism to ease the effort for developers and other stakeholders.Based on these results this paper introduces an architectural proposal for a next-generation continuous software delivery system.},
booktitle = {Proceedings of the 4th International Workshop on Rapid Continuous Software Engineering},
pages = {1–7},
numpages = {7},
keywords = {devops, microservices, continuous software engineering, continuous delivery, architecture, framework, domain modelling},
location = {Gothenburg, Sweden},
series = {RCoSE '18}
}
@article{10.1007/s11277-021-08517-w,
author = {Al-Surmi, Ibrahim and Raddwan, Basheer and Al-Baltah, Ibrahim},
title = {Next Generation Mobile Core Resource Orchestration: Comprehensive Survey, Challenges and Perspectives},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {120},
number = {2},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-021-08517-w},
doi = {10.1007/s11277-021-08517-w},
abstract = {Re-architecting mobile network functions and central office is one of the hottest topics of software defined networking (SDN) and network function virtualization (NFV). It is known as Next generation mobile network (NGMN). The main benefit of re-architecting is to bring cloud advantages to mobile operator networks. On the other hand, while the openness is one of the most wanted characteristics of NGMN, many open source implementations have been introduced to accelerate realizing the NGMN such as resource allocation management and orchestration which is considered as one of the hardest problems in SDN, NFV, and network virtualization. To that end, this article has comprehensively reviewed the mobile core architecture, resource management and orchestration evolutions in order to investigate the relay of the mobile operators on open source components, especially in developing countries, in order to build their future NGMN infrastructure for 4G/5G (fourth/fifth generations) access networks. Furthermore, the article shows a large number of open source infrastructure’ components that the operator needs to integrate them together, which is a challenging task. Moreover, the article addresses the integration framework challenges for resource management and orchestration based on continuous integration continuous development (DevOps) model. The outcomes of this work encourage mobile operators to involve and contribute to open source integration efforts as well as build and test their NGMN integration scenarios.},
journal = {Wirel. Pers. Commun.},
month = {sep},
pages = {1341–1415},
numpages = {75},
keywords = {Software defined networking, Service function chaining, Management and orchestration, Resource allocation, Next generation mobile network, Network function virtualization}
}
@book{10.5555/2787831,
author = {van Baarsen, Jeroen},
title = {GitLab Cookbook},
year = {2014},
isbn = {1783986840},
publisher = {Packt Publishing},
abstract = {Over 60 hands-on recipes to efficiently self-host your own Git repository using GitLab About This BookGet hands-on with day-to-day tasks to effectively manage and administer your repository with GitLabCovers advanced topics like GitLab continuous integration and LDAP integrationAuthored by a member of the GitLab core team, this Cookbook gives practical insights into installing and self-hosting your own GitLab and GitLab CI serverWho This Book Is ForThis book is aimed at developers and devops that have a GitLab server running, and want to be sure they use it to its full potential. This book will also be useful for people looking for a great Git platform, and learn how to set it up successfully. Some system administrating experience on a UNIX-based system would be useful, but is not required. In Detail GitLab is a popular, open source Git hosting solution implemented by more than 50,000 organizations. This book has some carefully chosen recipes to help you decide on the type of GitLab installation that will fit your requirements. Along with covering some of the basic principles of Git, the book covers practical scenarios to show how you or your organization can effectively manage your proprietary code.You will learn how to manage multiple users, groups, and the permissions GitLab has for them. Updating your GitLab instance, creating backups, and restoring backups are a few of the important tasks described in detail to assist you in maintaining your GitLab server. Moreover, the GitLab API is extensively covered to guide you through the various operations to manage your project.}
}
@inproceedings{10.5220/0006913601750182,
author = {Rom\'{a}n Portabales, Ant\'{o}n and Nores, Mart\'{\i}n L\'{o}pez},
title = {Dockemu: Extension of a Scalable Network Simulation Framework Based on Docker and NS3 to Cover IoT Scenarios},
year = {2018},
isbn = {9789897583230},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0006913601750182},
doi = {10.5220/0006913601750182},
abstract = {The purpose of this project was to extend an existing open-source simulation framework called Dockemu in order to make it suitable to perform IoT simulations. The work covered some improvements with goes from the support of more network technologies to the use of setup and deployment tools used by modern devops professionals. The paper explains the architecture, the newly-added features and the specific advantages it offers for research works in IoT network simulations.},
booktitle = {Proceedings of 8th International Conference on Simulation and Modeling Methodologies, Technologies and Applications},
pages = {175–182},
numpages = {8},
keywords = {ns-3 Network Simulation Docker Real-time Containers.},
location = {Porto, Portugal},
series = {SIMULTECH 2018}
}
@book{10.5555/3019180,
author = {Makam, Sreenivas},
title = {Mastering CoreOS},
year = {2016},
isbn = {1785288121},
publisher = {Packt Publishing},
abstract = {Key FeaturesConfidently deploy distributed applications and effectively manage distributed infrastructure using Containers and CoreOSBuild secure, scalable CoreOS clusters to deploy distributed applications using open source technologies and industry best practicesEvery concept and technology in this book is illustrated with practical examples that can be used in both development and production environments. Book DescriptionCoreOS makes Google and Amazon-style Cloud infrastructure available for anyone building their own private Cloud. This book covers the CoreOS internals and the technologies used in the deployment of container-based distributed applications. It starts with an overview of CoreOS and distributed application development while sharing knowledge on related technologies. Critical CoreOS services and networking and storage considerations for CoreOS are covered next. In latter half of the book, you will learn about Container runtime systems such as Docker and Rkt and Container Orchestration using Kubernetes. You will also find out about the integration of popular orchestration solutions such as OpenStack, the AWS Container service, and the Google Container Engine with CoreOS and Docker. Lastly, we cover troubleshooting as well as production considerations. What you will learnInstall CoreOS on a VM, on the Cloud, and bare metal, and find out how to keep your cluster secure and up to dateConfigure and troubleshoot key CoreOS services, such as etcd, systemd, and fleet, for distributed application deploymentStudy container networking using CoreOS Flannel and other solutions, such as Docker libnetwork, Weave, and CalicoExplore the container filesystem and container volume management using Docker volume, NFS, GlusterFS, and FlockerGet to know the internals of container technologies such as Docker, Rkt, and Container orchestration using Openstack, Kubernetes and Docker native solutionsTroubleshoot CoreOS cluster and Containers using monitoring and logging tools and master production techniques such as staging, security, and automationAbout the AuthorSreenivas Makam is currently working as a senior engineering manager at Cisco Systems, Bangalore. He has a masters in electrical engineering and around 18 years of experience in the networking industry. He has worked in both start-ups and big established companies. His interests include SDN, NFV, Network Automation, DevOps, and cloud technologies, and he likes to try out and follow open source projects in these areas. His blog can be found at https://sreeninet.wordpress.com/ and his hacky code at https://github.com/smakam. Sreenivas is part of the Docker bloggers forum and his blog articles have been published in Docker weekly newsletters. He has done the technical reviewing for Mastering Ansible, Packt Publishing and Ansible Networking Report, O'Reilly Publisher. He has also given presentations at Docker meetup in Bangalore. Sreenivas has one approved patent.}
}
@article{10.1109/MIC.2018.032501519,
author = {Pallis, George and Trihinas, Demetris and Tryfonos, Athanasios and Dikaiakos, Marios},
title = {DevOps as a Service: Pushing the Boundaries of Microservice Adoption},
year = {2018},
issue_date = {May./Jun. 2018},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {22},
number = {3},
issn = {1089-7801},
url = {https://doi.org/10.1109/MIC.2018.032501519},
doi = {10.1109/MIC.2018.032501519},
abstract = {Software teams of all sizes are embracing the DevOps philosophy to rapidly deliver applications by adopting the microservice paradigm. Industry trends show clearly that microservice adoption is expanding rapidly. However, microservices are not without challenges. Deployment at scale calls for implementing autonomic principles and solutions, which lead to higher complexity and increased failure risk.},
journal = {IEEE Internet Computing},
month = {may},
pages = {65–71},
numpages = {7}
}
@inproceedings{10.1145/3297280.3300182,
author = {Rademacher, Florian and Sorgalla, Jonas and Sachweh, Sabine and Z\"{u}ndorf, Albert},
title = {A Model-Driven Workflow for Distributed Microservice Development},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3300182},
doi = {10.1145/3297280.3300182},
abstract = {Model-driven Development (MDD) is a software engineering approach that abstracts a software's design leveraging models. In particular, the development of complex, service-based architectures is considered to benefit from MDD techniques like model validation, transformation, and code generation. This paper presents an MDD-based workflow for distributed, DevOps-based microservice development and identifies the involved model types. They provide the foundation for the subsequent development of modeling languages to employ MDD for MSA engineering.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1260–1262},
numpages = {3},
keywords = {distributed microservice development, microservice architecture, modeling languages, model-driven microservice development, viewpoint modeling},
location = {Limassol, Cyprus},
series = {SAC '19}
}
@book{10.5555/3122904,
author = {Vijayakumar, Thurupathan},
title = {Practical Azure Application Development: A Step-by-Step Approach to Build Feature-Rich Cloud-Ready Solutions},
year = {2017},
isbn = {1484228162},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Get started and learn a step-by-step approach to application development using Microsoft Azure. Select the right services to solve the problem at hand in a cost-effective manner and explore the potential different services and how they can help in building enterprise applications. Azure has an ample amount of resources and tutorials, but most of them focus on specific services and explain those services on their own and in a given context. Practical Azure Application Development focuses on building complete solutions on Azure using different services. This book gives you the holistic approach to Azure as a solutions development platform. This book:Covers Azure as a solution development platform for building applications Provides real-world examples to understand why and when an Azure service is required Discusses how Azure helps to achieve continuous improvement and expansion of an application Provides application development experience from purchasing Azure to integrating with core Azure services, including an introduction to DevOps with VSTS What You'll Learn Use Azure services to solve real-world software problems Define the usage of Azure services and select the right services to solve the problem at hand Make clear and less ambiguous decisions about using different Azure services Take a holistic approach to Azure as a solution platform Understand the basics of security, data protection, and cost controls in Azure Who This Book Is ForDevelopers, software engineers, and architects who have experience in .NET and web development, but have little or no knowledge in planning and developing an application on Azure}
}
@proceedings{10.1145/2688130,
title = {ETX '14: Proceedings of the 2014 Workshop on Eclipse Technology EXchange},
year = {2014},
isbn = {9781450325301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2014 Eclipse Technology eXchange Workshop, sponsored by ACM SIGPLAN. This year's workshop continues the tradition of bringing together researchers and practitioners to discuss potential new uses of Eclipse in research and education as well as how Eclipse can leverage novel work in, e.g., programming languages and software engineering research. ETX has been a very successful workshop at OOPSLA from 2003-2007 and given that the Eclipse Ecosystem is still very relevant for research and education we felt that it was time to revive ETX at SPLASH.Due to the longer hiatus, the response to our call for papers was a little lower than what we had hoped for, but after a rigorous round of reviews we had three submissions that were accepted. We decided to complement the program with two invited talks and provided authors and attendees with an opportunity to showcase some of their Eclipse-related work in an open demonstration session. In the first invited talk, Anish Karmarkar from Oracle presented the standardization work on CAMP (Cloud Application Management for Platforms), a standard for managing software applications on PaaS cloud platforms. Since the cloud is an ongoing hot topic and has led to the proliferation of the DevOps model, his talk could provide interesting insights into the interrelation between development, deployment, and operation of software systems in the cloud, an area where IDEs could and arguably need to play a much stronger role in the future.Tam\'{a}s Szab\'{o} from itemis AG was the second invited speaker and talked about mbeddr, a set of extensible and integrated languages for embedded software development. mbeddr is a customizable IDE that is built on the Meta Programming System (MPS) from JetBrains. MPS directly works on the Abstract Syntax Tree of the IDE contents and this model is projected to the user for editing. mbeddr utilizes the capabilities of the projectional editor by providing various notations (projections) for the developers; apart from the regular source code, developers can easily embed tables, complex mathematical formulas and diagrams right into to the text.},
location = {Portland, Oregon, USA}
}
@book{10.5555/3035701,
author = {Schwartz, Mark},
title = {The Art of Business Value},
year = {2016},
isbn = {1942788045},
publisher = {IT Revolution Press},
abstract = {Do you really understand what business value is? Information technology can and should deliver business value. But the Agile literature has paid scant attention to what business value meansand how to know whether or not you are delivering it. This problem becomes ever more critical as you push value delivery toward autonomous teams and away from requirements tossed over the wall by business stakeholders. An empowered team needs to understand its goal!Playful and thought-provoking, The Art of Business Value explores what business value means, why it matters, and how it should affect your software development and delivery practices. More than any other IT delivery approach, DevOps (and Agile thinking in general) makes business value a central concern. This book examines the role of business value in software and makes a compelling case for why a clear understanding of business value will change the way you deliver software.This book will make you think deeply about not only what it means to deliver value but also the relationship of the IT organization to the rest of the enterprise. It will give you the language to discuss value with the business, methods to cut through bureaucracy, and strategies for incorporating Agile teams and culture into the enterprise. Most of all, this book will startle you into new ways of thinking about the cutting-edge of Agile practice and where it may lead.}
}
@inproceedings{10.1145/3365438.3410951,
author = {Song, Hui and Dautov, Rustem and Ferry, Nicolas and Solberg, Arnor and Fleurey, Franck},
title = {Model-Based Fleet Deployment of Edge Computing Applications},
year = {2020},
isbn = {9781450370196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3365438.3410951},
doi = {10.1145/3365438.3410951},
abstract = {Edge computing brings software in close proximity to end users and IoT devices. Given the increasing number of distributed Edge devices with various contexts, as well as the widely adopted continuous delivery practices, software developers need to maintain multiple application versions and frequently (re-)deploy them to a fleet of many devices with respect to their contexts. Doing this correctly and efficiently goes beyond manual capabilities and requires employing an intelligent and reliable automated approach. Accordingly this paper describes a joint research with a Smart Healthcare application provider on a model-based approach to automatically assigning multiple software deployments to hundreds of Edge gateways. From a Platform-Specific Model obtained from the existing Edge computing platform, we extract a Platform-Independent Model that describes a list of target devices and a pool of available deployments. Next, we use constraint solving to automatically assign deployments to devices at once, given their specific contexts. The resulting solution is transformed back to the PSM as to proceed with software deployment accordingly. We validate the approach with a Fleet Deployment prototype integrated into the DevOps toolchain currently used by the application provider. Initial experiments demonstrate the viability of the approach and its usefulness in supporting DevOps in Edge computing applications.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
pages = {132–142},
numpages = {11},
keywords = {model-based software engineering, DevOps, software deployment, device fleet, IoT},
location = {Virtual Event, Canada},
series = {MODELS '20}
}
@book{10.5555/3312421,
author = {O'Grady, Adam},
title = {GitLab Quick Start Guide: Migrate to GitLab for All Your Repository Management Solutions},
year = {2018},
isbn = {1789534348},
publisher = {Packt Publishing},
abstract = {Port projects over from GitHub and convert SVN projects to GitLab hosted git projects Key Features Effective guide for GitLab migration from GitHub and SVN Learn to implement DevOps with GitLab 11 Manage projects with issue boards and time tracking Book Description Gitlab is an open source repository management and version control toolkit with an enterprise offering. This book is the ideal guide to GitLab as a version control system (VCS), issue management tool, and a continuous integration platform. The book starts with an introduction to GitLab, a walkthrough of its features, and explores concepts such as version control systems, continuous integration, and continuous deployment. It then takes you through the process of downloading and installing a local copy of the on-premise version of GitLab in Ubuntu and/or CentOS. You will look at some common work?ows associated with GitLab work?ow and learn about project management in GitLab. You will see tools and techniques for migrating your code base from various version control systems such as GitHub and SVN to GitLab. By the end of the book, you will be using Gitlab for repository management, and be able to migrate projects from other VCSs to GitLab. What you will learn Set up CI and test builds for your projects Understand the benefits and limitations of GitLab work?ow Migrate from other common VCS platforms to Gitlab Create, review, and merge code changes Learn to branch local code and create a new branch in GitLab Configure sequential stages and simultaneous stages for CI/CD Access Mattermost for on-premise GitLab Discover the issue tracking features of GitLab Who this book is for The book is intended for the developers, SREs, and DevOps professionals who are looking for techniques to port their codebase to GitLab from GitHub or are looking to work with GitLab as their version control system of choice. If you've used other VCSs before, that will help with this book.}
}
@article{10.1109/MS.2016.60,
author = {Basiri, Ali and Behnam, Niosha and de Rooij, Ruud and Hochstein, Lorin and Kosewski, Luke and Reynolds, Justin and Rosenthal, Casey},
title = {Chaos Engineering},
year = {2016},
issue_date = {May 2016},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {33},
number = {3},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2016.60},
doi = {10.1109/MS.2016.60},
abstract = {Modern software-based services are implemented as distributed systems with complex behavior and failure modes. Many large tech organizations are using experimentation to verify such systems' reliability. Netflix engineers call this approach chaos engineering. They've determined several principles underlying it and have used it to run experiments. This article is part of a theme issue on DevOps.},
journal = {IEEE Softw.},
month = {may},
pages = {35–41},
numpages = {7}
}
author = {Miell, Ian and Sayers, Aidan Hobson},
title = {Docker in Practice},
year = {2016},
isbn = {1617292729},
publisher = {Manning Publications Co.},
address = {USA},
edition = {1st},
abstract = {Summary An open source container system, Docker makes deploying applications painless and flexible. Docker is powerful and simple to use, and it makes life easier for developers and administrators alike providing shorter build times, fewer production bugs, and effortless application roll-out. About the Book Docker in Practice is a hands-on guide that covers 101 specific techniques you can use to get the most out of Docker. Following a cookbook-style Problem/Solution/Discussion format, this practical handbook gives you instantly useful solutions for important problems like effortless server maintenance and configuration, deploying microservices, creating safe environments for experimentation, and much more. As you move through this book, youll advance from basics to Docker best practices like using it with your Continuous Integration process, automating complex container creation with Chef, and orchestration with Kubernetes. Whats Inside Speeding up your DevOps pipeline Cheaply replacing VMs Streamlining your cloud workflow Using the Docker Hub Navigating the Docker ecosystem About the Reader For anyone interested in real-world Docker. About the Authors Ian Miell and Aidan Hobson Sayers have contributed to Docker and have extensive experience building and maintaining commercial Docker-based infrastructures in large-scale environments.}
}
@book{10.5555/2965058,
author = {Preston, Stuart},
title = {Using Chef with Microsoft Azure},
year = {2016},
isbn = {1484214773},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {This book is your hands-on guide to infrastructure provisioning and configuration management in the cloud using Chefs open source, cross-platform toolset. With over 10,000 customers joining the Microsoft Azure cloud platform each week and steadily increasing usage, the need for automation approaches has never been greater. This book provides both practical examples and a much needed strategic overview of how these two technologies can be combined. Using Chef with Microsoft Azure takes you through the process of writing recipes in Chef to describe your infrastructure as code, and simplify your configuration management processes. Youll also meet the Chef tools that can be used to provision complete environments within Microsoft Azure. There are now a wide variety of tools and approaches that can be taken to provision resources such as virtual machines within Microsoft Azure. This book demonstrates them, discusses the benefits and weaknesses of each approach, and shows how a continuous provisioning pipeline can be established as part of a reliable, repeatable, and robust provisioning process. Each chapter has practical exercises that highlight the capabilities of both Chef and Microsoft Azure from an automation perspective and can be executed on Windows, Mac, or Linux platforms. In this book, youll learn: The purpose and principles behind automated provisioning Microsoft Azure concepts and management options How to deploy Chef Azure Virtual Machine Extensions using PowerShell, Azure command-line tools, and Chef Provisioning Chef Provisioning techniques, including provisioning PaaS resources such as Key Vault How to integrate quality tooling into the Chef development lifecycle, including Test Kitchen and InSpec with Azure compute resources How to set up a pipeline for continuous provisioning with Chef and Azure Who This Book Is For This book is for infrastructure platform and operations engineers and DevOps specialists/practitioners working with infrastructure and platform provisioning on Microsoft's public cloud, Azure. An understanding of programming in any language would be beneficial, but not necessary as the examples are designed to be easily readable by anyone with general IT experience. While it is expected most users picking up this book will be on the Windows platform, a good proportion of compute workload on the Azure platform is Linux based. As a result the book includes examples that are relevant to both Windows and Linux platforms.}
}
@inproceedings{10.5220/0005894302160221,
author = {Hadar, Ethan and Hadar, Irit},
title = {CURA: Complex-System Unified Reference Architecture},
year = {2016},
isbn = {9789897581892},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0005894302160221},
doi = {10.5220/0005894302160221},
abstract = {Constructing enterprise-level solution requires integration of existing, modified, and new modular technologies. A customer specific solution is instantiated from a reference implementation owned by the services organization, as a result of multiple products and their reference design created by the R&amp;D organization. Yet, the disciplines of R&amp;D and enterprise architecture differ in their analysis and design processes, artifacts, and semantics, leading to a mismatch in product design, knowledge and requirements interpretation. The Complex-systems Unified Reference Architecture (CURA) was developed as a common platform for both field and R&amp;D practices. This methodology binds a 4-layered structure and a 4-phased architecture process, controlling the solution architecture lifecycle from reference design to reference implementation and solution instantiation, and fits both agile and DevOps methodologies. The presented version of CURA was tested and implemented with several customers as a lean and minimal blueprinting approach, serving as part of the architectural deliverables. CURA can be adjusted to other visual binding notations such as UML and TOGAF modeling languages, and can scale up to system-of-systems design.},
booktitle = {Proceedings of the 11th International Conference on Evaluation of Novel Software Approaches to Software Engineering},
pages = {216–221},
numpages = {6},
keywords = {TOGAF, Solution Architecture, Enterprise IT., Reference Architecture},
location = {Rome, Italy},
series = {ENASE 2016}
}
@inproceedings{10.5555/3398761.3399086,
author = {Amaral, Cleber Jorge and Kampik, Timotheus and Cranefield, Stephen},
title = {A Framework for Collaborative and Interactive Agent-Oriented Developer Operations},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Considering the increasing prevalence of autonomous systems in today's society, one could expect that agent-oriented programming (AOP) is gaining traction among mainstream software engineering practitioners. However, the tools and frameworks that are used and developed in the academic multi-agent systems engineering community struggle to keep up with recent developments in the software industry in regards to how complex information systems are developed and maintained. An important aspect of recent changes in software engineering practices is the application of technologies that supports the increasingly fast iteration of a programming-testing-deployment cycle. Such approaches require intense collaboration that crosses boundaries between traditionally separated roles like software development, quality assurance, and operations; these approaches are often referred to as DevOps. Researchers need to explore what additional value AOP has to offer in the context of new paradigms and practices. In this paper, we work towards the integration of DevOps and AOP by introducing an extension of jacamo-web, an Integrated Development Environment (IDE) that supports the collaborative, web-based development and real-time continuous integration of autonomous agents and Multi-Agent Systems (MAS).},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2092–2094},
numpages = {3},
keywords = {engineering multi-agent systems, agent-oriented programming, iterative software development, ide},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}
@inproceedings{10.1145/2804371.2804373,
author = {Olszewska, Marta and Wald\'{e}n, Marina},
title = {DevOps Meets Formal Modelling in High-Criticality Complex Systems},
year = {2015},
isbn = {9781450338172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2804371.2804373},
doi = {10.1145/2804371.2804373},
abstract = {Quality is the cornerstone of high criticality systems, since in case of failure not only major financial losses are at stake, but also human lives. Formal methods that support model based-development are one of the methodologies used to achieve correct-by-construction systems. However, these are often heavy-weight and need a dedicated development process. In our work we combine formal and agile software engineering approaches. In particular, we use Event-B and Scrum to assure the quality and more rapid and flexible development. Since we identified that there are more prerequisites for a successful IT project, we use DevOps to embrace the development, quality assurance and IT operations. In this paper we show how formal modelling can function within DevOps and thus promote various dimensions of quality and continuous delivery.},
booktitle = {Proceedings of the 1st International Workshop on Quality-Aware DevOps},
pages = {7–12},
numpages = {6},
keywords = {Scrum, formal modelling, Agile, DevOps, Event-B},
location = {Bergamo, Italy},
series = {QUDOS 2015}
}
@article{10.1145/3359981,
author = {Leite, Leonardo and Rocha, Carla and Kon, Fabio and Milojicic, Dejan and Meirelles, Paulo},
title = {A Survey of DevOps Concepts and Challenges},
year = {2019},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3359981},
doi = {10.1145/3359981},
abstract = {DevOpsis a collaborative and multidisciplinary organizational effort to automate continuous delivery of new software updates while guaranteeing their correctness and reliability. The present survey investigates and discusses DevOps challenges from the perspective of engineers, managers, and researchers. We review the literature and develop a DevOps conceptual map, correlating the DevOps automation tools with these concepts. We then discuss their practical implications for engineers, managers, and researchers. Finally, we critically explore some of the most relevant DevOps challenges reported by the literature.},
journal = {ACM Comput. Surv.},
month = {nov},
articleno = {127},
numpages = {35},
keywords = {configuration management, release process, and build process, continuous (delivery, deployment, integration), versioning, DevOps}
}
@book{10.5555/3122730,
author = {Armstrong, Steven},
title = {DevOps for Networking},
year = {2016},
isbn = {1786464853},
publisher = {Packt Publishing},
abstract = {Boost your organization's growth by incorporating networking in the DevOps culture About This Book Implement networking fundamentals to the DevOps culture with ease, improving your organization's stabilityLeverage various open source tools such as Puppet and Ansible in order to automate your network This step-by-step learning guide collaborating the functions of developers and network administrators Who This Book Is For The book is aimed for Network Engineers, Developers, IT operations and System admins who are planning to incorporate Networking in DevOps culture and have no knowledge about it. What You Will Learn Learn about public and private cloud networking using AWS and OpenStack as examples Explore strategies that can be used by engineers or managers to initiate the cultural changes required to enable the automation of network functions Learn about SDN and how an API-driven approach to networking can help solve common networking problemsGet the hang of configuration management tools, such as Ansible and Jenkins, that can be used to orchestrate and configure network devicesSetup continuous integration, delivery, and deployment pipelines for network functions Create test environments for network changes Understand how load balancing is becoming more software defined with the emergence of microservice applications In Detail Frustrated that your company's network changes are still a manual set of activities that slow developers down? It doesn't need to be that way any longer, as this book will help your company and network teams embrace DevOps and continuous delivery approaches, enabling them to automate all network functions. This book aims to show readers network automation processes they could implement in their organizations. It will teach you the fundamentals of DevOps in networking and how to improve DevOps processes and workflows by providing automation in your network. You will be exposed to various networking strategies that are stopping your organization from scaling new projects quickly. You will see how SDN and APIs are influencing DevOps transformations, which will in turn help you improve the scalability and efficiency of your organizations networks operations. You will also find out how to leverage various configuration management tools such as Ansible, to automate your network. The book will also look at containers and the impact they are having on networking as well as looking at how automation impacts network security in a software-defined network. Style and approach This will be a comprehensive, learning guide for teaching our readers how networking can be leveraged to improve the DevOps culture for any organization.}
}
@book{10.5555/2821210,
author = {Roberts, Trevor A. and Atwell, Josh and Sigler, Egle and van Doorn, Yvo},
title = {DevOps for VMware Administrators},
year = {2015},
isbn = {0133846474},
publisher = {VMware Press},
address = {Palo Alto, CA, USA},
edition = {1st},
abstract = {DevOps for VMware Administrators is the first book focused on using DevOps tools and practices with VMware technologies. The authors introduce high-value tools from third parties and VMware itself, and guide you through using them to improve the performance of all your virtualized systems and applications. Youll walk through automating and optimizing configuration management, provisioning, log management, continuous integration, and more. The authors also offer step-by-step coverage of deploying and managing applications at scale with Docker containers and Google Kubernetes. They conclude with an up-to-the-minute discussion of VMwares newest DevOps initiatives, including VMware vRealize Automation and VMware vRealize Code Stream. Coverage includes Understanding the challenges that DevOps tools and practices can help VMware administrators to solve Using Vagrant to quickly deploy Dev and Test environments that match production system specifications Writing Chef recipes that streamline server configuration and maintenance Simplifying Unix/Linux configuration management and orchestration with Ansible Implementing Docker containers for faster and easier application management Automating provisioning across the full lifecycle with Razor Integrating Microsoft PowerShell Desired State Configuration (DSC) and VMware PowerCLI to automate key Windows Server and vSphere VM admin tasks Using Puppet to automate infrastructure provisioning, configuration, orchestration, and reporting Supercharging log management with ELK (Elasticsearch, Logstash, Kibana) Supporting DevOps source code management with Git and continuous integration practices with Jenkins Achieving continuous integration, delivery, and deployment with VMwares vRealize Code Stream}
}
@book{10.5555/3153463,
author = {Brikman, Yevgeniy},
title = {Terraform: Up and Running Writing Infrastructure as Code},
year = {2017},
isbn = {1491977086},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Terraform has emerged as a key player in the DevOps world for defining, launching, and managing infrastructure as code (IAC) across a variety of cloud and virtualization platforms, including AWS, Google Cloud, and Azure. This hands-on book is the fastest way to get up and running with Terraform. Gruntwork co-founder Yevgeniy (Jim) Brikman walks you through dozens of code examples that demonstrate how to use Terraforms simple, declarative programming language to deploy and manage infrastructure with just a few commands. Whether youre a novice developer, aspiring DevOps engineer, or veteran sysadmin, this book will take you from Terraform basics to running a full tech stack capable of supporting a massive amount of traffic and a large team of developers. Compare Terraform to other IAC tools, such as Chef, Puppet, Ansible, and Salt Stack Use Terraform to deploy server clusters, load balancers, and databases Learn how Terraform manages the state of your infrastructure and how it impacts file layout, isolation, and locking Create reusable infrastructure with Terraform modules Try out advanced Terraform syntax to implement loops, if-statements, and zero-downtime deployment Use Terraform as a team, including best practices for writing, testing, and versioning Terraform code}
}
@inproceedings{10.1145/3324884.3416640,
author = {Yin, Likang and Filkov, Vladimir},
title = {Team Discussions and Dynamics during DevOps Tool Adoptions in OSS Projects},
year = {2020},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416640},
doi = {10.1145/3324884.3416640},
abstract = {In Open Source Software (OSS) projects, pre-built tools dominate DevOps-oriented pipelines. In practice, a multitude of configuration management, cloud-based continuous integration, and automated deployment tools exist, and often more than one for each task. Tools are adopted (and given up) by OSS projects regularly. Prior work has shown that some tool adoptions are preceded by discussions, and that tool adoptions can result in benefits to the project. But important questions remain: how do teams decide to adopt a tool? What is discussed before the adoption and for how long? And, what team characteristics are determinant of the adoption?In this paper, we employ a large-scale empirical study in order to characterize the team discussions and to discern the teamlevel determinants of tool adoption into OSS projects' development pipelines. Guided by theories of team and individual motivations and dynamics, we perform exploratory data analyses, do deep-dive case studies, and develop regression models to learn the determinants of adoption and discussion length, and the direction of their effect on the adoption. From data of commit and comment traces of large-scale GitHub projects, our models find that prior exposure to a tool and member involvement are positively associated with the tool adoption, while longer discussions and the number of newer team members associate negatively. These results can provide guidance beyond the technical appropriateness for the timeliness of tool adoptions in diverse programmer teams.Our data and code is available at https://github.com/lkyin/tool_adoptions.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {697–708},
numpages = {12},
location = {Virtual Event, Australia},
series = {ASE '20}
}
@inproceedings{10.1145/2811681.2824996,
author = {Shahin, Mojtaba},
title = {Architecting for DevOps and Continuous Deployment},
year = {2015},
isbn = {9781450337960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811681.2824996},
doi = {10.1145/2811681.2824996},
abstract = {Development and Operations (DevOps) in the context of Continuous Deployment (CD) have emerged as an attractive software development movement, which tries to establish a strong connection between development and operations teams. CD is defined as the ability to quickly put new releases into production. We believe that DevOps/CD brings new challenges for architects, which considerably impacts both on their (architectural) design decisions and their organizational responsibilities. We assert that there is an important and urgent need of sufficient research work to gain a deep understanding of how DevOps/CD adoption can influence architecting, architectural decision-making processes and their outcomes in an organization. This PhD research is aimed at understanding and addressing new challenges for designing architectures for supporting DevOps in the context of CD.},
booktitle = {Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference},
pages = {147–148},
numpages = {2},
keywords = {continuous deployment, DevOps, Software architecture},
location = {Adelaide, SA, Australia},
series = {ASWEC ' 15 Vol. II}
}
@inproceedings{10.1145/3412841.3442016,
author = {Brito, Miguel and Cunha, J\'{a}come and Saraiva, Jo\~{a}o},
title = {Identification of Microservices from Monolithic Applications through Topic Modelling},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442016},
doi = {10.1145/3412841.3442016},
abstract = {Microservices emerged as one of the most popular architectural patterns in the recent years given the increased need to scale, grow and flexibilize software projects accompanied by the growth in cloud computing and DevOps. Many software applications are being submitted to a process of migration from its monolithic architecture to a more modular, scalable and flexible architecture of microservices. This process is slow and, depending on the project's complexity, it may take months or even years to complete.This paper proposes a new approach on microservice identification by resorting to topic modelling in order to identify services according to domain terms. This approach in combination with clustering techniques produces a set of services based on the original software. The proposed methodology is implemented as an open-source tool for exploration of monolithic architectures and identification of microservices. A quantitative analysis using the state of the art metrics on independence of functionality and modularity of services was conducted on 200 open-source projects collected from GitHub. Cohesion at message and domain level metrics' showed medians of roughly 0.6. Interfaces per service exhibited a median of 1.5 with a compact interquartile range. Structural and conceptual modularity revealed medians of 0.2 and 0.4 respectively.Our first results are positive demonstrating beneficial identification of services due to overall metrics' results.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1409–1418},
numpages = {10},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}
@book{10.5555/2802125,
author = {Gajda, Wlodzimierz},
title = {Pro Vagrant},
year = {2015},
isbn = {1484200748},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Pro Vagrant teaches you how to effectively implement and optimize Vagrant in your everyday work environment. Master the creation and configuration of virtual development environments with an easy-to-use workflow, and focus on automation. Vagrant lowers development environment setup time, increases development/production parity, and makes the "works on my machine" excuse a relic of the past. DevOps is mainstream best practice nowadays, and Vagrant sits firmly in the DevOps toolkit. This book will take you from basic usage and getting started, to provisioning with Shell, Puppet, and Chef. You will see how to use Vagrant in real-life scenarios, so that you can start to use Vagrant day-to-day in your work. Author Wodimierz Gajda is a Vagrant expert and now brings his experience to you in Pro Vagrant. This is an indispensable book for anyone using Vagrant - add it to your library today. What youll learn Get started with Vagrant, basic usage Provisioning with Shell, Puppet, and Chef How to use Vagrant in real-life scenarios Who this book is for This book is for anyone wishing to implement Vagrant as a DevOps tool, to master the creation and configuration of virtual development environments with an easy-to-use workflow, and focus on automation.}
}
@inproceedings{10.1145/2652524.2652598,
author = {Erich, Floris and Amrit, Chintan and Daneva, Maya},
title = {Cooperation between Information System Development and Operations: A Literature Review},
year = {2014},
isbn = {9781450327749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2652524.2652598},
doi = {10.1145/2652524.2652598},
abstract = {Software development can profit from improvements in the deployment and maintenance phases. DevOps improves these phases through a collection of principles and practices, centered around close collaboration between Development and Operations personnel. Both sides have paid little attention to issues faced by each other. Yet knowledge sharing is invaluable. Development personnel can for example make software more robust by implementing scalability and performance features desired by operations personnel.},
booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {69},
numpages = {1},
keywords = {services, measurement, DevOps, service oriented architecture, culture, development, cloud computing, sharing, continuous delivery, operations, automation},
location = {Torino, Italy},
series = {ESEM '14}
}
@inproceedings{10.1145/3230833.3233255,
author = {Guija, Daniel and Siddiqui, Muhammad Shuaib},
title = {Identity and Access Control for Micro-Services Based 5G NFV Platforms},
year = {2018},
isbn = {9781450364485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3230833.3233255},
doi = {10.1145/3230833.3233255},
abstract = {The intrinsic use of SDN/NFV technologies in 5G infrastructures promise to enable the flexibility and programmability of networks to ensure lower cost of network and service provisioning and operation, however it brings new challenges and requirements due to new architectural changes. In terms of security, authentication and authorization functions need to evolve towards the new and emerging 5G virtualization platforms in order to meet the requirements of service providers and infrastructure operators. Over the years, a lot of authentication techniques have been used. Now, a wide range of options arise allowing to extend existing authentication and authorization mechanisms.This paper focuses on proposing and showcasing a 5G platform oriented solution among different approaches to integrate authentication and authorization functionalities, an adapted secure and stateless mechanism, providing identity and permissions management to handle not only users, but also system micro-services, in a network functions virtualization management and orchestration (NFV MANO) system, oriented to deploy virtualized services. The presented solution uses the NFV-based SONATA Service Platform which offers capabilities for a continuous integration and delivery DevOps methodology that allow high levels of programmability and flexibility to manage the entire life cycle of Virtual Network Functions, and enables the perfect scenario to showcase different approaches for authentication and authorization mechanisms for users and micro-services in a 5G platform.},
booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
articleno = {46},
numpages = {10},
keywords = {micro-services, Authorization, 5G, JSON Web Token, identity, network services, Authentication, DevOps, NFV MANO, virtual network functions, Keycloak},
location = {Hamburg, Germany},
series = {ARES 2018}
}
@inproceedings{10.1145/3053600.3053625,
author = {Di Marco, Antinisca},
title = {DevOps and WSN App: A Bio-Inspired Paradigm},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053625},
doi = {10.1145/3053600.3053625},
abstract = {Wireless Sensor Networks (WSN) are nowadays applied to a wide set of domains (e.g., security, health). WSN are networks of spatially distributed, radio-communicating, battery-powered, autonomous sensor nodes. WSN are characterized by scarcity of resources, hence an application running on them should carefully manage its resources. Applications running on WSN (namely, WSN App) and using sensors, must be adaptable to modify their behavior at run-time to respond to changes in the environment they run, to changes of the users' requirements or to changes occurring in the system itself.This talk will present a bio-inspired paradigm that mimics the cell lifecycle and uses the concept of membrane to define the border of a system adaptation. The adaptation is specifies by PROTEUS a language for reconfiguration plans. The talk will show the application of such a paradigm to WSN domain through the MAIA framework (FraMework for Adaptaptive wIreless sensor network Applications). MAIA provides components i) to model and analysis quality attributes (e.g., timing, performance and energy consumption) of AGILLA agents, ii) to generate AGILLA code from the provided models and to dynamically delivery the generated code on WSN. MAIA supports DevOps process for WSN App.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {157–158},
numpages = {2},
keywords = {wireless sensor network, adaptation, devops, quality attribute},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}
@book{10.5555/3137480,
author = {Shirinkin, Kirill},
title = {Getting Started with Terraform},
year = {2017},
isbn = {1786465108},
publisher = {Packt Publishing},
abstract = {Key Features An up-to-date and comprehensive resource on Terraform that lets you quickly and efficiently launch your infrastructureLearn how to implement your infrastructure as code and make secure, effective changes to your infrastructure Learn to build multi-cloud fault-tolerant systems and simplify the management and orchestration of even the largest scale and most complex cloud infrastructures Book Description Terraform is a tool used to efficiently build, configure, and improve production infrastructure. It can manage existing infrastructure as well as create custom in-house solutions. This book shows you when and how to implement infrastructure as a code practices with Terraform. It covers everything necessary to set up complete management of infrastructure with Terraform, starting with the basics of using providers and resources. This book is a comprehensive guide that begins with very small infrastructure templates and takes you all the way to managing complex systems, all using concrete examples that evolve over the course of the book. It finishes with the complete workflow of managing a production infrastructure as code this is achieved with the help of version control and continuous integration. At the end of this book, you will be familiar with advanced techniques such as multi-provider support and multiple remote modules. What you will learn Understand what Infrastructure as Code (IaC) means and why it matters Install, configure, and deploy Terraform Take full control of your infrastructure in the form of code Manage complete complete infrastructure, starting with a single server and scaling beyond any limits Discover a great set of production-ready practices to manage infrastructure Set up CI/CD pipelines to test and deliver Terraform stacks Construct templates to simplify more complex provisioning tasks About the Author Kirill Shirinkin is an IT consultant who focuses on Cloud technologies and DevOps practices. He has worked in companies of different sizes and areas, from an online language learning leader to a major IT provider for the global travel industry and one of the largest management consultancies. He is also a cofounder of online mentorship platform mkdev.me, where he leads a team and teaches his students all about DevOps.}
}
@inbook{10.1145/3474624.3477071,
author = {Ferino, Samuel and Fernandes, Marcelo and Fernandes, Anny and Kulesza, Uir\'{a} and Aranha, Eduardo and Treude, Christoph},
title = {Analyzing DevOps Teaching Strategies: An Initial Study},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3477071},
abstract = {DevOps refers to a set of practices that integrate software development and operations with the primary aim to enable the continuous delivery of high-quality software. DevOps has also promoted several challenges to software engineering teaching. In this paper, we present a preliminary study that analyzes existing teaching strategies reported in the literature. Our findings indicate a set of approaches highlighting the use of environments to support teaching. Our work also investigates how these environments can contribute to address existing challenges and recommendations of DevOps teaching.},
booktitle = {Brazilian Symposium on Software Engineering},
pages = {180–185},
numpages = {6}
}
@inproceedings{10.1145/3053600.3053631,
author = {Guerriero, Michele and Tamburri, Damian A. and Ridene, Youssef and Marconi, Francesco and Bersani, Marcello M. and Artac, Matej},
title = {Towards DevOps for Privacy-by-Design in Data-Intensive Applications: A Research Roadmap},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053631},
doi = {10.1145/3053600.3053631},
abstract = {With the onset of Big Data and Data-Intensive Applications (DIAs) exploiting such big data, the problem of offering privacy guarantees to data owners becomes crucial, even more so with the emergence of DevOps development strategies where speed is paramount. This paper outlines this complex scenario and the challenges therein. On one hand, we outline a tool prototype that addresses the key challenge we found in industry, more specifically, assisting the process of continuous DIA architecting for the purpose of offering privacy-by-design guarantees. On the other hand we define a research roadmap in pursuit of a more correct and complete solution for ensured privacy-by-design in the context of Big Data DevOps.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {139–144},
numpages = {6},
keywords = {big data, trace-checking, privacy-by-design, devops},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}
@book{10.5555/3306648,
author = {Agarwal, Aditi},
title = {The Basics Of Kanban: A Popular Lean Framework},
year = {2018},
isbn = {1729181430},
publisher = {Independently published},
abstract = {Do you feel overwhelmed with multiple things that need your attention? Do you feel like youre always switching from one task to another, struggling to focus on any one thing for long enough to make progress? Do you feel that you work all day, but cant get anything to complete? Do you feel that you are not as productive as you would like to be? Does your team have enough visibility on work items that each member is working on? Does your team struggle to track external team dependencies? Does your team stay focused and motivated? Does your team meet its commitments? Kanban is a popular Lean framework and a workflow visualization approach to managing any professional or personal work in an effective and efficient manner. This book is written to provide you with a complete reference guide on Kanban to assist you on your journey towards success. Implementing Kanban is least disruptive. You can apply Kanban to your existing processes, embracing continuous improvement, improved results, optimized efficiency, and minimized waste. What will you learn with this book?-What Is Kanban?-Why Kanban?-Kanban Principles and Practices-Kanban Board-WIP Limits-Cumulative Flow Diagram-Lead Time Chart-Cycle Time Chart-Flow Efficiency-Blockers Clustering-Throughput or Velocity-Scrum Vs Kanban-Scrumban-DevOps and Kanban-Kaizen and Kanban-Kanban Tools-Practical Examples-Sample Kanban Boards Who Should Read This Book? Since Kanban can be applied at both work and your personal life, anyone can read this book. Here are a few roles and scenarios that will most likely benefit from this book.-Project Managers-Business Analysts-Scrum Masters-Product Managers-Product Owners-Engineers-Test Managers-Business Managers-Technology Leaders-Subject Matter Experts-System Administrators-Operations or Support teams-Sales and Marketing teams-Students seeking an IT job-A product development team with regular intake requests-Anyone who is looking to manage their personal or professional work-Anyone who is looking to adopt Kanban-Anyone who needs to understand when and when not to use Kanban-Anyone who wants to understand the differences between Kanban and Scrum-Anyone who needs to learn Kanban to expand ones career opportunities-Anyone who needs a simple and concise reference book on Kanban Grab your copy today. Learn how to effectively manage your personal and professional work with Kanban.}
}
@book{10.5555/3137491,
author = {Hamburger, Valentin},
title = {Building VMware Software-Defined Data Centers},
year = {2017},
isbn = {1786464373},
publisher = {Packt Publishing},
abstract = {Key FeaturesLearn how you can automate your data center operations and deploy and manage applications and services across your public, private, and hybrid infrastructure in minutesDrive great business results with cost-effective solutions without compromising on ease, security, and controlsTransform your business processes and operations in a way that delivers any application, anywhere, with complete peace of mindBook DescriptionVMware offers the industry-leading software-defined data center (SDDC) architecture that combines compute, storage, networking, and management offerings into a single unified platform. This book uses the most up-to-date, cutting-edge VMware products to help you deliver a complete unified hybrid cloud experience within your infrastructure. It will help you build a unified hybrid cloud based on SDDC architecture and practices to deliver a fully virtualized infrastructure with cost-effective IT outcomes. In the process, you will use some of the most advanced VMware products such as VSphere, VCloud, and NSX. You will learn how to use vSphere virtualization in a software-defined approach, which will help you to achieve a fully-virtualized infrastructure and to extend this infrastructure for compute, network, and storage-related data center services. You will also learn how to use EVO:RAIL. Next, you will see how to provision applications and IT services on private clouds or IaaS with seamless accessibility and mobility across the hybrid environment. This book will ensure you develop an SDDC approach for your datacenter that fulfills your organization's needs and tremendously boosts your agility and flexibility. It will also teach you how to draft, design, and deploy toolsets and software to automate your datacenter and speed up IT delivery to meet your lines of businesses demands. At the end, you will build unified hybrid clouds that dramatically boost your IT outcomes. What you will learnUnderstand and optimize end-to-end processes in your data centerTranslate IT processes and business needs into a technical designApply and create vRO workflow automation functionalities to servicesDeploy NSX in a virtual environmentTechnically accomplish DevOps offeringsSet up and use vROPs to master the SDDC resource demandsTroubleshoot all the components of SDDCAbout the AuthorValentin Hamburger was working at VMware for more than seven years. In his former role, he was a lead consulting architect and took care of the delivery and architecture of cloud projects in central EMEA. In his current role, he is EMEA solutions lead for VMware at Hitachi Data Systems (HDS). Furthermore he works as an advisor with HDS engineering on the Hitachi Enterprise Cloud, which is based on VMware vRealize technology. He holds many industry certifications in various areas such as VMware, Linux, and IBM Power compute environments. He serves as a partner and trusted advisor to HDS customers primarily in EMEA. His main responsibilities are ensuring that HDS's future innovations align with essential customer needs and translating customer challenges to opportunities focused on virtualization topics. Valentin enjoys sharing his knowledge as a speaker at national and international conferences such as VMworld.}
}
@book{10.5555/3153470,
author = {Sanchez, Carlos Perez and Vilarino, Pablo Solar},
title = {PHP Microservices},
year = {2017},
isbn = {1787125378},
publisher = {Packt Publishing},
abstract = {Transit from monolithic architectures to highly available, scalable, and fault-tolerant microservices About This BookBuild your own applications based on event-driven microservices and set them up on a production server. Successfully transform any monolithic application into a microservice. Monitor the health of your application, prevent downtime, and reduce costs. Who This Book Is For PHP developers who want to build scalable, highly available, and secure applications will find this book useful. No knowledge of microservices is assumed. What You Will LearnSet up a development environment using the right strategies and tools. Learn about application design and structure to start implementing your application. Transform a monolithic application into microservices. Explore the best way to start implementing your application using testing. Understand how to monitor your microservices, handle errors, and debug the application. Deploy your finished application into a production environment and learn how to solve common problems.Know how to scale your application based on microservices once it is upand-running. In DetailThe world is moving away from bulky, unreliable, and high-maintenance PHP applications, to small, easy-to-maintain and highly available microservices and the pressing need is for PHP developers to understand the criticalities in building effective microservices that scale at large. This book will be a reliable resource, and one that will help you to develop your skills and teach you techniques for building reliable microservices in PHP. The book begins with an introduction to the world of microservices, and quickly shows you how to set up a development environment and build a basic platform using Docker and Vagrant. You will then get into the different design aspects to be considered while building microservices in your favorite framework and you will explore topics such as testing, securing, and deploying microservices. You will also understand how to migrate a monolithic application to the microservice architecture while keeping scalability and best practices in mind. Furthermore you will get into a few important DevOps techniques that will help you progress on to more complex domains such as native cloud development, as well as some interesting design patterns. By the end of this book you will be able to develop applications based on microservices in an organized and efficient way. You will also gain the knowledge to transform any monolithic applications into microservices. Style and approach Filled with code that you can start typing straightaway, this book will take you through building, testing, securing, and deploying microservices in the most practical way possible. The focus of the book is more inclined towards showing you how it's done, rather than with what to do, although you will get a good idea of those tools most widely used to build microservices.}
}
@book{10.5555/3153688,
author = {Rajani, Renu},
title = {Testing Practitioner Handbook},
year = {2017},
isbn = {178829954X},
publisher = {Packt Publishing},
abstract = {Gain insights into the latest technology and business trends within testing domains About This Book This book covers the latest trends that every Testing and QA professional should keep up-to-date with given the advancements in digital technologies. Master cutting-edge testing techniques for emerging areas such as IOT, Machine Learning, Cognitive. Best practices for Testing and Quality Assurance within several industry domains. Who This Book Is For This book is targeted at those working in the QA and Testing areas. The book does not cover testing basics, which QA professional are already familiar withfor example, writing a test plan or test case, and so on. What You Will Learn Understand the TCOE model, managed services, the structure of testing in Agile/DevOps engagements, factory models, and crowdsourcing Implement testing processes, practices, and automation tools in the Agile/DevOps life cycle Adapt to current technologies in social media, mobile, analytics and the Cloud Leverage cognitive intelligence/machine-learning, robotics, and the Internet of Things in testingHow key industries/domains (consumer products and retail, energy and utilities, healthcare, telecom, and automotive) adapt to digital transformation Future directions for the QA industry, consulting careers, testing profession, and professionalsIn Detail The book is based on the author's experience in leading and transforming large test engagements and architecting solutions for customer testing requirements/bids/problem areas. It targets the testing practitioner population and provides them with a single go-to place to find perspectives, practices, trends, tools, and solutions to test applications as they face the evolving digital world. This book is divided into five parts where each part explores different aspects of testing in the real world. The first module explains the various testing engagement models. You will then learn how to efficiently test code in different life cycles. The book discusses the different aspects of Quality Analysis consideration while testing social media, mobile, analytics, and the Cloud. In the last module, you will learn about futuristic technologies to test software. By the end of the book, you will understand the latest business and IT trends in digital transformation and learn the best practices to adopt for business assurance. Style and approach This book is a compilation of the latest business and IT trends in digital transformation &amp; Tools and Best Practices that QA professionals need to adopt for business assurance.}
}
@inproceedings{10.1145/3322385.3322400,
author = {Wiedemann, Anna and Wiesche, Manuel and Krcmar, Helmut},
title = {Integrating Development and Operations in Cross-Functional Teams - Toward a DevOps Competency Model},
year = {2019},
isbn = {9781450360883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3322385.3322400},
doi = {10.1145/3322385.3322400},
abstract = {The integration of cross-functional teams for new product development is still an elusive aim. Cross-functional information technology (IT) teams are used to provide new initiatives in fast-changing and challenging environments. Moreover, concepts such as Development and Operations (DevOps) appear in practice and bring software development and operations tasks in one team. Organizations are currently searching for necessary, suitable competencies for setting up high collaborative cross-functional teams that manage the tasks of the software delivery lifecycle. Therefore, in this paper, employing a multi-perspective research approach, we conducted a workshop and a multiple-case study. Hence, this paper presents a competency model for enabling a high level of collaboration within a team and explains how these competencies are implemented in IT functions. Additionally, we identified six competencies and two major challenges associated with DevOps team setups.},
booktitle = {Proceedings of the 2019 on Computers and People Research Conference},
pages = {14–19},
numpages = {6},
keywords = {devops, competency model, organizational transformation, multiple-case study},
location = {Nashville, TN, USA},
series = {SIGMIS-CPR '19}
}
@book{10.5555/3169316,
author = {Leszko, Rafal},
title = {Continuous Delivery with Docker and Jenkins: Delivering Software at Scale},
year = {2017},
isbn = {1787125238},
publisher = {Packt Publishing},
abstract = {Key Features Build reliable and secure applications using Docker containers. Create a complete Continuous Delivery pipeline using Docker, Jenkins, and Ansible. Deliver your applications directly on the Docker Swarm cluster. Create more complex solutions using multi-containers and database migrations. Book Description The combination of Docker and Jenkins improves your Continuous Delivery pipeline using fewer resources. It also helps you scale up your builds, automate tasks and speed up Jenkins performance with the benefits of Docker containerization. This book will explain the advantages of combining Jenkins and Docker to improve the continuous integration and delivery process of app development. It will start with setting up a Docker server and configuring Jenkins on it. It will then provide steps to build applications on Docker files and integrate them with Jenkins using continuous delivery processes such as continuous integration, automated acceptance testing, and configuration management. Moving on you will learn how to ensure quick application deployment with Docker containers along with scaling Jenkins using Docker Swarm. Next, you will get to know how to deploy applications using Docker images and testing them with Jenkins. By the end of the book, you will be enhancing the DevOps workflow by integrating the functionalities of Docker and Jenkins. What you will learnGet to grips with docker fundamentals and how to dockerize an application for the Continuous Delivery process Configure Jenkins and scale it using Docker-based agents Understand the principles and the technical aspects of a successful Continuous Delivery}
}
@book{10.5555/3006360,
author = {Davis, Jennifer and Daniels, Ryn},
title = {Effective DevOps: Building a Culture of Collaboration, Affinity, and Tooling at Scale},
year = {2016},
isbn = {1491926309},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Some companies think that adopting devops means bringing in specialists or a host of new tools. With this practical guide, youll learn why devops is a professional and cultural movement that calls for change from inside your organization. Authors Katherine Daniels and Jennifer Davis provide several approaches for improving collaboration within teams, creating affinity among teams, promoting efficient tool usage in your company, and scaling up what works throughout your organizations inflection points. Devops stresses iterative efforts to break down information silos, monitor relationships, and repair misunderstandings that arise between and within teams in your organization. By applying the actionable strategies in this book, you can make sustainable changes in your environment regardless of your level within your organization. Explore the foundations of devops and learn the four pillars of effective devopsEncourage collaboration to help individuals work together and build durable and long-lasting relationships Create affinity among teams while balancing differing goals or metrics Accelerate cultural direction by selecting tools and workflows that complement your organization Troubleshoot common problems and misunderstandings that can arise throughout the organizational lifecycleLearn from case studies from organizations and individuals to help inform your own devops journey}
}
@inproceedings{10.1145/3512716.3512718,
author = {Lazuardi, Muthia and Raharjo, Teguh and Hardian, Bob and Simanungkalit, Tiarma},
title = {Perceived Benefits of DevOps Implementation in Organization: A Systematic Literature Review},
year = {2021},
isbn = {9781450384315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512716.3512718},
doi = {10.1145/3512716.3512718},
abstract = {Nowadays, organizations are competing to accelerate the process of transforming business needs or business ideas into software applications. DevOps emerges to enable the development and operation team to work collaboratively and has gained much attention from various organizations to improve their software delivery process. Therefore, this study aims to gain further knowledge from various case studies on the perceived benefits of implementing the DevOps approach in organizations. A systematic literature review was conducted to summarizes the benefits that organizations perceived in implementing DevOps into benefit category mapping. From 446 potential related papers, 10 papers were selected by full-text review. This research found that there are nine benefit categories. The most benefit that organizations have perceived is frequent software deployment improvement, then followed by team productivity improvement and software quality improvement. With this DevOps benefit categories, it is hoped that researchers and practitioners can have an easy-to-understand understanding of the benefits that will be obtained if their organization wants to implement DevOps as their software development method.},
booktitle = {2021 10th International Conference on Software and Information Engineering (ICSIE)},
pages = {10–16},
numpages = {7},
keywords = {DevOps, DevOps implementation in organization, DevOps benefits},
location = {Cairo, Egypt},
series = {ICSIE 2021}
}
@book{10.5555/3265463,
author = {Laster, Brent},
title = {Jenkins 2: Up and Running Evolve Your Deployment Pipeline for Next Generation Automation},
year = {2018},
isbn = {1491979593},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Design, implement, and execute continuous delivery pipelines with a level of flexibility, control, and ease of maintenance that was not possible with Jenkins before. With this practical book, build administrators, developers, testers, and other professionals will learn how the features in Jenkins 2 let you define pipelines as code, leverage integration with other key technologies, and create automated, reliable pipelines to simplify and accelerate your DevOps environments. Author Brent Laster shows you how Jenkins 2 is significantly different from the more traditional, web-only versions of this popular open source automation platform. If youre familiar with Jenkins and want to take advantage of the new technologies to transform your legacy pipelines or build new modern, automated continuous delivery environments, this is your book. Create continuous delivery pipelines as code with the Jenkins domain-specific language Get practical guidance on how to migrate existing jobs and pipelines Harness best practices and new methods for controlling access and security Explore the structure, implementation, and use of shared pipeline libraries Learn the differences between declarative syntax and scripted syntax Leverage new and existing project types in Jenkins Understand and use the new Blue Ocean graphical interface Take advantage of the capabilities of the underlying OS in your pipeline Integrate analysis tools, artifact management, and containers}
}
@inproceedings{10.5555/2907890.2907895,
author = {Sebby, Brian},
title = {Devops is Improv: How Improv Made Me a Better Sysadmin},
year = {2015},
isbn = {9781931971270},
publisher = {USENIX Association},
address = {USA},
abstract = {With the rise of DevOps as a prevailing software development model, organizations are finding that teamwork and communication are tools that are vital to the overall success of their mission. Three years ago, I took my first improv class, and in addition to helping me be more comfortable with public speaking, I have found that many of the techniques that help an improv team succeed on stage are directly applicable to helping a DevOps team succeed.},
booktitle = {Proceedings of the 29th Usenix Conference on Large Installation System Administration},
pages = {49},
numpages = {1},
location = {Washington, D.C.},
series = {LISA'15}
}
@inproceedings{10.1109/ISSRE.2015.7381796,
author = {Farshchi, Mostafa and Schneider, Jean-Guy and Weber, Ingo and Grundy, John},
title = {Experience Report: Anomaly Detection of Cloud Application Operations Using Log and Cloud Metric Correlation Analysis},
year = {2015},
isbn = {9781509004065},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2015.7381796},
doi = {10.1109/ISSRE.2015.7381796},
abstract = {Failure of application operations is one of the main causes of system-wide outages in cloud environments. This particularly applies to DevOps operations, such as backup, redeployment, upgrade, customized scaling, and migration that are exposed to frequent interference from other concurrent operations, configuration changes, and resources failure. However, current practices fail to provide a reliable assurance of correct execution of these kinds of operations. In this paper, we present an approach to address this problem that adopts a regression-based analysis technique to find the correlation between an operation's activity logs and the operation activity's effect on cloud resources. The correlation model is then used to derive assertion specifications, which can be used for runtime verification of running operations and their impact on resources. We evaluated our proposed approach on Amazon EC2 with 22 rounds of rolling upgrade operations while other types of operations were running and random faults were injected. Our experiment shows that our approach successfully managed to raise alarms for 115 random injected faults, with a precision of 92.3%.},
booktitle = {Proceedings of the 2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)},
pages = {24–34},
numpages = {11},
series = {ISSRE '15}
}
@inproceedings{10.1145/3375555.3384936,
author = {Avritzer, Alberto},
title = {Automated Scalability Assessment in DevOps Environments},
year = {2020},
isbn = {9781450371094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375555.3384936},
doi = {10.1145/3375555.3384936},
abstract = {In this extended abstract, we provide an outline of the presentation planned for WOSP-C 2020. The goal of the presentation is to provide an overview of the challenges and approaches for automated scalability assessment in the context of DevOps and microservices. The focus of this presentation is on approaches that employ automated identification of performance problems because these approaches can leverage performance anti-pattern[5] detection technology. In addition, we envision extending the approach to recommend component refactoring. In our previous work[1,2] we have designed a methodology and associated tool support for the automated scalability assessment of micro-service architectures, which included the automation of all the steps required for scalability assessment. The presentation starts with an introduction to dependability, operational Profile Data, and DevOps. Specifically, we provide an overview of the state of the art in continuous performance monitoring technologies[4] that are used for obtaining operational profile data using APM tools. We then present an overview of selected approaches for production and performance testing based on the application monitoring tool (PPTAM) as introduced in [1,2]. The presentation concludes by outlining a vision for automated performance anti-pattern[5] detection. Specifically, we present the approach introduced for automated anti-pattern detection based on load testing results and profiling introduced in[6] and provide recommendations for future research.},
booktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},
pages = {10},
numpages = {1},
location = {Edmonton AB, Canada},
series = {ICPE '20}
}
@inproceedings{10.1145/2945408.2945410,
author = {Jones, Stephen and Noppen, Joost and Lettice, Fiona},
title = {Management Challenges for DevOps Adoption within UK SMEs},
year = {2016},
isbn = {9781450344111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2945408.2945410},
doi = {10.1145/2945408.2945410},
abstract = {The DevOps phenomenon is gathering pace as more UK organisations seek to leverage the benefits it can potentially bring to software engineering functions. However substantial organisational change is inherent to adopting DevOps, especially where there are prior and established methods. As part of a wider piece of doctoral research investigating the management challenges of DevOps adoption, we present early findings of a six month qualitative diary study following the adoption of DevOps within a UK based SME with over 200 employees. We find that within our case study organisation, the DevOps approach is being adopted for the development of a new system used both internally and by customers. DevOps, conceptually, appears to be generally well regarded, but in reality is proving difficult to fully adopt. This difficulty is down to a combination of necessity in maintaining a legacy system, lack of senior management buy-in, managerial structure and resistance. Additionally, we are finding evidence of job crafting, especially with the software developers. Taken together, we put forward the argument that DevOps is an interdisciplinary topic which would greatly benefit from further management and potentially psychology oriented research attention.},
booktitle = {Proceedings of the 2nd International Workshop on Quality-Aware DevOps},
pages = {7–11},
numpages = {5},
keywords = {DevOps, United Kingdom, Management Challenges, Case Study, SME},
location = {Saarbr\"{u}cken, Germany},
series = {QUDOS 2016}
}
@book{10.5555/3239725,
author = {Kaewkasi, Chanwit},
title = {Docker for Serverless Applications: Containerize and Orchestrate Functions Using OpenFaas, OpenWhisk, and Fn},
year = {2018},
isbn = {1788835263},
publisher = {Packt Publishing},
abstract = {Build applications and infrastructures that leverage Function-as-a-Service and Docker Key Features Implement containerization in Serverless/FaaS environments Utilize Docker as a functional unit of work for Serverless/FaaS platforms Use Docker as a portable infrastructure for Serverless Applications Book Description Serverless applications have gained a lot of popularity among developers and are currently the buzzwords in the tech market. Docker and serverless are two terms that go hand-in-hand. This book will start by explaining serverless and Function-as-a-Service (FaaS) concepts, and why they are important. Then, it will introduce the concepts of containerization and how Docker fits into the Serverless ideology. It will explore the architectures and components of three major Docker-based FaaS platforms, how to deploy and how to use their CLI. Then, this book will discuss how to set up and operate a production-grade Docker cluster. We will cover all concepts of FaaS frameworks with practical use cases, followed by deploying and orchestrating these serverless systems using Docker. Finally, we will also explore advanced topics and prototypes for FaaS architectures in the last chapter. By the end of this book, you will be in a position to build and deploy your own FaaS platform using Docker. What you will learn Learn what Serverless and FaaS applications areGet acquainted with the architectures of three major serverless systems Explore how Docker technologies can help develop Serverless applications Create and maintain FaaS infrastructures Set up Docker infrastructures to serve as on-premises FaaS infrastructures Define functions for Serverless applications with Docker containers Who This Book Is ForIf you are a Developer, a Docker Engineer, a DevOps Engineer, or any stakeholder interested in learning the use of Docker on Serverless environments then this book is for you.}
}
@article{10.1145/3106164,
author = {Jiang, He and Chen, Xin and He, Tieke and Chen, Zhenyu and Li, Xiaochen},
title = {Fuzzy Clustering of Crowdsourced Test Reports for Apps},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3106164},
doi = {10.1145/3106164},
abstract = {DevOps is a new approach to drive a seamless Application (App) cycle from development to delivery. As a critical part to promote the successful implementation of DevOps, testing can significantly improve team productivity and reliably deliver user experience. However, it is difficult to use traditional testing to cover diverse mobile phones, network environments, operating systems, and so on. Hence, many large companies crowdsource their App testing tasks to workers from open platforms. In crowdsourced testing, test reports submitted by workers may be highly redundant, and their quality may vary sharply. Meanwhile, multi-bug test reports may be submitted, and their root causes are hard to diagnose. Hence, it is a time-consuming and tedious task for developers to manually inspect these test reports. To help developers address the above challenges, we issue the new problem of Fuzzy Clustering Test Reports (FULTER). Aiming to resolve FULTER, a series of barriers need to be overcome. In this study, we propose a new framework named Test Report Fuzzy Clustering Framework (TERFUR) by aggregating redundant and multi-bug test reports into clusters to reduce the number of inspected test reports. First, we construct a filter to remove invalid test reports to break through the invalid barrier. Then, a preprocessor is built to enhance the descriptions of short test reports to break through the uneven barrier. Last, a two-phase merging algorithm is proposed to partition redundant and multi-bug test reports into clusters that can break through the multi-bug barrier. Experimental results over 1,728 test reports from five industrial Apps show that TERFUR can cluster test reports by up to 78.15% in terms of AverageP, 78.41% in terms of AverageR, and 75.82% in terms of AverageF1 and outperform comparative methods by up to 31.69%, 33.06%, and 24.55%, respectively. In addition, the effectiveness of TERFUR is validated in prioritizing test reports for manual inspection.},
journal = {ACM Trans. Internet Technol.},
month = {feb},
articleno = {18},
numpages = {28},
keywords = {test report, fuzzy clustering, duplicate detection, Crowdsourced testing, unsupervised method}
}
@book{10.5555/3240104,
author = {Odika, Chiyo},
title = {Microsoft Operations Management Suite Cookbook: Enhance Your Management Experience and Capabilities across Your Cloud and on-Premises Environments with Microsoft OMS},
year = {2018},
isbn = {178646909X},
publisher = {Packt Publishing},
abstract = {Manage on-premises and cloud IT assets from one console Key Features Empower yourself with practical recipes to collect and analyze operational insights on Windows and Linux servers in your on premises datacenters and in any public cloud environments such as Azure and AWS. Build capabilities through practical tasks and techniques to collect and analyze machine dataAddress business challenges and discover means to accommodate workloads and instances in a low cost mannerBook Description Microsoft Operations Management Suite Cookbook begins with an overview of how to hit the ground running with OMS insights and analytics. Next, you will learn to search and analyze data to retrieve actionable insights, review alert generation from the analyzed data, and use basic and advanced Log search queries in Azure Log Analytics. Following this, you will explore some other management solutions that provide functionality related to workload assessment, application dependency mapping, automation and configuration management, and security and compliance. You will also become well versed with the data protection and recovery functionalities of OMS Protection and Recovery, and learn how to use Azure Automation components and features in OMS. Finally you will learn how to evaluate key considerations for using the Security and Audit solution, and working with Security and Compliance in OMS. By the end of the book, you will be able to configure and utilize solution offerings in OMS, understand OMS workflows, how to unlock insights, integrate capabilities into new or existing workflows, manage configurations, and automate tasks and processes. What you will learn Understand the important architectural considerations and strategies for OMS Use advanced search query commands and strategies to derive insights from indexed data Make use of alerting in OMS such as alert actions, and available options for the entire lifecycle of the alertDiscover some practical tips for monitoring Azure container service containers and clusters using OMS Review and use the backup options available through the Azure backup service, as well as data recovery options available through Azure Site Recovery (ASR) Understand how to advance important DevOps concepts within your IT organization Learn how to manage configurations and automate process Who This Book Is ForThis book is written for the IT professional and general reader who is interested in technology themes such as DevOps, Big Data Analytics, and digital transformation concepts. Azure and other cloud platform administrators, cloud professionals, and technology analysts who would like to solve everyday problems quickly and efficiently with hybrid management tools available in the Microsoft product ecosystem will derive much value from this book. Prior experience with OMS 2012 would be helpful.}
}
@inproceedings{10.1145/2889160.2889207,
author = {Staples, Mark and Zhu, Liming and Grundy, John},
title = {Continuous Validation for Data Analytics Systems},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889207},
doi = {10.1145/2889160.2889207},
abstract = {From a future history of 2025: Continuous development is common for build/test (continuous integration) and operations (devOps). This trend continues through the lifecycle, into what we call 'devUsage': continuous usage validation. In addition to ensuring systems meet user needs, organisations continuously validate their legal and ethical use. The rise of end-user programming and multi-sided platforms exacerbate validation challenges. A separate trend is the specialisation of software engineering for technical domains, including data analytics. This domain has specific validation challenges. We must validate the accuracy of statistical models, but also whether they have illegal or unethical biases. Usage needs addressed by machine learning are sometimes not specifiable in the traditional sense, and statistical models are often 'black boxes'. We describe future research to investigate solutions to these devUsage challenges for data analytics systems. We will adapt risk management and governance frameworks previously used for software product qualities, use social network communities for input from aligned stakeholder groups, and perform cross-validation using autonomic experimentation, cyber-physical data streams, and online discursive feedback.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {769–772},
numpages = {4},
keywords = {governance, data analytics, software validation, machine learning, devOps, continuous development, ethics},
location = {Austin, Texas},
series = {ICSE '16}
}
@article{10.1109/MS.2016.86,
author = {Woods, Eoin},
title = {Operational: The Forgotten Architectural View},
year = {2016},
issue_date = {May 2016},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {33},
number = {3},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2016.86},
doi = {10.1109/MS.2016.86},
abstract = {The emerging DevOps movement emphasizes development and operations staff working together as early as possible--sharing tools, processes, and practices that smooth the production path. This article is part of a theme issue on DevOps.},
journal = {IEEE Softw.},
month = {may},
pages = {20–23},
numpages = {4}
}
@inproceedings{10.1007/978-3-030-33702-5_3,
author = {Niedermaier, Sina and Koetter, Falko and Freymann, Andreas and Wagner, Stefan},
title = {On Observability and Monitoring of Distributed Systems – An Industry Interview Study},
year = {2019},
isbn = {978-3-030-33701-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33702-5_3},
doi = {10.1007/978-3-030-33702-5_3},
abstract = {Business success of companies heavily depends on the availability and performance of their client applications. Due to modern development paradigms such as DevOps and microservice architectural styles, applications are decoupled into services with complex interactions and dependencies. Although these paradigms enable individual development cycles with reduced delivery times, they cause several challenges to manage the services in distributed systems. One major challenge is to observe and monitor such distributed systems. This paper provides a qualitative study to understand the challenges and good practices in the field of observability and monitoring of distributed systems. In 28 semi-structured interviews with software professionals we discovered increasing complexity and dynamics in that field. Especially observability becomes an essential prerequisite to ensure stable services and further development of client applications. However, the participants mentioned a discrepancy in the awareness regarding the importance of the topic, both from the management as well as from the developer perspective. Besides technical challenges, we identified a strong need for an organizational concept including strategy, roles and responsibilities. Our results support practitioners in developing and implementing systematic observability and monitoring for distributed systems.},
booktitle = {Service-Oriented Computing: 17th International Conference, ICSOC 2019, Toulouse, France, October 28–31, 2019, Proceedings},
pages = {36–52},
numpages = {17},
keywords = {Monitoring, Cloud, Distributed systems, Industry, Observability},
location = {Toulouse, France}
}
@book{10.5555/2564816,
author = {Carlson, Lucas},
title = {Programming for PaaS},
year = {2013},
isbn = {1449334903},
publisher = {O'Reilly Media, Inc.},
abstract = {Platform-as-a-Service (PaaS) is gaining serious traction among web and mobile developers, but as new PaaS providers emerge and existing vendors upgrade their features, its hard to keep track of what PaaS has to offer. This thorough introduction takes you through the PaaS model from a developers point of view, and breaks down the types of services that Google App Engine, Windows Azure, Heroku, Cloud Foundry, and others deliver. Whether youre an entrepreneur or part of a large enterprise development team, this book shows you how PaaS can help you focus on innovative applications, rather than spend your time worrying about technical operations.Track the clouds evolution from IaaS and DevOps to PaaS Learn how PaaS combines the simplicity of shared web hosting with the control of dedicated hosting Explore the benefits of both portable and non-portable PaaS options Apply best practices for moving legacy apps to PaaSand understand the challenges involved Write new applications for PaaS from scratch with RESTful meta-services Use PaaS to build mobile apps with backend services that scale Examine the core services that each major provider currently offers Learn the situations in which PaaS might not be advantageous}
}
@inproceedings{10.5555/3507788.3507833,
author = {M\"{u}ller, Hausi A. and Rivera, Luis F. and Jim\'{e}nez, Miguel and Villegas, Norha M. and Tamura, Gabriel and Akkiraju, Rama and Watts, Ian and Erpenbach, Eric},
title = {Proactive AIOps through Digital Twins},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The rise of advanced IT environments (IT ·Envs) that meet ever increasing user expectations on software quality necessitates innovative practices in the development and operation of software-intensive systems. DevOps teams find themselves searching for ways to deliver value by attacking operational challenges that tend to overwhelm human capabilities. Most of these challenges relate to the structural and behavioural complexities of modern IT·Envs. While the former concerns the orchestration of multiple technologies, the latter involves the exploitation of the huge data streams produced that are integral to DevOps activities. As automation, autonomy, and artificial intelligence technologies are maturing and permeating various activities in the software development lifecycle, opportunities arise from their integration with DevOps practices to improve risk mitigation, root cause analysis, problem resolution, and operational optimization in IT·Envs. This CASCON x EVOKE 2021 workshop discussed challenges and opportunities in developing proactive AIOps through digital twin technologies.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {275–276},
numpages = {2},
keywords = {cloud, fault prediction, IT operations, AI, digital twins, machine learning, AIOps, DevOps},
location = {Toronto, Canada},
series = {CASCON '21}
}
@book{10.5555/2815657,
author = {Kumar, Amrith and Shelley, Douglas},
title = {OpenStack Trove},
year = {2015},
isbn = {1484212223},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {OpenStack Trove is your step-by-step guide to set up and run a secure and scalable cloud Database as a Service (DBaaS) solution. The book shows you how to set up and configure the Trove DBaaS framework, use prepackaged or custom database implementations, and provision and operate a variety of databasesincluding MySQL, PostgreSQL, MongoDB, Cassandra, and Redisin development and production environments. Authors Amrith Kumar and Douglas Shelley, both active technical contributors to the Trove project, describe common deployment scenarios such as single-node database instances and walk you through the setup, configuration, and ongoing management of complex database topics like replication, clustering, and high availability. The book provides detailed descriptions of how Trove works and gives you an in-depth understanding of its architecture. It also shows you how to avoid common errors and debug and troubleshoot Trove installations, and perform common tasks such as: What youll learn Install and configure Trove Install preconfigured database technologies or guest images Launch database instances using Trove Perform common administrative tasks Resize and reconfigure database instances Take backups, and launch instances from existing backups Manage groups of database instances with configuration groups Debug and troubleshoot a Trove installation Set up replication and clustering Build custom guest images for use with Trove Who this book is for OpenStack Trove is targeted at a broad spectrum of readers, including software engineers seeking development agility with database-driven applications, devops engineers tasked with operating a database infrastructure with numerous databases, and data analysts looking to improve velocity by being able to quickly provision and release database capacity.}
}
@inproceedings{10.5555/2819009.2819119,
author = {Jayaram, K. R.},
title = {Towards Explicitly Elastic Programming Frameworks},
year = {2015},
publisher = {IEEE Press},
abstract = {It is a widely held view that software engineers should not be "burdened" with the responsibility of making their application components elastic; and that elasticity should be either be implicit and automatic in the programming framework; or that it is the responsibility of the cloud provider's operational staff (DevOps) to make distributed applications written for dedicated clusters elastic and execute them on cloud environments.In this paper, we argue the opposite -- we present a case for explicit elasticity, where software engineers are given the flexibility to explicitly engineer elasticity into their distributed applications. We present several scenarios where elasticity retrofitted to applications by DevOps is ineffective, present preliminary empirical evidence that explicit elasticity improves efficiency, and argue for elastic programming languages and frameworks to reduce programmer effort in engineering elastic distributed applications. We also present a bird's eye view of ongoing work on two explicitly elastic programming frameworks -- ElasticThrift (based on Apache Thrift [6]) and ElasticJava, an extension of Java with support for explicit elasticity.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {619–622},
numpages = {4},
location = {Florence, Italy},
series = {ICSE '15}
}
@book{10.5555/3384174,
author = {Campbell, Bradley},
title = {The Definitive Guide to AWS Infrastructure Automation: Craft Infrastructure-as-Code Solutions},
year = {2019},
isbn = {1484253973},
publisher = {Apress},
address = {USA},
edition = {1st},
abstract = {Discover the pillars of AWS infrastructure automation, starting with API-driven infrastructure concepts and its immediate benefits such as increased agility, automation of the infrastructure life cycle, and flexibility in experimenting with new architectures. With this base established, the book discusses infrastructure-as-code concepts in a general form, establishing principled outcomes such as security and reproducibility. Inescapably, we delve into how these concepts enable and underpin the DevOps movement. The Definitive Guide to AWS Infrastructure Automation begins by discussing services and tools that enable infrastructure-as-code solutions; first stop: AWS's CloudFormation service. You'll then cover the ever-expanding ecosystem of tooling emerging in this space, including CloudFormation wrappers such as Troposphere and orchestrators such as Sceptre, to completely independent third-party tools such as Terraform and Pulumi. As a bonus, you'll also work with AWS' newly-released CDK (Cloud Development Kit). You'll then look at how to implement modular, robust, and extensible solutions across a few examples -- in the process building out each solution with several different tools to compare and contrast the strengths and weaknesses of each. By the end of the journey, you will have gained a wide knowledge of both the AWS-provided and third-party ecosystem of infrastructure-as-code/provisioning tools, and the strengths and weaknesses of each. You'll possess a mental framework for how to craft an infrastructure-as-code solution to solve future problems based on examples discussed throughout the book. You'll also have a demonstrable understanding of the hands-on operation of each tool, situational appropriateness of each tool, and how to leverage the tool day to day. What You Will Learn Discover the technological and organizational benefits to infrastructure-as-code solutions; Examine the overall landscape of infrastructure-as-code tooling and solutions available to consumers of AWS services; See the strengths and weaknesses of these tools relative to one another as examined through hands-on implementation of several solutions; Gain hands-on experience, best practices, and tips and tricks learned through several years' real-world experience delivering solutions using these very tools in a wide variety of scenarios; Engineer solid solutions that leave room for new requirements and changes without requiring needless refactoring; Who This Book Is For DevOps engineers, cloud engineers and architects focused on the AWS ecosystem, software engineers/developers working within the AWS ecosystem, and engineering leaders looking for best practices.}
}
@article{10.1109/MNET.001.2100227,
author = {Yang, Lixuan and Rossi, Dario},
title = {Quality Monitoring and Assessment of Deployed Deep Learning Models for Network AIOps},
year = {2021},
issue_date = {November/December 2021},
publisher = {IEEE Press},
volume = {35},
number = {6},
issn = {0890-8044},
url = {https://doi.org/10.1109/MNET.001.2100227},
doi = {10.1109/MNET.001.2100227},
abstract = {Artificial intelligence (AI) has recently attracted a lot of attention, transitioning from research labs to a wide range of successful deployments in many fields, which is particularly true for deep learning (DL) techniques. Ultimately, DL models, being software artifacts, need to be regularly maintained and updated: AIOps is the logical extension of the DevOps software development practices to AI software applied to network operation and management. In the life cycle of a DL model deployment, it is important to assess the quality of deployed models, to detect “stale” models and prioritize their update. In this article, we cover the issue in the context of network management, proposing simple but effective techniques for quality assessment of individual inference, and for overall model quality tracking over multiple inferences, that we apply to two use cases, representative of the network management and image recognition fields.},
journal = {Netwrk. Mag. of Global Internetwkg.},
month = {nov},
pages = {84–90},
numpages = {7}
}
@article{10.1109/MS.2016.68,
author = {Ebert, Christof and Gallardo, Gorka and Hernantes, Josune and Serrano, Nicolas},
title = {DevOps},
year = {2016},
issue_date = {May 2016},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {33},
number = {3},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2016.68},
doi = {10.1109/MS.2016.68},
abstract = {Building on lean and agile practices, DevOps means end-to-end automation in software development and delivery. Hardly anybody will be able to approach it with a cookbook-style approach, but most developers will benefit from better connecting the previously isolated silos of development and operations. Many DevOps tools exist that can help them do this.},
journal = {IEEE Softw.},
month = {may},
pages = {94–100},
numpages = {7}
}
@proceedings{10.1145/2693182,
title = {LT '15: Proceedings of the 4th International Workshop on Large-Scale Testing},
year = {2015},
isbn = {9781450333375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the Fourth International Workshop on Large-Scale Testing (LT 2015), held in Austin, Texas, USA, on February 1st, 2015.Large-scale software systems must service thousands (e.g., enterprise applications) or even millions (e.g., e-commerce websites like Amazon) of concurrent users every day. Many field problems of these systems are due to their inability to scale to field workloads, rather than feature bugs. In addition to conventional functional testing (e.g., unit and integration testing), these systems must be tested with large volumes of concurrent requests (called the load) to ensure the quality of these systems. Large-scale testing includes all different objectives and strategies of testing large-scale software systems using load. Examples of large-scale testing include live upgrade testing, load testing, high availability testing, operational profile testing, performance testing, reliability testing, stability testing and stress testing.LT 2015 is a one-day workshop. The workshop participants consist of a mixture of academic and industrial researchers. A big emphasis of this workshop is to make the workshop interactive with many discussion slots assigned throughout the schedule. The workshop has two keynote talks: "Load Testing Elasticity and Performance Isolation in Shared Execution Environments" by Professor Samuel Kounev from University of W\"{u}rzburg and "Challenges, Benefits and Best Practices of Performance Focused DevOps" by Wolfgang Gottesheim from Compuware. In addition, the workshop also includes presentations from technical papers and industrial talks. Finally, there is a panel, which brings together industrial practitioners and academic researchers to discuss the opportunities and challenges associated with large-scale testing.We hope you enjoy the technical and social program. If you are not able to attend our workshop, we hope you will find the papers and talks in this workshop simulating. This workshop would not happen without the efforts of the program committee members who helped with timely and constructive reviews. In addition, we want to extend our gratitude to each author and presenter who submitted their work to the LT 2015 workshop.},
location = {Austin, Texas, USA}
}
@inproceedings{10.1145/3277593.3277642,
author = {Truong, Hong-Linh},
title = {Dynamic IoT Data, Protocol, and Middleware Interoperability with Resource Slice Concepts and Tools: Tutorial},
year = {2018},
isbn = {9781450365642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277593.3277642},
doi = {10.1145/3277593.3277642},
abstract = {Dealing with interoperability in the IoT domain is a complex matter that requires various techniques for tackling data, protocol and middleware interoperability. We cannot solve IoT interoperability problems by just developing (new) software components and (semantic) data models. In this tutorial, we will present interoperability techniques for complex IoT Cloud applications by leveraging dynamic solutions of provisioning and reconfiguring of IoT data processing pipelines, protocol bridges, IoT middleware and cloud services. First, the tutorial will examine cross-layered, cross-system inter-operability issues and present a DevOps IoT Interoperability approach for defining metadata, selecting resources and software artifacts, and provisioning and connecting resources to create various potential solutions for IoT Cloud interoperability using resource slice concepts. Second, the tutorial will present techniques for dynamically provisioning data pipelines, middleware services, protocol adapters and custom solutions to address cross-layered, cross-system interoperability for IoT Cloud applications. Such solutions also allow dynamic reconfiguration of resources to add/remove interoperability support. We will present the concepts and techniques with hands-on examples using our research tools rsiHub and IoTCloudSamples.},
booktitle = {Proceedings of the 8th International Conference on the Internet of Things},
articleno = {48},
numpages = {4},
keywords = {IoT interoperability, cloud computing, resource slice},
location = {Santa Barbara, California, USA},
series = {IOT '18}
}
@phdthesis{10.5555/AAI27744168,
author = {Casertano, Andrew Emil and Gulick, Denny and Chmiel, Margaret and Kraus, Kari and Wang, Ping},
advisor = {Richard, Marciano,},
title = {An Autoethnographic Account of Innovation at the US Department of Veterans Affairs},
year = {2020},
isbn = {9798662468207},
publisher = {University of Maryland, College Park},
abstract = {The history of the U.S. Department of Veterans Affairs (VA) health information technology (HIT) has been characterized by both enormous successes and catastrophic failures. While the VA was once hailed as the way to the future of twenty-first-century health care, many programs have been mismanaged, delayed, or flawed, resulting in the waste of hundreds of millions of taxpayer dollars. Since 2015 the U.S. Government Accountability Office (GAO) has designated HIT at the VA as being susceptible to waste, fraud, and mismanagement. The timely central research question I ask in this study is, can healthcare IT at the VA be healed? To address this question, I investigate a HIT case study at the VA Center of Innovation (VACI), originally designed to be the flagship initiative of the open government transformation at the VA. The Open Source Electronic Health Record Alliance (OSEHRA) was designed to promote the open innovation ecosystem public-private-academic partnership. Based on my fifteen years of experience at the VA, I use an autoethnographic methodology to make a significant value-added contribution to understanding and modeling the VA's approach to innovation. I use several theoretical information system framework models including People, Process, and Technology (PPT), Technology, Organization and Environment (TOE), and Technology Adaptive Model (TAM) and propose a new adaptive theory to understand the inability of VA HIT to innovate. From the perspective of people and culture, I study retaliation against whistleblowers, organization behavioral integrity, and lack of transparency in communications. I examine the VA processes, including the different software development methodologies used, the development and operations process (DevOps) of an open-source application developed at VACI, the Radiology Protocol Tool Recorder (RAPTOR), a Veterans Health Information Systems and Technology Architecture (VistA) radiology workflow module. I find that the VA has chosen to migrate away from inhouse application software and buy commercial software. The impact of these People, Process, and Technology findings are representative of larger systemic failings and are appropriate examples to illustrate systemic issues associated with IT innovation at the VA. This autoethnographic account builds on first-hand project experience and literature-based insights.},
note = {AAI27744168}
}
@book{10.5555/2851113,
author = {Eadline, Douglas},
title = {Hadoop 2 Quick-Start Guide: Learn the Essentials of Big Data Computing in the Apache Hadoop 2 Ecosystem},
year = {2015},
isbn = {0134049942},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {Get Started Fast with Apache Hadoop 2, YARN, and Todays Hadoop Ecosystem With Hadoop 2.x and YARN, Hadoop moves beyond MapReduce to become practical for virtually any type of data processing. Hadoop 2.x and the Data Lake concept represent a radical shift away from conventional approaches to data usage and storage. Hadoop 2.x installations offer unmatched scalability and breakthrough extensibility that supports new and existing Big Data analytics processing methods and models. Hadoop 2 Quick-Start Guide is the first easy, accessible guide to Apache Hadoop 2.x, YARN, and the modern Hadoop ecosystem. Building on his unsurpassed experience teaching Hadoop and Big Data, author Douglas Eadline covers all the basics you need to know to install and use Hadoop 2 on personal computers or servers, and to navigate the powerful technologies that complement it. Eadline concisely introduces and explains every key Hadoop 2 concept, tool, and service, illustrating each with a simple beginning-to-end example and identifying trustworthy, up-to-date resources for learning more. This guide is ideal if you want to learn about Hadoop 2 without getting mired in technical details. Douglas Eadline will bring you up to speed quickly, whether youre a user, admin, devops specialist, programmer, architect, analyst, or data scientist. Coverage Includes Understanding what Hadoop 2 and YARN do, and how they improve on Hadoop 1 with MapReduce Understanding Hadoop-based Data Lakes versus RDBMS Data Warehouses Installing Hadoop 2 and core services on Linux machines, virtualized sandboxes, or clusters Exploring the Hadoop Distributed File System (HDFS) Understanding the essentials of MapReduce and YARN application programming Simplifying programming and data movement with Apache Pig, Hive, Sqoop, Flume, Oozie, and HBase Observing application progress, controlling jobs, and managing workflows Managing Hadoop efficiently with Apache Ambariincluding recipes for HDFS to NFSv3 gateway, HDFS snapshots, and YARN configuration Learning basic Hadoop 2 troubleshooting, and installing Apache Hue and Apache Spark}
}
@inproceedings{10.5555/2663360.2663362,
author = {Bass, Len and Jeffery, Ross and Wada, Hiroshi and Weber, Ingo and Zhu, Liming},
title = {Eliciting Operations Requirements for Applications},
year = {2013},
isbn = {9781467364416},
publisher = {IEEE Press},
abstract = {The DevOps community advocates communication between the operations staff and the development staff as a means of ensuring that the developers understand the issues associated with operations. This paper argues that "communication" is too vague and that there are a variety of specific and well known sources that developers can examine to determine requirements to support the installation and operations of an application product. These sources include standards, process descriptions, studies about sources of failure in configuration and upgrade, and models that include both product and process.},
booktitle = {Proceedings of the 1st International Workshop on Release Engineering},
pages = {5–8},
numpages = {4},
keywords = {operations processes, applications requirements, devops},
location = {San Francisco, California},
series = {RELENG '13}
}